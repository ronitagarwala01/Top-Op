{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelLibrary import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variational Autoencoder</h2>\n",
    "\n",
    "<p>An autoencoding model that takes an input, in this case it will be the load condtions and a part image, and produces a latentspace, in terms of mean and standard deviation. We then use a decoder to expand this latent space on a specific normal distribution to regenerat the optimal part.</p>\n",
    "<p>The input space for this model would be an image of a current part(as a seed) the load conditions could be kept as either a vector or could be expanded into an image like the iterative model. The latent space would have to be standardized as would the image resolutions. The output would just be the final iteration of the part.</p>\n",
    "</div>\n",
    "<p>The second stage to this setup would have us take the decoder and train a new encoder to produce the same latent space but with only the format vector and a noise value. This would then have to be pluged into the decoder to produce the optimal part.</p>\n",
    "<p>A special training regime would have to be run for this setup. The load encoder would produce a set of means and standard deviations. The mean of this set(no deviation) should decode into the optimal part for the load conditions. The standard deviations can be added to get some similar parts around the optimal.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview of the data\n",
    "#dataDirectory = os.path.join(os.getcwd(),'data')\n",
    "dataDirectory = r\"E:\\TopoptGAfileSaves\\ComplianceMinimization\\Agents\"\n",
    "DATA_FILE_PATH = os.path.join(dataDirectory,'100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "    def __init__(self,imageShape,latenDims):\n",
    "        super(VariationalAutoEncoder,self).__init__()\n",
    "        self.encoder = buildEncoder(imageShape,latenDims,10)\n",
    "        self.decoder = buildDecoder(latenDims,imageShape,10)\n",
    "        \n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean( name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            #print(z.shape)\n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSample(res):\n",
    "    im_array = np.random.normal(0,.1,size=(res,res))\n",
    "    im_array = np.abs(im_array)\n",
    "\n",
    "    for i in range(res):\n",
    "        im_array[i,i] = 1 - np.abs(np.random.normal(0,.1))\n",
    "    \n",
    "    return im_array\n",
    "\n",
    "def createData(number,res):\n",
    "    data = np.zeros((number,res,res))\n",
    "    for i in range(number):\n",
    "        if(np.random.random() >= 0.5):\n",
    "            data[i,:,:] = createDataSample(res)\n",
    "        else:\n",
    "            data[i,:,:] = np.fliplr(createDataSample(res))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d8b31a3b88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(createDataSample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "res = 5\n",
    "num = 10\n",
    "data = createData(num,res)\n",
    "data = np.reshape(data,(num,res,res,1))\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 5, 5).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Nate\\AppData\\Local\\Temp/ipykernel_13836/2619329750.py\", line 21, in train_step\n        reconstruction = self.decoder(z)\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 118, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape\" \"                 f\"(type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [5, 25], output_shape = [5, 5]\n    \n    Call arguments received by layer \"reshape\" \"                 f\"(type Reshape):\n      • inputs=tf.Tensor(shape=(None, 5, 25), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13836/2273724978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariationalAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13836/2619329750.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mreconstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;31m#print(z.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mreconstruction_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Nate\\AppData\\Local\\Temp/ipykernel_13836/2619329750.py\", line 21, in train_step\n        reconstruction = self.decoder(z)\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py\", line 118, in _fix_unknown_dimension\n        raise ValueError(msg)\n\n    ValueError: Exception encountered when calling layer \"reshape\" \"                 f\"(type Reshape).\n    \n    total size of new array must be unchanged, input_shape = [5, 25], output_shape = [5, 5]\n    \n    Call arguments received by layer \"reshape\" \"                 f\"(type Reshape):\n      • inputs=tf.Tensor(shape=(None, 5, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vae = VariationalAutoEncoder((res,res),res)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(data, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
