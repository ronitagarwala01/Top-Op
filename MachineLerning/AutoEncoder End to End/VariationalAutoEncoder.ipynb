{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetAgentData import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variational Autoencoder</h2>\n",
    "\n",
    "<p>An autoencoding model that takes an input, in this case it will be the load condtions and a part image, and produces a latentspace, in terms of mean and standard deviation. We then use a decoder to expand this latent space on a specific normal distribution to regenerat the optimal part.</p>\n",
    "<p>The input space for this model would be an image of a current part(as a seed) the load conditions could be kept as either a vector or could be expanded into an image like the iterative model. The latent space would have to be standardized as would the image resolutions. The output would just be the final iteration of the part.</p>\n",
    "</div>\n",
    "<p>The second stage to this setup would have us take the decoder and train a new encoder to produce the same latent space but with only the format vector and a noise value. This would then have to be pluged into the decoder to produce the optimal part.</p>\n",
    "<p>A special training regime would have to be run for this setup. The load encoder would produce a set of means and standard deviations. The mean of this set(no deviation) should decode into the optimal part for the load conditions. The standard deviations can be added to get some similar parts around the optimal.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview of the data\n",
    "#dataDirectory = os.path.join(os.getcwd(),'data')\n",
    "dataDirectory = r\"E:\\TopoptGAfileSaves\\ComplianceMinimization\\Agents\"\n",
    "DATA_FILE_PATH = os.path.join(dataDirectory,'100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
