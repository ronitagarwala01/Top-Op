{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetMassData import *\n",
    "from ModelData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 363\n",
      "Agent_101624\n"
     ]
    }
   ],
   "source": [
    "#overview of the data\n",
    "#dataDirectory = os.path.join(os.getcwd(),'data')\n",
    "dataDirectory = os.path.join(r\"E:\\TopoptGAfileSaves\",\"Mass minimization\",\"AlienWareData\",\"Augmented\",\"Set1\",\"Agents\")\n",
    "DATA_FILE_PATH = os.path.join(dataDirectory,'120_60')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = os.path.join(\"E:\\TopoptGAfileSaves\",\"Mass minimization\",\"JustMirrored\",\"Agents\",\"100_50\")\n",
    "path = dataDirectory#os.path.join(dataDirectory,'100_50')\n",
    "AgentsToGrab = os.listdir(path)\n",
    "numAgents = len(AgentsToGrab)\n",
    "print(\"There are {} files to explore.\".format(numAgents))\n",
    "\n",
    "fx_array = []\n",
    "fy_array = []\n",
    "Youngs_array = []\n",
    "compliance_array = []\n",
    "stress_array = []\n",
    "for i,agent in enumerate(AgentsToGrab):\n",
    "    print(\"{:.1f}%\\t\".format(100*(i/numAgents)),end='\\r')\n",
    "    agentFiles = os.listdir(os.path.join(path,agent))\n",
    "    for fileName in agentFiles:\n",
    "        if('loadConditions' in fileName):\n",
    "            loadConditions = np.load(os.path.join(path,agent,fileName))\n",
    "            #print('loadCondtions Exist')\n",
    "            formated = unpackLoadConditions(loadConditions)\n",
    "            circles = formated[0]\n",
    "            radii = formated[1]\n",
    "            forces = formated[2]\n",
    "            nelx, nely = formated[3], formated[4]\n",
    "            Youngs, C_max, S_max = formated[5], formated[6], formated[7]\n",
    "            fx_array.append(forces[0][0])\n",
    "            fx_array.append(forces[0][1])\n",
    "            fx_array.append(forces[0][2])\n",
    "            fy_array.append(forces[1][0])\n",
    "            fy_array.append(forces[1][1])\n",
    "            fy_array.append(forces[1][2])\n",
    "            Youngs_array.append(Youngs)\n",
    "            compliance_array.append(C_max)\n",
    "            stress_array.append(S_max)\n",
    "            break\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(fx_array))\n",
    "print(np.mean(fy_array))\n",
    "print(np.mean(Youngs_array))\n",
    "print(np.mean(compliance_array))\n",
    "print(np.mean(stress_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatStats(array):\n",
    "    print(\"min:\",np.min(array))\n",
    "    print(\"mean:\",np.mean(array))\n",
    "    print(\"max:\",np.max(array))\n",
    "\n",
    "    print(\"Normalizing\")\n",
    "    # Forces\n",
    "    # ar2 = np.array(array) \n",
    "    # ar2_mean = np.mean(np.abs(ar2))\n",
    "    # ar2 = ar2 / ar2_mean\n",
    "    ar2 = np.array(array) \n",
    "    ar2_mean = np.mean(ar2)\n",
    "    ar2 = ar2 / ar2_mean\n",
    "    print(\"min:\",np.min(ar2))\n",
    "    print(\"mean:\",np.mean(ar2))\n",
    "    print(\"max:\",np.max(ar2))\n",
    "\n",
    "    print(ar2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatStats(stress_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence class will hold each problem statement as a sequence of all the iterations.\n",
    "It will hold the load conditions as well as each iteration.\n",
    "<ol>\n",
    "<li>When training the model, some fraction of the sequences will be called and the model will train on them.</li>\n",
    "<li>The model will then be given some other fraction of seqences to predict.</li>\n",
    "<li>These predictions will be maped to their original inputs and will be re-outputed as new problem statment iterations.</li>\n",
    "<li>The new(Model predicted) datapoints can then be inputed back into the model for training.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(dataPointsToGrab:int):\n",
    "\n",
    "    # Constants of interest\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the data grabed so that the first thee datapoints aren't always in the data.\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "    nonConvergedCounter = 0\n",
    "\n",
    "    sequenceData = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{:.2f}%\\t\\t\".format((100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            #join the data file path to a random sorted member within the data directory\n",
    "            pathToAgent = os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])\n",
    "            formated,x_array,derivatives_array,objectives_array,markName = getData(pathToAgent)\n",
    "            \n",
    "        except:\n",
    "            #if an exception occurs list it and move forward\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "            continue\n",
    "        else:\n",
    "            cvrg = True\n",
    "            if('NotConverged' in markName):\n",
    "                print(\"file {} has not converged.\".format(dir_list[indexList[i]]))\n",
    "                nonConvergedCounter += 1\n",
    "                cvrg = False\n",
    "            else:\n",
    "                #if no error occured append that data to the data list\n",
    "                sequenceData.append(TopOptSequence(i,formated,x_array,len(x_array),cvrg))\n",
    "\n",
    "    print(\"100%\\t\\t\")\n",
    "    print(f\"Out of {dataPointsToGrab} data points gathered, {100*(nonConvergedCounter/dataPointsToGrab)}% had not converged for a total of {nonConvergedCounter}\")\n",
    "    return sequenceData\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving 30 Datapoints.\n",
      "file Agent_349369 has not converged.\n",
      "100%\t\t\t\t\n",
      "Out of 30 data points gathered, 3.3333333333333335% had not converged for a total of 1\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "Data = buildDataSet(30)\n",
    "print(len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadCondtionsImage = Data[0].formatLoadCondtions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 14\n",
      "\n",
      "Test: 15\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "\"\"\"\n",
    "By performing the test train split we can get a training data set and a testing dataset to get the metrics for out model\n",
    "By performing the split a second time we can get a validataion dataset that the model will never see that we can use to get out own accuracy score out of\n",
    "\"\"\"\n",
    "Data_train, Data_test = train_test_split(Data, test_size=0.5)\n",
    "print(\"Train: {}\".format(len(Data_train)))\n",
    "print(\"\\nTest: {}\".format(len(Data_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel():\n",
    "    modelNum = 9\n",
    "    model = Model_m9(121,61)\n",
    "    fileSaveName = \"Model_m{}\".format(modelNum)\n",
    "    \n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelPath,fileSaveName),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        try:\n",
    "            \n",
    "            model.load_weights(os.path.join(modelPath,fileSaveName))\n",
    "        except:\n",
    "            print(\"Model weights could not be loaded.\")\n",
    "        else:\n",
    "            print(\"Model weights Loaded\")\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "        print(\"Model path created\")\n",
    "\n",
    "    \n",
    "    \n",
    "    model.compile(  optimizer='Adam',\n",
    "                    loss= keras.losses.BinaryCrossentropy())\n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat shapes (None, 32, 16, 64) and (None, 31, 16, 64) create padding 1 and 0\n",
      "concat shapes (None, 62, 32, 32) and (None, 61, 31, 32) create padding 1 and 1\n",
      "concat shapes (None, 122, 62, 64) and (None, 121, 61, 16) create padding 1 and 1\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF351FC8> and <keras.layers.regularization.dropout.Dropout object at 0x000002B3EF773588>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF79B2C8> and <keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF351FC8>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF785D88> and <keras.layers.regularization.gaussian_noise.GaussianNoise object at 0x000002B3EF792808>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EA9EE208> and <keras.layers.regularization.dropout.Dropout object at 0x000002B3EF785C08>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF50E648> and <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002B3EF781B08>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF792408> and <keras.layers.regularization.gaussian_noise.GaussianNoise object at 0x000002B3EF799F48>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d_transpose.Conv2DTranspose object at 0x000002B3FF7D3AC8> and <keras.layers.regularization.dropout.Dropout object at 0x000002B3EF514D88>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF7E0B88> and <keras.layers.convolutional.conv2d_transpose.Conv2DTranspose object at 0x000002B3FF7D3AC8>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF7E5EC8> and <keras.layers.regularization.gaussian_noise.GaussianNoise object at 0x000002B3EF790D88>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d_transpose.Conv2DTranspose object at 0x000002B3FF7EF1C8> and <ModelData.ConcatAndCrop object at 0x000002B3FF7DADC8>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF7FA288> and <keras.layers.regularization.dropout.Dropout object at 0x000002B3FF7DAC88>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF328048> and <keras.layers.convolutional.conv2d_transpose.Conv2DTranspose object at 0x000002B3FF7EF1C8>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d_transpose.Conv2DTranspose object at 0x000002B3FF80C108> and <keras.layers.regularization.gaussian_noise.GaussianNoise object at 0x000002B3FF7F2B88>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF81B8C8> and <keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF7FA288>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF828FC8> and <keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3EF328048>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.conv2d.Conv2D object at 0x000002B3FF828548> and <keras.layers.regularization.dropout.Dropout object at 0x000002B3EF32A748>).\n",
      "Model weights Loaded\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x (InputLayer)                 [(None, 121, 61, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " loadConditions (InputLayer)    [(None, 121, 61, 6)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 121, 61, 7)   0           ['x[0][0]',                      \n",
      "                                                                  'loadConditions[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 121, 61, 16)  1024        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 121, 61, 16)  2320        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 61, 31, 16)  0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " gaussian_noise_6 (GaussianNois  (None, 61, 31, 16)  0           ['max_pooling2d_3[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 61, 31, 16)   0           ['gaussian_noise_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 61, 31, 32)   4640        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 61, 31, 32)   9248        ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 31, 16, 32)  0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " gaussian_noise_7 (GaussianNois  (None, 31, 16, 32)  0           ['max_pooling2d_4[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 31, 16, 32)   0           ['gaussian_noise_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 31, 16, 64)   18496       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 31, 16, 64)   36928       ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 16, 8, 64)   0           ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " gaussian_noise_8 (GaussianNois  (None, 16, 8, 64)   0           ['max_pooling2d_5[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16, 8, 64)    0           ['gaussian_noise_8[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 8, 128)   73856       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 8, 128)   147584      ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 32, 16, 64)  204864      ['conv2d_21[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " gaussian_noise_9 (GaussianNois  (None, 32, 16, 64)  0           ['conv2d_transpose_3[0][0]']     \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " concat_and_crop_3 (ConcatAndCr  (None, 31, 16, 128)  0          ['gaussian_noise_9[0][0]',       \n",
      " op)                                                              'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 31, 16, 64)   73792       ['concat_and_crop_3[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 31, 16, 64)   36928       ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 31, 16, 64)   0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 62, 32, 32)  51232       ['dropout_8[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " gaussian_noise_10 (GaussianNoi  (None, 62, 32, 32)  0           ['conv2d_transpose_4[0][0]']     \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " concat_and_crop_4 (ConcatAndCr  (None, 61, 31, 64)  0           ['gaussian_noise_10[0][0]',      \n",
      " op)                                                              'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 61, 31, 32)   18464       ['concat_and_crop_4[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 61, 31, 32)   9248        ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 61, 31, 32)   0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 122, 62, 64)  51264      ['dropout_9[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concat_and_crop_5 (ConcatAndCr  (None, 121, 61, 80)  0          ['conv2d_transpose_5[0][0]',     \n",
      " op)                                                              'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 121, 61, 16)  11536       ['concat_and_crop_5[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 121, 61, 16)  2320        ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " x_out (Conv2D)                 (None, 121, 61, 1)   17          ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 753,761\n",
      "Trainable params: 753,761\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "currentModelNumber = 9 #change this one\n",
    "model,callBack = getModel()\n",
    "print()\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(hist):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.set_title(\"\")\n",
    "    keys = hist.history.keys()\n",
    "    y = np.arange(1,hist.params['epochs']+1)\n",
    "    for key in keys:\n",
    "        if('output' in key):\n",
    "            minVal = min(hist.history[key])\n",
    "            meanVal = np.mean(hist.history[key])\n",
    "            maxVal = max(hist.history[key])\n",
    "            if(minVal != maxVal):\n",
    "                print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "                #ax.plot(y,hist.history[key],linewidth=0.5,label=key)\n",
    "        else:\n",
    "            ax.plot(y,hist.history[key],label=key)\n",
    "            minVal = min(hist.history[key])\n",
    "            meanVal = np.mean(hist.history[key])\n",
    "            maxVal = max(hist.history[key])\n",
    "            print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plotHistory_lite(hist):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.set_title(\"\")\n",
    "    keys = hist.keys()\n",
    "    for key in keys:\n",
    "        if('output' in key):\n",
    "            minVal = min(hist[key])\n",
    "            meanVal = np.mean(hist[key])\n",
    "            maxVal = max(hist[key])\n",
    "            if(minVal != maxVal):\n",
    "                print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "                #ax.plot(y,hist.history[key],linewidth=0.5,label=key)\n",
    "        else:\n",
    "            y = np.arange(1,len(hist[key])+1)\n",
    "            ax.plot(y,hist[key],label=key)\n",
    "            minVal = min(hist[key])\n",
    "            meanVal = np.mean(hist[key])\n",
    "            maxVal = max(hist[key])\n",
    "            print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTrainModelOverFirstIteration(iterationJump:int=5):\n",
    "    def createDataset(data):\n",
    "        loadCondtions = []\n",
    "        parts = []\n",
    "        outputs = []\n",
    "        for i in range(len(data)):\n",
    "            StartingBlock,formattedImage,outputParts = data[i].dispenceFirstIteration(5,iterationJump)\n",
    "            loadCondtions.append(formattedImage)\n",
    "            parts.append(StartingBlock)\n",
    "            outputArrays = []\n",
    "            for outputBlock in outputParts:\n",
    "                outputArrays.append(outputBlock)\n",
    "            outputs.append(outputArrays)\n",
    "        \n",
    "        loadCondtions = np.array(loadCondtions)\n",
    "        parts = np.array(parts)\n",
    "        outputs = np.array(outputs)\n",
    "        return loadCondtions,parts,outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    format_array,x_array,outputs_array = createDataset(Data_train)\n",
    "\n",
    "    x1 = outputs_array[:,0,:,:,:]\n",
    "    x2 = outputs_array[:,1,:,:,:]\n",
    "    x3 = outputs_array[:,2,:,:,:]\n",
    "    x4 = outputs_array[:,3,:,:,:]\n",
    "    x5 = outputs_array[:,4,:,:,:]\n",
    "\n",
    "    print(\"format_array.shape:\",format_array.shape)\n",
    "    print(\"x_array.shape:\",x_array.shape)\n",
    "    print(\"outputs_array.shape:\",outputs_array.shape)\n",
    "    print(\"x1.shape:\",x1.shape)\n",
    "    print(\"x5.shape:\",x5.shape)\n",
    "    numEpochs = 5\n",
    "    BatchSize = 32 # default tensorflow batchsize\n",
    "    numBatches = len(x_array) // BatchSize\n",
    "    BatchesPerEpoch = numBatches// numEpochs\n",
    "    print(\"Pretraining model over {} epochs.\\n\\tnumSamples: {}\\n\\tnumBatches: {}\\n\\tBatches per Epoch:{}\\n\".format(numEpochs,len(x_array),numBatches,BatchesPerEpoch))\n",
    "    \n",
    "    history1 = model.fit(\n",
    "        x={'x':x_array,'loadConditions':format_array},\n",
    "        y=(x1,x2,x3,x4,x5),\n",
    "        validation_split = 0.1,\n",
    "        epochs=numEpochs,\n",
    "        shuffle=True,\n",
    "        steps_per_epoch = BatchesPerEpoch,\n",
    "        callbacks = [callBack])\n",
    "\n",
    "    return history1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = preTrainModelOverFirstIteration(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(iterationJump:int=5):\n",
    "    def createDataset(data):\n",
    "        loadCondtions = []\n",
    "        parts = []\n",
    "        outputs = []\n",
    "        for i in range(len(data)):\n",
    "            if(data[i].converged):\n",
    "                for j in range(data[i].numIterations):\n",
    "                    StartingBlock,formattedImage,outputParts = data[i].dispenceIteration(j,5,iterationJump)\n",
    "                    loadCondtions.append(formattedImage)\n",
    "                    parts.append(StartingBlock)\n",
    "                    outputArrays = []\n",
    "                    for outputBlock in outputParts:\n",
    "                        outputArrays.append(outputBlock)\n",
    "                    outputs.append(outputArrays)\n",
    "        \n",
    "        loadCondtions = np.array(loadCondtions)\n",
    "        parts = np.array(parts)\n",
    "        outputs = np.array(outputs)\n",
    "        return loadCondtions,parts,outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    format_array,x_array,outputs_array = createDataset(Data_train)\n",
    "\n",
    "    x1 = outputs_array[:,0,:,:,:]\n",
    "    x2 = outputs_array[:,1,:,:,:]\n",
    "    x3 = outputs_array[:,2,:,:,:]\n",
    "    x4 = outputs_array[:,3,:,:,:]\n",
    "    x5 = outputs_array[:,4,:,:,:]\n",
    "\n",
    "    print(\"format_array.shape:\",format_array.shape)\n",
    "    print(\"x_array.shape:\",x_array.shape)\n",
    "    print(\"outputs_array.shape:\",outputs_array.shape)\n",
    "    print(\"x1.shape:\",x1.shape)\n",
    "    print(\"x5.shape:\",x5.shape)\n",
    "    numEpochs = 1\n",
    "    BatchSize = 32 # default tensorflow batchsize\n",
    "    numBatches = len(x_array) // BatchSize\n",
    "    BatchesPerEpoch = numBatches// numEpochs\n",
    "    print(\"Pretraining model over {} epochs.\\n\\tnumSamples: {}\\n\\tnumBatches: {}\\n\\tBatches per Epoch:{}\\n\".format(numEpochs,len(x_array),numBatches,BatchesPerEpoch))\n",
    "    \n",
    "    history1 = model.fit(\n",
    "        x={'x':x_array,'loadConditions':format_array},\n",
    "        y=(x1,x2,x3,x4,x5),\n",
    "        validation_split = 0.1,\n",
    "        epochs=numEpochs,\n",
    "        shuffle=True)#,\n",
    "        #steps_per_epoch = BatchesPerEpoch)#,\n",
    "        #callbacks = [callBack])\n",
    "\n",
    "    return history1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_array.shape: (917, 121, 61, 6)\n",
      "x_array.shape: (917, 121, 61, 1)\n",
      "outputs_array.shape: (917, 5, 121, 61, 1)\n",
      "x1.shape: (917, 121, 61, 1)\n",
      "x5.shape: (917, 121, 61, 1)\n",
      "Pretraining model over 1 epochs.\n",
      "\tnumSamples: 917\n",
      "\tnumBatches: 28\n",
      "\tBatches per Epoch:28\n",
      "\n",
      " 1/26 [>.............................] - ETA: 5:39 - loss: 1.3168 - output_1_loss: 0.2849 - output_2_loss: 0.2775 - output_3_loss: 0.2507 - output_4_loss: 0.2478 - output_5_loss: 0.2558"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14560/2978803656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14560/3378566164.py\u001b[0m in \u001b[0;36mTrainModel\u001b[1;34m(iterationJump)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         shuffle=True)#,\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;31m#steps_per_epoch = BatchesPerEpoch)#,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m#callbacks = [callBack])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h3 = TrainModel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = TrainModel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = json.load(open(r\"C:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\trainHistory_0\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory_lite(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EditImage(image):\n",
    "\n",
    "    #noise = np.random.normal(loc=0,scale=.05,size=image.shape)\n",
    "    #return image + noise\n",
    "\n",
    "    return np.flip(image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawModelIteratins(num):\n",
    "    sequenceToStart:TopOptSequence = Data_test[num]\n",
    "    numImages = sequenceToStart.numIterations\n",
    "    imagesToShow = 5\n",
    "    #print(numImages)\n",
    "    fig,ax = plt.subplots(2,imagesToShow)\n",
    "\n",
    "    nelx = 100\n",
    "    nely = 50\n",
    "    StartingBlock,formattedImage,_ = sequenceToStart.dispenceFirstIteration(1,1)\n",
    "\n",
    "    formattedImage = np.array(formattedImage)\n",
    "    ImageToPredict = np.array(StartingBlock)\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages):\n",
    "        \n",
    "        output = model.predict({'x':ImageToPredict,'loadConditions':formattedImage},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages,end-start,(end-start)/numImages))\n",
    "    imagesToJump = numImages // imagesToShow\n",
    "\n",
    "    for i in range(0,imagesToShow-1):\n",
    "        ax[0,i].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[0,i].get_xaxis().set_visible(False)\n",
    "        ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "        #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "        ax[1,i].imshow(np.reshape(PredictedImages[i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[1,i].get_xaxis().set_visible(False)\n",
    "        ax[1,i].get_yaxis().set_visible(False)\n",
    "    ax[0,-1].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,-1].get_xaxis().set_visible(False)\n",
    "    ax[0,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,-1].imshow(np.reshape(PredictedImages[-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,-1].get_xaxis().set_visible(False)\n",
    "    ax[1,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[0,0].set_title(\"True\")\n",
    "    ax[1,0].set_title(\"Pred\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0#np.random.randint(0,len(Data_score)-1)\n",
    "print(n)\n",
    "DrawModelIteratins(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = np.random.randint(0,len(Data_score)-1)\n",
    "n = np.arange(len(Data_score),dtype='int32')\n",
    "np.random.shuffle(n)\n",
    "print(len(n))\n",
    "for i in range(10):\n",
    "    DrawModelIteratins(n[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOverIterations(index,data):\n",
    "    sequenceToStart = data[index]\n",
    "    numImages = 20#sequenceToStart.numIterations\n",
    "    imagesToShow = numImages\n",
    "    #print(numImages)\n",
    "    nelx = 101\n",
    "    nely = 51\n",
    "    StartingBlock,formattedImage,_ = sequenceToStart.dispenceFirstIteration(1,1)\n",
    "\n",
    "    formattedImage = np.reshape(formattedImage,(1,nelx,nely,6))\n",
    "    ImageToPredict = np.reshape(StartingBlock,(1,nelx,nely,1))\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages):\n",
    "        \n",
    "        output = m2.predict({'x':ImageToPredict,'loadConditions':formattedImage},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages,end-start,(end-start)/numImages))\n",
    "    imagesToJump = 1\n",
    "    imageArray = []\n",
    "\n",
    "    for i,image in enumerate(PredictedImages):\n",
    "        fig,ax = plt.subplots(1,1)\n",
    "        \n",
    "        if(i == 0):\n",
    "            ax.set_title(\"Iteration: {}\".format(i))\n",
    "        else:\n",
    "            im1 = np.reshape(PredictedImages[i],(nelx*nely))\n",
    "            im2 = np.reshape(PredictedImages[i-1],(nelx*nely))\n",
    "            ax.set_title(\"Iteration: {}, Change: {:.5f}\".format(i,np.linalg.norm(im1-im2,ord=np.inf)))\n",
    "        ax.imshow(np.reshape(image,(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        #img_buf = io.BytesIO()\n",
    "        #plt.savefig(img_buf, format='png')\n",
    "\n",
    "        #im = Image.open(img_buf)\n",
    "        #imageArray.append(im)\n",
    "\n",
    "        plt.show()\n",
    "    #return imageArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOverIterations(1,Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesToSave = 10\n",
    "rnd = np.arange(imagesToSave,dtype='int32')\n",
    "np.random.shuffle(rnd)\n",
    "for i in range(10):\n",
    "    im_array = plotOverIterations(rnd[i],Data)\n",
    "    im = im_array[0]\n",
    "    im_array.pop(0)\n",
    "    im.save(\"out{}.gif\".format(i),save_all=True,append_images = im_array,optimize=False,loop=0)\n",
    "    im.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thoughts</h1>\n",
    "\n",
    "M6: Looking at the model at work shows progress when loads are grouped up. Failures seem to occur with spaced load conditions and low volfrac."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Unet, in order to be able to capture multiple resolutions we need to allow the downsampling to resolve issues with resolutions that are not multiples of 2.\n",
    "\n",
    "This can be solved with the following setup\n",
    "Take the resolution when a down sample occurs. Take the ceil of the down sample(5/2 = 3). Pass this to the next layer and continue untill upscaleing. When we upscale there is a possibility of the tensors that must be concatenated not being the same resolution. We take the resolution with the higher dimensions(this will always be the upsampled part, not the skip connection) and crop it by one along the nessesary dimension.\n",
    "\n",
    "Some times the cropping will be nessesary sometimes it will not be nessesary but it will always be a cropping by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"Model_m9\"\n",
    "\n",
    "modelPath = os.path.join(os.getcwd(),'ModelSave',modelName)\n",
    "m2.load_weights(os.path.join(modelPath,modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.set_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(m2.model.layers):\n",
    "#layer = model.model.layers[1].output\n",
    "    name = layer.name\n",
    "    #if('conv2d' in name):\n",
    "    print(i,name)\n",
    "print(len(model.model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.model.layers):\n",
    "#layer = model.model.layers[1].output\n",
    "    name = layer.name\n",
    "    #if('conv2d' in name):\n",
    "    print(i,name)\n",
    "print(len(model.model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = [[11,4],[14,7],[15,8],[18,11],[19,12],[22,15],[23,16],[24,17],[27,20],[28,21],[29,22],[32,25],[33,26],[34,27],[36,29],[37,30],[39,31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m2_layer in enumerate(m2.model.layers):\n",
    "    for j,m1_layer in enumerate(model.model.layers):\n",
    "        for iMatch,jMatch in matchups:\n",
    "            if(i==iMatch and j == jMatch):\n",
    "                print(f\"Getting weights from {i}:{m2_layer.name} and putting them in {j}:{m1_layer.name}\")\n",
    "                m1_layer.set_weights(m2_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"Model_m9\"\n",
    "\n",
    "modelPath = os.path.join(os.getcwd(),'ModelSave',modelName)\n",
    "model.save_weights(modelPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
