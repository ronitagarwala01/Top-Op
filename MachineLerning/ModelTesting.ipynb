{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetAgentData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview of the data\n",
    "dataDirectory = os.path.join(os.getcwd(),'data')\n",
    "DATA_FILE_PATH = os.path.join(dataDirectory,'100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopOptSequence:\n",
    "    def __init__(self,ID,forces,dof,passive,x,numIterations):\n",
    "        self.ID = ID\n",
    "        self.forceImage = forces\n",
    "        self.anchorImage = dof\n",
    "        self.filledAreaImage = passive\n",
    "        self.xPhys_array = x\n",
    "        self.numIterations = numIterations\n",
    "        self.iterationJumpTracker = []\n",
    "    \n",
    "    def dispenceData(self,iterationJump:int=5):\n",
    "        \"\"\"\n",
    "        When called creates list of numpy arrays filled with the data needed to train the model\n",
    "\n",
    "        returns:\n",
    "            forces_array\n",
    "            support_array\n",
    "            filled_array\n",
    "            x_array\n",
    "            x_optimized_array\n",
    "            finished_array\n",
    "        \"\"\"\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        self.iterationJumpTracker = []\n",
    "        for j in range(self.numIterations-iterationJump):\n",
    "                dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,j]])\n",
    "                v = 0.0\n",
    "                f= 'unfinished'\n",
    "                if(j+iterationJump >= self.numIterations - 1):\n",
    "                    v = 1.0\n",
    "                    f = 'finished'\n",
    "                dataY.append([self.xPhys_array[:,:,j+iterationJump],np.array([v])])\n",
    "                self.iterationJumpTracker.append([j,j+iterationJump])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:{}\".format(j,j+iterationJump,f))\n",
    "\n",
    "        for j in range(1,min(iterationJump,self.numIterations)):\n",
    "            # add the last iterations(dataY has True)\n",
    "            dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,-j -1]])\n",
    "            dataY.append([self.xPhys_array[:,:,self.numIterations-1],np.array([1.])])\n",
    "            self.iterationJumpTracker.append([-j,self.numIterations-1])\n",
    "\n",
    "            #print(\"Adding itter: {} -> {}:finished\".format(numIterations-j-1,numIterations-1))\n",
    "\n",
    "        # add the optimal Stoping point data, input = output\n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,self.numIterations-1]])\n",
    "        dataY.append([self.xPhys_array[:,:,self.numIterations-1],np.array([1.])])\n",
    "        self.iterationJumpTracker.append([self.numIterations-1,self.numIterations-1])\n",
    "\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for x,finished in dataY:\n",
    "            x_optimized_array.append(x)\n",
    "            finished_array.append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "\n",
    "    def findNextIterations(self,i):\n",
    "        \"\"\"\n",
    "        Given and index for a predicted image, find it's next optimized output.\n",
    "        each output image will have a order that matches the order of it's input.\n",
    "        By knowing the input image we can find what image the prediction was supposed to be.\n",
    "        By knowing what the image was supposed to be, we can find next step in the iteration.\n",
    "\n",
    "\n",
    "        Process works like this:\n",
    "            - iterationTracker stores the input and output image,\n",
    "            - We know the input image so we use this to find the correct output image\n",
    "            - We then search the tracker for where the output image was used as input to get the correct next iteration.\n",
    "        \"\"\"\n",
    "        def searchTracker(index):\n",
    "            \"\"\"given an input index find the matching output index\"\"\"\n",
    "            for inputIndex,outputIndex in self.iterationJumpTracker:\n",
    "                if(inputIndex == index):\n",
    "                    return outputIndex\n",
    "            return -1\n",
    "        \n",
    "        correctOutput = searchTracker(i)\n",
    "        nextIteration = searchTracker(correctOutput)\n",
    "        return nextIteration\n",
    "\n",
    "    def formatPredictedData(self,predicted_x_array):\n",
    "        \"\"\"\n",
    "        Given an array of images and the finished array, reformate the images with their respective inputs to create a new dataset that has as input the predicted x and as output the correct next iteration.\n",
    "\n",
    "        The iteration Jump tracker has stored what iterations were jumped so by following the tracker list we can find the correct next output\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(predicted_x_array)\n",
    "        if(n ==  self.numIterations):#check if correct number of iterations has been recieved\n",
    "            forces_array = []\n",
    "            support_array = []\n",
    "            filled_array = []\n",
    "            x_array = []\n",
    "            x_optimized_array = []\n",
    "            finished_array = []\n",
    "            for i in range(n):\n",
    "                correctOutput = self.findNextIterations(i)\n",
    "                if(correctOutput <= 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    forces_array.append(self.forceImage.copy())\n",
    "                    support_array.append(self.anchorImage.copy())\n",
    "                    filled_array.append(self.filledAreaImage.copy())\n",
    "\n",
    "                    x_array.append(predicted_x_array[i].copy())\n",
    "                    v = 0.0\n",
    "                    if(correctOutput >= n):\n",
    "                        correctOutput = n-1\n",
    "                        v = 1.0\n",
    "                    x_optimized_array.append(self.xPhys_array[:,:,correctOutput])\n",
    "                    finished_array.append([v])\n",
    "                    \n",
    "            return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Data given is not of the correct format. required iterations: {}. iterations recieved: {}\".format(self.numIterations,n))\n",
    "\n",
    "    def dispenceFirstIterationData(self):\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        \n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,0]])\n",
    "        dataY.append([self.xPhys_array[:,:,1],np.array([0])])\n",
    "\n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,0]])\n",
    "        dataY.append([self.xPhys_array[:,:,2],np.array([0])])\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for x,finished in dataY:\n",
    "            x_optimized_array.append(x)\n",
    "            finished_array.append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "        \n",
    "    def dispenceM7modelData(self,iterationJump:int=5,predictionDepth:int=5):\n",
    "        \"\"\"\n",
    "        When called creates list of numpy arrays filled with the data needed to train the model\n",
    "        Designed to return the inital input but with an array of output representing the folowing iterations.\n",
    "\n",
    "        This will allow the model to train on its own predictions\n",
    "        \"\"\"\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        for j in range(self.numIterations-(iterationJump//2)):\n",
    "            dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,j]])\n",
    "            \n",
    "            dataY.append([])\n",
    "            for i in range(predictionDepth):\n",
    "                currentIteration = min(j + i*iterationJump,self.numIterations-1)\n",
    "                v = 0.0\n",
    "                if(currentIteration >= self.numIterations - 1):\n",
    "                    v = 1.0\n",
    "                dataY[j].append([self.xPhys_array[:,:,currentIteration],np.array([v])])\n",
    "\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for i in range(len(dataY)):\n",
    "            x_optimized_array.append([])\n",
    "            finished_array.append([])\n",
    "            for x,finished in dataY[i]:\n",
    "                x_optimized_array[i].append(x)\n",
    "                finished_array[i].append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(dataPointsToGrab:int):\n",
    "\n",
    "    # Constants of interest\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the data grabed so that the first thee datapoints aren't always in the data.\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    sequenceData = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{:.2f}%\\t\\t\".format((100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            #join the data file path to a random sorted member within the data directory\n",
    "            pathToAgent = os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])\n",
    "            forces,dof,passive,x,numIterations = formatIterativeModelDataSet(pathToAgent)\n",
    "        except:\n",
    "            #if an exception occurs list it and move forward\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "            continue\n",
    "        else:\n",
    "            #if no error occured append that data to the data list\n",
    "            sequenceData.append(TopOptSequence(i,forces,dof,passive,x,numIterations))\n",
    "\n",
    "    print(\"100%\\t\\t\")\n",
    "    return sequenceData\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = buildDataSet(50)\n",
    "print(len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the data output is correct\n",
    "def checkArrays(arraysOfValues):\n",
    "    correct = True\n",
    "    for i in range(1,len(arraysOfValues)):\n",
    "        a = np.equal(arraysOfValues[i-1],arraysOfValues[i]).sum()\n",
    "        numberofValues = np.prod(arraysOfValues[i-1].shape)\n",
    "        #print(a,numberofValues)\n",
    "        if(a != numberofValues):\n",
    "            print(\"iteration {} is not the same as iteration {}, {} != {}.\".format(i-1,i,a,numberofValues))\n",
    "            correct = False\n",
    "        #print(a,forceValues)\n",
    "\n",
    "    return correct\n",
    "            \n",
    "def plotIteration(input_array,output_array,finished_array):\n",
    "    numIterations = len(input_array)\n",
    "    for i in range(numIterations):\n",
    "        fig,ax = plt.subplots(1,2)\n",
    "        ax[0].imshow(input_array[i].T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[0].get_xaxis().set_visible(False)\n",
    "        ax[0].get_yaxis().set_visible(False)\n",
    "        ax[0].set_title(\"Input\")\n",
    "\n",
    "        ax[1].imshow(output_array[i].T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[1].get_xaxis().set_visible(False)\n",
    "        ax[1].get_yaxis().set_visible(False)\n",
    "        ax[1].set_title(\"Output, Finished:{}\".format(finished_array[i]))\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def checkData(indexToUse):\n",
    "    currentSum = 0\n",
    "    for sequence in Data:\n",
    "        currentSum += sequence.numIterations\n",
    "    \n",
    "    print(\"With {} problem statements there are {} sample datapoints.\".format(len(Data),currentSum))\n",
    "\n",
    "    forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array = Data[indexToUse].dispenceFirstIterationData()\n",
    "    #check forces\n",
    "    print(\"check Forces:\")\n",
    "    if(checkArrays(forces_array)):\n",
    "        print(\"\\tOk.\")\n",
    "\n",
    "    print(\"check Supports:\")\n",
    "    if(checkArrays(support_array)):\n",
    "        print(\"\\tOk.\")\n",
    "    \n",
    "    print(\"check Filled area:\")\n",
    "    if(checkArrays(filled_array)):\n",
    "        print(\"\\tOk.\")\n",
    "    \n",
    "    numIterations = Data[indexToUse].numIterations\n",
    "    print(\"Iterations:\",numIterations )\n",
    "    plotIteration(x_array,x_optimized_array,finished_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array = Data[0].dispenceData()\n",
    "\n",
    "#print(Data[0].numIterations)\n",
    "#print(len(x_array))\n",
    "checkData(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal parameters\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_m7(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.GaussianNoise(stddev=0.1)(conv_64_32)\n",
    "    conv_64_32 = layers.Dropout(rate=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.GaussianNoise(stddev=0.1)(conv_32_16)\n",
    "    conv_32_16 = layers.Dropout(rate=0.2)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.Dropout(rate=0.3)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape=conv_16_8.shape[1:]\n",
    "    shapeFlat = np.prod(newShape)\n",
    "    denseLayer = layers.Flatten()(conv_16_8)\n",
    "    denseLayer = layers.Dense(shapeFlat,activation=activation)(denseLayer)\n",
    "    denseLayer_16_8 = layers.Reshape(newShape)(denseLayer)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(denseLayer_16_8)\n",
    "    convUpscale_32_16 = layers.Dropout(rate=0.3)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.GaussianNoise(stddev=0.1)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_64_32 = layers.Dropout(rate=0.2)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_128_64 = layers.Dropout(rate=0.1)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='hard_sigmoid', name=\"x_out\")(output_resize)\n",
    "    \"\"\"\n",
    "    The hard sigmoid activation, defined as:\n",
    "        if x < -2.5: return 0\n",
    "        if x > 2.5: return 1\n",
    "        if -2.5 <= x <= 2.5: return 0.2 * x + 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])#,finishedOutput])\n",
    "\n",
    "class Model_m7(keras.Model):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model_m7, self).__init__()\n",
    "        self.model = buildModel_m7()\n",
    "        \n",
    "\n",
    "    def call(self,data,training = False):\n",
    "        #part = data['x']\n",
    "        #forces = data['forces']\n",
    "        #supports = data['supports']\n",
    "        #filled = data['filled']\n",
    "        #print(1)\n",
    "        if(training):\n",
    "            \n",
    "            out1 = self.model(data)\n",
    "            data['x'] = out1\n",
    "            \n",
    "            #print(2)\n",
    "            out2 = self.model(data)\n",
    "            data['x'] = out2\n",
    "\n",
    "            out3 = self.model(data)\n",
    "            data['x'] = out3\n",
    "        \n",
    "            out4 = self.model(data)\n",
    "            data['x'] = out4\n",
    "\n",
    "            out5 = self.model(data)\n",
    "            #print(6)\n",
    "            return out1,out2,out3,out4,out5\n",
    "        else:\n",
    "            return self.model(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_m8(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.GaussianNoise(stddev=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.GaussianNoise(stddev=0.1)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.GaussianNoise(stddev=0.1)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(conv_16_8)\n",
    "    convUpscale_32_16 = layers.GaussianNoise(stddev=0.1)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 16, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 16, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='hard_sigmoid', name=\"x_out\")(output_resize)\n",
    "    \"\"\"\n",
    "    The hard sigmoid activation, defined as:\n",
    "        if x < -2.5: return 0\n",
    "        if x > 2.5: return 1\n",
    "        if -2.5 <= x <= 2.5: return 0.2 * x + 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])#,finishedOutput])\n",
    "\n",
    "class Model_m8(keras.Model):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model_m8, self).__init__()\n",
    "        self.model = buildModel_m8()\n",
    "        \n",
    "\n",
    "    def call(self,data,training = False):\n",
    "        #part = data['x']\n",
    "        #forces = data['forces']\n",
    "        #supports = data['supports']\n",
    "        #filled = data['filled']\n",
    "        #print(1)\n",
    "        if(training):\n",
    "            \n",
    "            out1 = self.model(data)\n",
    "            data['x'] = out1\n",
    "            \n",
    "            #print(2)\n",
    "            out2 = self.model(data)\n",
    "            data['x'] = out2\n",
    "\n",
    "            out3 = self.model(data)\n",
    "            data['x'] = out3\n",
    "        \n",
    "            out4 = self.model(data)\n",
    "            data['x'] = out4\n",
    "\n",
    "            out5 = self.model(data)\n",
    "            #print(6)\n",
    "            return out1,out2,out3,out4,out5\n",
    "        else:\n",
    "            return self.model(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUpOptimizer(variant):\n",
    "    \"\"\"\n",
    "    Builds a keras optmizer based of default parameters\n",
    "    \n",
    "    Accepts:\n",
    "        1:adam\n",
    "        2:adadelta\n",
    "        3:adafactor\n",
    "        4:adagrad\n",
    "        5:adamax\n",
    "        6:ftrl\n",
    "        7:nadam\n",
    "        8:rmsprop\n",
    "    \"\"\"\n",
    "    if(variant == 1 or variant == 'adam'):\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') \n",
    "    elif(variant == 2 or variant == 'adadelta'):\n",
    "        print(\"Optimizer: AdaDelta\")\n",
    "        return keras.optimizers.experimental.Adadelta(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.95,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adadelta'\n",
    "                                                    )\n",
    "    elif(variant == 3 or variant == 'adafactor'):\n",
    "        print(\"Optimizer: AdaFactor\")\n",
    "        return keras.optimizers.experimental.Adafactor(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_2_decay=-0.8,\n",
    "                                                        epsilon_1=1e-30,\n",
    "                                                        epsilon_2=0.001,\n",
    "                                                        clip_threshold=1.0,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adafactor'\n",
    "                                                    )\n",
    "    elif(variant == 4 or variant == 'adagrad'):\n",
    "        print(\"Optimizer: AdaGrad\")\n",
    "        return keras.optimizers.experimental.Adagrad(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        initial_accumulator_value=0.1,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adagrad'\n",
    "                                                    )\n",
    "    elif(variant == 5 or variant == 'adamax'):\n",
    "        print(\"Optimizer: AdaMax\")\n",
    "        return keras.optimizers.experimental.Adamax(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_1=0.9,\n",
    "                                                        beta_2=0.999,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adamax'\n",
    "                                                    )\n",
    "    elif(variant == 6 or variant == 'ftrl'):\n",
    "        print(\"Optimizer: FTRL\")\n",
    "        return keras.optimizers.experimental.Ftrl(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    learning_rate_power=-0.5,\n",
    "                                                    initial_accumulator_value=0.1,\n",
    "                                                    l1_regularization_strength=0.0,\n",
    "                                                    l2_regularization_strength=0.0,\n",
    "                                                    l2_shrinkage_regularization_strength=0.0,\n",
    "                                                    beta=0.0,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Ftrl'\n",
    "                                                )\n",
    "    elif(variant == 7 or variant == 'nadam'):\n",
    "        print(\"Optimizer: Nadam\")\n",
    "        return keras.optimizers.experimental.Nadam(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    beta_1=0.9,\n",
    "                                                    beta_2=0.999,\n",
    "                                                    epsilon=1e-07,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Nadam'\n",
    "                                                )\n",
    "    elif(variant == 8 or variant == 'rmsprop'):\n",
    "        print(\"Optimizer: RMSprop\")\n",
    "        return keras.optimizers.experimental.RMSprop(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.9,\n",
    "                                                        momentum=0.0,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=100,\n",
    "                                                        name='RMSprop'\n",
    "                                                    )\n",
    "    else:\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel(modelNumber,optimizerVarient:int = 1):\n",
    "    if(modelNumber == 7):\n",
    "        model = Model_m7()\n",
    "        fileSaveName = \"Model_m7\"\n",
    "    elif(modelNumber == 8):\n",
    "        model = Model_m8()\n",
    "        fileSaveName = \"Model_m8\"\n",
    "    else:\n",
    "        raise Exception(\"No model identified, model {} DNE.\".format(modelNumber))\n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelPath,fileSaveName),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        try:\n",
    "            \n",
    "            model.load_weights(os.path.join(modelPath,fileSaveName))\n",
    "        except:\n",
    "            print(\"Model weights could not be loaded.\")\n",
    "        else:\n",
    "            print(\"Model weights Loaded\")\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "        print(\"Model path created\")\n",
    "\n",
    "    \n",
    "    model.compile(  optimizer=SetUpOptimizer(optimizerVarient),\n",
    "                        loss= keras.losses.BinaryCrossentropy()\n",
    "                        )\n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentModelNumber = 8 #change this one\n",
    "model,callBack = getModel(currentModelNumber)\n",
    "print()\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EditImage(image):\n",
    "\n",
    "    #noise = np.random.normal(loc=0,scale=.05,size=image.shape)\n",
    "    #return image + noise\n",
    "\n",
    "    return image#np.flip(image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawModelIteratins(num):\n",
    "    sequenceToStart:TopOptSequence = Data[num]\n",
    "    numImages = sequenceToStart.numIterations\n",
    "    imagesToShow = 5\n",
    "    #print(numImages)\n",
    "    fig,ax = plt.subplots(2,imagesToShow)\n",
    "\n",
    "    sequenceToStart.dispenceData()\n",
    "\n",
    "    nelx = 100\n",
    "    nely = 50\n",
    "    force,support,filled,x_start,x_optimized,finished = sequenceToStart.dispenceData(1)\n",
    "\n",
    "    force = np.array([force[0]])\n",
    "    force = EditImage(force)\n",
    "    support = EditImage(np.array([support[0]]))\n",
    "    filled = EditImage(np.array([filled[0]]))\n",
    "    ImageToPredict = np.array([sequenceToStart.xPhys_array[:,:,0]])\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages):\n",
    "        \n",
    "        output = model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages,end-start,(end-start)/numImages))\n",
    "    imagesToJump = numImages // imagesToShow\n",
    "\n",
    "    for i in range(0,imagesToShow-1):\n",
    "        ax[0,i].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[0,i].get_xaxis().set_visible(False)\n",
    "        ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "        #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "        ax[1,i].imshow(np.reshape(PredictedImages[i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[1,i].get_xaxis().set_visible(False)\n",
    "        ax[1,i].get_yaxis().set_visible(False)\n",
    "    ax[0,-1].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,-1].get_xaxis().set_visible(False)\n",
    "    ax[0,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,-1].imshow(np.reshape(PredictedImages[-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,-1].get_xaxis().set_visible(False)\n",
    "    ax[1,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[0,0].set_title(\"True\")\n",
    "    ax[1,0].set_title(\"Pred\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0#np.random.randint(0,len(Data_score)-1)\n",
    "print(n)\n",
    "DrawModelIteratins(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOverIterations(index,data,overIterateFactor:int=4):\n",
    "    sequenceToStart = data[index]\n",
    "    numImages = sequenceToStart.numIterations\n",
    "    imagesToShow = numImages\n",
    "    #print(numImages)\n",
    "\n",
    "    sequenceToStart.dispenceData()\n",
    "\n",
    "    nelx = 100\n",
    "    nely = 50\n",
    "    force,support,filled,x_start,x_optimized,finished = sequenceToStart.dispenceData(1)\n",
    "\n",
    "    force = np.array([force[0]])\n",
    "    support = np.array([support[0]])\n",
    "    filled = np.array([filled[0]])\n",
    "    ImageToPredict = np.array([sequenceToStart.xPhys_array[:,:,0]])\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages * overIterateFactor):\n",
    "        \n",
    "        output = model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages * overIterateFactor,end-start,(end-start)/(numImages * overIterateFactor)))\n",
    "    imagesToJump = 1\n",
    "    imageArray = []\n",
    "\n",
    "    for i,image in enumerate(PredictedImages):\n",
    "        fig,ax = plt.subplots(1,1)\n",
    "        \n",
    "        if(i == 0):\n",
    "            ax.set_title(\"Iteration: {}\".format(i))\n",
    "        else:\n",
    "            im1 = np.reshape(PredictedImages[i],(nelx*nely))\n",
    "            im2 = np.reshape(PredictedImages[i-1],(nelx*nely))\n",
    "            ax.set_title(\"Iteration: {}, Change: {:.5f}\".format(i,np.linalg.norm(im1-im2,ord=np.inf)))\n",
    "        ax.imshow(np.reshape(image,(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        img_buf = io.BytesIO()\n",
    "        plt.savefig(img_buf, format='png')\n",
    "\n",
    "        im = Image.open(img_buf)\n",
    "        imageArray.append(im)\n",
    "\n",
    "        #plt.show()\n",
    "    return imageArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "im_array = plotOverIterations(i,Data,10)\n",
    "im = im_array.pop(0)\n",
    "im.save(\"out{}.gif\".format(i),save_all=True,append_images = im_array,optimize=False,loop=0)\n",
    "im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.model.layers:\n",
    "#layer = model.model.layers[1].output\n",
    "    name = layer.output.name\n",
    "    #if('conv2d' in name):\n",
    "    print(name)\n",
    "print(len(model.model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq = Data[0]\n",
    "force,support,filled,x_start,x_optimized,finished = seq.dispenceData(1)\n",
    "\n",
    "force = np.array([force[0]])\n",
    "support = np.array([support[0]])\n",
    "filled = np.array([filled[0]])\n",
    "ImageToPredict = np.array([seq.xPhys_array[:,:,0]])\n",
    "PredictedImages = [ImageToPredict]\n",
    "\n",
    "layer_output=model.model.layers[9].output\n",
    "intermediate_model=tf.keras.models.Model(inputs=model.model.input,outputs=layer_output)\n",
    "print(intermediate_model)\n",
    "\n",
    "intermediate_prediction=intermediate_model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "\n",
    "def showModelFilters(layerNum,Seqence:TopOptSequence,iterationIdex:int=0):\n",
    "    \"\"\"\n",
    "    Show the most activated layers of the model filters as the selected image is passed through the model\n",
    "    \"\"\"\n",
    "    #cap off the index\n",
    "    iterationIdex = min(Seqence.numIterations-1,max(0,int(iterationIdex)))\n",
    "\n",
    "    seq = Data[0]\n",
    "    force,support,filled,x_start,x_optimized,finished = seq.dispenceData(1)\n",
    "\n",
    "    force = np.array([force[0]])\n",
    "    support = np.array([support[0]])\n",
    "    filled = np.array([filled[0]])\n",
    "    ImageToPredict = np.array([seq.xPhys_array[:,:,iterationIdex]])\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "    layer_output=model.model.layers[layerNum].output\n",
    "    intermediate_model=tf.keras.models.Model(inputs=model.model.input,outputs=layer_output)\n",
    "    print(intermediate_model)\n",
    "\n",
    "    intermediate_prediction=intermediate_model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled})\n",
    "    return intermediate_prediction\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotModelFilters(lNum,index):\n",
    "\n",
    "    intermediate_prediction = showModelFilters(lNum,Data[0],index)\n",
    "    #print(intermediate_prediction.shape)\n",
    "    im = np.reshape(intermediate_prediction,newshape=intermediate_prediction.shape[1:])\n",
    "    #print(im.shape)\n",
    "\n",
    "    nfilters = im.shape[-1]\n",
    "    print(\"Layer {}({}) has {} filters.\".format(model.model.layers[lNum].output.name,lNum,nfilters))\n",
    "    print(\"Shape={}\".format(im.shape))\n",
    "    #print(nfilters)\n",
    "    if(nfilters == 1):\n",
    "        fix,ax = plt.subplots(1,1)\n",
    "        \n",
    "        ax.imshow(im[:,:,0].T,norm=colors.Normalize(vmin=0))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    elif(nfilters//4 == 0):\n",
    "        fix,ax = plt.subplots(1,nfilters)\n",
    "        for j in range(nfilters):\n",
    "            ax[j].imshow(im[:,:,j].T,norm=colors.Normalize(vmin=0))\n",
    "            ax[j].get_xaxis().set_visible(False)\n",
    "            ax[j].get_yaxis().set_visible(False)\n",
    "    else:\n",
    "        for i in range(nfilters//4):\n",
    "            fix,ax = plt.subplots(1,4)\n",
    "            for j in range(4):\n",
    "                ax[j].imshow(im[:,:,4*i + j].T,norm=colors.Normalize(vmin=0))\n",
    "                ax[j].get_xaxis().set_visible(False)\n",
    "                ax[j].get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLayers = len(model.model.layers)\n",
    "firstLayer = 9\n",
    "\n",
    "for lNum in range(firstLayer,numLayers):\n",
    "    print('='*50)\n",
    "    plotModelFilters(lNum,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
