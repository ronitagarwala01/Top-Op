{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3123\n",
      "Agent1_485135\n"
     ]
    }
   ],
   "source": [
    "#overview of the data\n",
    "DATA_FILE_PATH = os.path.join(os.getcwd(),'data','100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "data_x_columns = ['forces','supports','filled','x']\n",
    "data_y_columns = ['x','finished']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data information:</h1>\n",
    "\n",
    "All the data will bes stored in a pandas data frame\n",
    "\n",
    "Three primary datasets can be retreived from the data in the folder\n",
    "<ul>\n",
    "    <li>Iterative method data</li>\n",
    "    <li>End to End data</li>\n",
    "    <li>Compliance clasification data</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackLoadCondtions(loadConditions):\n",
    "    forces = loadConditions['a']\n",
    "    free = loadConditions['b']\n",
    "    passive = loadConditions['c']\n",
    "    formating_array = loadConditions['d']\n",
    "\n",
    "    volfrac = formating_array[0]\n",
    "    nelx = int(formating_array[1])\n",
    "    nely = int(formating_array[2])\n",
    "    penal = formating_array[3]\n",
    "    rmin = formating_array[4]\n",
    "\n",
    "    #print(volfrac,nelx,nely)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin\n",
    "\n",
    "\n",
    "def unpackIteration(iteration):\n",
    "    x = iteration['a']\n",
    "    xPhys = iteration['b']\n",
    "    formating_array = iteration['c']\n",
    "\n",
    "    compliance = formating_array[0]\n",
    "    change = formating_array[1]\n",
    "    mass = formating_array[2]\n",
    "\n",
    "    #print(compliance,change,mass)\n",
    "    return x,xPhys,compliance,change,mass\n",
    "\n",
    "def getAgentData(agentPath):\n",
    "    \"\"\"\n",
    "    Given a agent file path as a input, return all the unpacked and sorted data from that agent\n",
    "    returns:\n",
    "        forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "    \"\"\"\n",
    "\n",
    "    FilesToGrab = os.listdir(agentPath)\n",
    "    numberOfIterations = len(FilesToGrab) - 1\n",
    "    iterations = []\n",
    "\n",
    "    loadConditionsExist = False\n",
    "\n",
    "\n",
    "    for fileName in FilesToGrab:\n",
    "        if('loadConditions' in fileName):\n",
    "            loadConditions = np.load(os.path.join(agentPath,fileName))\n",
    "            #print('loadCondtions Exist')\n",
    "            loadConditionsExist = True\n",
    "            \n",
    "        elif('iteration_' in fileName):\n",
    "            number_extension = fileName[len('iteration_'):]\n",
    "            extesionIndex = number_extension.find('.')\n",
    "            number = int(number_extension[:extesionIndex])\n",
    "            #print(number)\n",
    "            iterations.append([number,np.load(os.path.join(agentPath,fileName))])\n",
    "        #print(fileName)\n",
    "    \n",
    "    if(not loadConditionsExist):\n",
    "        raise Exception(\"File path {} does not hold propper data\".format(agentPath))\n",
    "\n",
    "    def sortKey(x):\n",
    "        return x[0]\n",
    "\n",
    "    iterations.sort(key=sortKey)\n",
    "    #print(iterations)\n",
    "\n",
    "    forces,free,passive,volfrac,nelx,nely,penal,rmin = unpackLoadCondtions(loadConditions)\n",
    "\n",
    "    x_array = []\n",
    "    xPhys_array = []\n",
    "    compliance_array = []\n",
    "    change_array = []\n",
    "    mass_array = []\n",
    "\n",
    "    for i in range(numberOfIterations):\n",
    "        x,xPhys,compliance,change,mass = unpackIteration(iterations[i][1])\n",
    "        x_array.append(x)\n",
    "        xPhys_array.append(xPhys)\n",
    "        compliance_array.append(compliance)\n",
    "        change_array.append(change)\n",
    "        mass_array.append(mass)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset will be the iterative model.\n",
    "\n",
    "This model will attempt to mimic the proccess of the TopOpt where a 'part' and load conditions will be inputed and then the optimal part will then be outputed. This new optimal part should in theory be able to be put back into the model untill it is fully optimized.\n",
    "\n",
    "The model data will be formated as follows:\n",
    "<h1>Inputs</h1>\n",
    "<ul>\n",
    "    <li>xphys:the part to be optimized</li>\n",
    "    <li>forces: as an image for xforces and y forces</li>\n",
    "    <li>Supports: as an image</li>\n",
    "</ul>\n",
    "\n",
    "<h1>Outputs</h1>\n",
    "<ul>\n",
    "    <li>x: the optimal part</li>\n",
    "    <li> A boolean representing if the part has been fully optimized, i.e. last iteration</li>\n",
    "</ul>\n",
    "\n",
    "The data will be built with the following factors in mind.\n",
    "<ol>\n",
    "    <li>The output x will be an image of values between 0 and 1</li>\n",
    "    <li>The boolean can be gotten using a cross entropy error and the wieght on the total accuracy will be low</li>\n",
    "    <li>Since mass will need to remain constant, we can sum the first xphys input layer and use that to normalize the output x</li>\n",
    "    <li>Forces will be an image of nelx+1 by nely+1 with two channels, supports will be the same size as forces but with one channel. xPhys will only be nelx by nely so some form of resizing may be needed</li>\n",
    "    <li>It will be important for the model to know when the part is fully optimized, thus extra data of a fully optimized part as input and itself as output will be used to enforce the idea that there is an optimal end point</li>\n",
    "    <li>A step/jump in iterations may be needed, this will make it so that instead of model predicting an iteration, it will predict 2 iterations in one go.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatIterativeModelDataSet(agentFilePath):\n",
    "    \"\"\"\n",
    "    For the iterative model data.\n",
    "    Takes the extensive output of the getAgentData function and returns the formated data needed for the iterateive model\n",
    "\n",
    "\n",
    "    Forces, passive, and free must be rebuilt as propper images and not 1D arrays\n",
    "    \"\"\"\n",
    "    forces,free,passive,_,nelx,nely,_,_,_,xPhys_array,_,_,_ = getAgentData(agentFilePath)\n",
    "    # print(\"Forces shape\",forces.shape)\n",
    "    # print(\"free shape\",free.shape)\n",
    "    # print(\"passive shape\",passive.shape)\n",
    "    # print(\"xphys shape\",xPhys_array[0].shape)\n",
    "\n",
    "\n",
    "    finalShape = (int(nelx+1),int(nely+1))\n",
    "    forces2 = forces.sum(1)\n",
    "    forces2 = np.reshape(forces2,(finalShape[0],finalShape[1],2))\n",
    "\n",
    "    d2 = np.ones(2*finalShape[0]*finalShape[1])\n",
    "    for index in free:\n",
    "        d2[index] = 0\n",
    "    d3 = np.reshape(d2,(finalShape[0],finalShape[1],2))\n",
    "    degreesOfFreedom2 = d3.sum(2)\n",
    "\n",
    "    passive2 = np.zeros((nelx*nely))\n",
    "    passive2 = np.where(passive > 0,1,0)\n",
    "    passive2 = np.reshape(passive2,(nelx,nely))\n",
    "\n",
    "\n",
    "    #reshape x_arrays as an np array\n",
    "    numberOfIterations = len(xPhys_array)\n",
    "    xPhys_np_array = np.zeros((nelx,nely,numberOfIterations))\n",
    "    for i in range(numberOfIterations):\n",
    "        xPhys_np_array[:,:,i] = np.reshape(xPhys_array[i],(nelx,nely))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return forces2,degreesOfFreedom2,passive2,xPhys_np_array,numberOfIterations\n",
    "\n",
    "def buildIterativeModelDataSet(dataPointsToGrab:int,iterationJump:int=1):\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the dataGrabed\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{}%\\t\\t\".format(int(100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            forces,dof,passive,x,numIterations = formatIterativeModelDataSet(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]]))\n",
    "        except:\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "            continue\n",
    "        else:\n",
    "            # print(\"index:\",indexList[i])\n",
    "            # print(\"Forces shape:\",forces.shape)\n",
    "            # print(\"free shape:\",dof.shape)\n",
    "            # print(\"passive shape:\",passive.shape)\n",
    "            # print(\"xphys shape:\",x.shape)\n",
    "            #print(\"Out of {} iterations.\".format(numIterations))\n",
    "            for j in range(numIterations-iterationJump):\n",
    "                dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,j]])\n",
    "                v = 0.0\n",
    "                f= 'unfinished'\n",
    "                if(j+iterationJump >= numIterations - 1):\n",
    "                    v = 1.0\n",
    "                    f = 'finished'\n",
    "                dataY.append([x[:,:,j+iterationJump],np.array([v])])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:{}\".format(j,j+iterationJump,f))\n",
    "\n",
    "            for j in range(1,min(iterationJump,numIterations)):\n",
    "                # add the last iterations(dataY has True)\n",
    "                dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,-j -1]])\n",
    "                dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:finished\".format(numIterations-j-1,numIterations-1))\n",
    "\n",
    "            # add the optimal Stoping point data, input = output\n",
    "            dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,numIterations-1]])\n",
    "            dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "\n",
    "        #print(\"Adding itter: {} -> {}:finished\".format(numIterations-1,numIterations-1))\n",
    "    print(\"100%\\t\\t\")\n",
    "    return dataX,dataY\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFirstIterationDataset(dataPointsToGrab:int):\n",
    "    \"\"\"\n",
    "    Due to the lack of learning of the model when given all the data points, this data set seeks to tech it the first iteration, \n",
    "    the model will be given the atarting iteration 0 as input and then iteration 1 and 2  as output.\n",
    "    \"\"\"\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the dataGrabed\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{}%\\t\\t\".format(int(100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            forces,dof,passive,x,numIterations = formatIterativeModelDataSet(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]]))\n",
    "        except:\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "        else:\n",
    "            #add the 0th iteration as input and the 1st and 2nd iteration as output\n",
    "            dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,0]])\n",
    "            dataY.append([x[:,:,1],np.array([0.])])\n",
    "\n",
    "            dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,0]])\n",
    "            dataY.append([x[:,:,2],np.array([0.])])\n",
    "\n",
    "        #print(\"Adding itter: {} -> {}:finished\".format(numIterations-1,numIterations-1))\n",
    "    print(\"100%\\t\\t\")\n",
    "    return dataX,dataY\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving 2000 Datapoints.\n",
      "100%\t\t\n",
      "x: 4000\n",
      "y: 4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data_x,data_y = buildIterativeModelDataSet(500,10)\n",
    "data_x,data_y = buildFirstIterationDataset(2000)\n",
    "print(\"x:\",len(data_x))\n",
    "print(\"y:\",len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 3200\n",
      "Y_train: 3200\n",
      "\n",
      "X_test: 760\n",
      "Y_test: 760\n",
      "\n",
      "X_score: 40\n",
      "Y_score: 40\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "\"\"\"\n",
    "By performing the test train split we can get a training data set and a testing dataset to get the metrics for out model\n",
    "By performing the split a second time we can get a scoring dataset that the model will never see that we can use to get out own accuracy score out of\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test  = train_test_split(data_x,data_y, test_size=0.2)\n",
    "X_test, X_score, Y_test, Y_score = train_test_split(X_test,Y_test, test_size=0.05)\n",
    "print(\"X_train: {}\\nY_train: {}\".format(len(X_train), len(Y_train)))\n",
    "print(\"\\nX_test: {}\\nY_test: {}\".format(len(X_test), len(Y_test)))\n",
    "print(\"\\nX_score: {}\\nY_score: {}\".format(len(X_score), len(Y_score)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal parameters\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m1(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    A generic image creation model\n",
    "    ['forces','supports','filled','x']\n",
    "\n",
    "    Inputs:\n",
    "        x: (100,50)\n",
    "        forces: (101,51,2)\n",
    "        supports: (101,51)\n",
    "        filled: (100,50)\n",
    "\n",
    "    Outputs:\n",
    "        x: (100,50)\n",
    "        done: bool\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(forcesInput)\n",
    "    supportConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(supportsInput)\n",
    "\n",
    "    #resize the partConv to be the same as the rest of the data\n",
    "    partConv = layers.ZeroPadding2D(padding=((1,0),(1,0)))(partConv)\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape = [x2.shape[1],x2.shape[2]]\n",
    "    x3 = layers.Flatten()(x2)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride < kernalsize\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x2)\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x4)\n",
    "    paddingNeeded = ((filledInput.shape[1]-x4.shape[1],0),(filledInput.shape[2]-x4.shape[2],0))\n",
    "\n",
    "    x4 = layers.ZeroPadding2D(padding=paddingNeeded)(x4)\n",
    "    filledAreaAddition = layers.Concatenate()([x4,filledInput])\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(5,5),padding='same',activation=activation, name=\"x_out\")(filledAreaAddition)\n",
    "\n",
    "    #output for finished part\n",
    "\n",
    "    x5 = layers.Dense(newShape[1],activation=activation)(x3)\n",
    "    x5 = layers.Dense(20,activation=activation)(x5)\n",
    "    output_finished =layers.Dense(1,activation='sigmoid', name=\"finished\")(x5)\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part,output_finished])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m2(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    A generic image creation model\n",
    "    ['forces','supports','filled','x']\n",
    "\n",
    "    Inputs:\n",
    "        x: (100,50)\n",
    "        forces: (101,51,2)\n",
    "        supports: (101,51)\n",
    "        filled: (100,50)\n",
    "\n",
    "    Outputs:\n",
    "        x: (100,50)\n",
    "        done: bool\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(forcesInput)\n",
    "    supportConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(supportsInput)\n",
    "\n",
    "    #resize the partConv to be the same as the rest of the data\n",
    "    partConv = layers.ZeroPadding2D(padding=((1,0),(1,0)))(partConv)\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    x1 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    x2 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape = [x2.shape[1],x2.shape[2]]\n",
    "    x3 = layers.Flatten()(x2)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride < kernalsize\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x2)\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x4)\n",
    "    paddingNeeded = ((filledInput.shape[1]-x4.shape[1],0),(filledInput.shape[2]-x4.shape[2],0))\n",
    "\n",
    "    x4 = layers.ZeroPadding2D(padding=paddingNeeded)(x4)\n",
    "    filledAreaAddition = layers.Concatenate()([x4,filledInput])\n",
    "    filledAreaAddition = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(filledAreaAddition)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(3,3),padding='same',activation=activation, name=\"x_out\")(filledAreaAddition)\n",
    "\n",
    "    #output for finished part\n",
    "\n",
    "    x5 = layers.Dense(20,activation=activation)(x3)\n",
    "    x5 = layers.Dense(20,activation=activation)(x5)\n",
    "    output_finished =layers.Dense(1,activation='sigmoid', name=\"finished\")(x5)\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part,output_finished])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUpOptimizer(variant):\n",
    "    \"\"\"\n",
    "    Builds a keras optmizer based of default parameters\n",
    "    \n",
    "    Accepts:\n",
    "        1:adam\n",
    "        2:adadelta\n",
    "        3:adafactor\n",
    "        4:adagrad\n",
    "        5:adamax\n",
    "        6:ftrl\n",
    "        7:nadam\n",
    "        8:rmsprop\n",
    "    \"\"\"\n",
    "    if(variant == 1 or variant == 'adam'):\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') \n",
    "    elif(variant == 2 or variant == 'adadelta'):\n",
    "        print(\"Optimizer: AdaDelta\")\n",
    "        return keras.optimizers.experimental.Adadelta(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.95,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adadelta'\n",
    "                                                    )\n",
    "    elif(variant == 3 or variant == 'adafactor'):\n",
    "        print(\"Optimizer: AdaFactor\")\n",
    "        return keras.optimizers.experimental.Adafactor(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_2_decay=-0.8,\n",
    "                                                        epsilon_1=1e-30,\n",
    "                                                        epsilon_2=0.001,\n",
    "                                                        clip_threshold=1.0,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adafactor'\n",
    "                                                    )\n",
    "    elif(variant == 4 or variant == 'adagrad'):\n",
    "        print(\"Optimizer: AdaGrad\")\n",
    "        return keras.optimizers.experimental.Adagrad(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        initial_accumulator_value=0.1,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adagrad'\n",
    "                                                    )\n",
    "    elif(variant == 5 or variant == 'adamax'):\n",
    "        print(\"Optimizer: AdaMax\")\n",
    "        return keras.optimizers.experimental.Adamax(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_1=0.9,\n",
    "                                                        beta_2=0.999,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adamax'\n",
    "                                                    )\n",
    "    elif(variant == 6 or variant == 'ftrl'):\n",
    "        print(\"Optimizer: FTRL\")\n",
    "        return keras.optimizers.experimental.Ftrl(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    learning_rate_power=-0.5,\n",
    "                                                    initial_accumulator_value=0.1,\n",
    "                                                    l1_regularization_strength=0.0,\n",
    "                                                    l2_regularization_strength=0.0,\n",
    "                                                    l2_shrinkage_regularization_strength=0.0,\n",
    "                                                    beta=0.0,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Ftrl'\n",
    "                                                )\n",
    "    elif(variant == 7 or variant == 'nadam'):\n",
    "        print(\"Optimizer: Nadam\")\n",
    "        return keras.optimizers.experimental.Nadam(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    beta_1=0.9,\n",
    "                                                    beta_2=0.999,\n",
    "                                                    epsilon=1e-07,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Nadam'\n",
    "                                                )\n",
    "    elif(variant == 8 or variant == 'rmsprop'):\n",
    "        print(\"Optimizer: RMSprop\")\n",
    "        return keras.optimizers.experimental.RMSprop(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.9,\n",
    "                                                        momentum=0.0,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=100,\n",
    "                                                        name='RMSprop'\n",
    "                                                    )\n",
    "    else:\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel(modelNumber,optimizerVarient:int = 1):\n",
    "    if(modelNumber == 1):\n",
    "        model = model_m1()\n",
    "        fileSaveName = \"Model_m1\"\n",
    "        \n",
    "    elif(modelNumber == 2):\n",
    "        model = model_m2()\n",
    "        fileSaveName = \"Model_m2\"\n",
    "    else:\n",
    "        raise Exception(\"No model identified, model {} DNE.\".format(modelNumber))\n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelPath,fileSaveName),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        model.load_weights(os.path.join(modelPath,fileSaveName))\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "\n",
    "    if(modelNumber == 1 or modelNumber == 2):\n",
    "        model.compile(optimizer=SetUpOptimizer(optimizerVarient),\n",
    "                        loss={\n",
    "                            'x_out':keras.losses.MeanSquaredLogarithmicError(), #logrithmic error for the 0-1 output of the image\n",
    "                            'finished':keras.losses.BinaryCrossentropy(from_logits=True) #binary entropy error for the bool output\n",
    "                        },\n",
    "                        loss_weights={'x_out':1.0,'finished':0.01})\n",
    "    \n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x (InputLayer)                 [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 100, 50, 5)   50          ['x[0][0]']                      \n",
      "                                                                                                  \n",
      " forces (InputLayer)            [(None, 101, 51, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " supports (InputLayer)          [(None, 101, 51, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 101, 51, 5)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 101, 51, 5)   95          ['forces[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 101, 51, 5)   50          ['supports[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 101, 51, 15)  0           ['zero_padding2d[0][0]',         \n",
      "                                                                  'conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 101, 51, 64)  8704        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 101, 51, 64)  36928       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 101, 51, 64)  36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 50, 25, 64)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 50, 25, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 50, 25, 32)   18464       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 50, 25, 16)   4624        ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 25, 12, 16)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 50, 24, 16)  2320        ['max_pooling2d_1[0][0]']        \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 100, 48, 16)  2320       ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 100, 50, 16)  0          ['conv2d_transpose_1[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " filled (InputLayer)            [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4800)         0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 100, 50, 17)  0           ['zero_padding2d_1[0][0]',       \n",
      "                                                                  'filled[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 20)           96020       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 100, 50, 32)  4928        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           420         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " x_out (Conv2D)                 (None, 100, 50, 1)   289         ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " finished (Dense)               (None, 1)            21          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 249,089\n",
      "Trainable params: 249,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,callBack = getModel(2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    }
   ],
   "source": [
    "#data spliting\n",
    "def splitX(data):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    for forces,support,filled,x in data:\n",
    "        forces_array.append(forces)\n",
    "        support_array.append(support)\n",
    "        filled_array.append(filled)\n",
    "        x_array.append(x)\n",
    "    return x_array,filled_array,forces_array, support_array,  \n",
    "\n",
    "def splitY(data):\n",
    "    x_array = []\n",
    "    finished_array = []\n",
    "    for x,finished in data:\n",
    "        x_array.append(x)\n",
    "        finished_array.append(finished)\n",
    "    return x_array,finished_array\n",
    "\n",
    "X_train_part, X_train_filled, X_train_forces, X_train_supports = splitX(X_train)\n",
    "Y_train_x, Y_train_finished = splitY(Y_train)\n",
    "X_test_part, X_test_filled, X_test_forces, X_test_supports = splitX(X_test)\n",
    "Y_test_x, Y_test_finished = splitY(Y_test)\n",
    "\n",
    "\n",
    "X_train_part = np.array(X_train_part)\n",
    "X_train_forces = np.array(X_train_forces)\n",
    "X_train_supports = np.array(X_train_supports)\n",
    "X_train_filled = np.array(X_train_filled)\n",
    "Y_train_x = np.array(Y_train_x)\n",
    "Y_train_finished = np.array(Y_train_finished)\n",
    "\n",
    "X_test_part = np.array(X_test_part)\n",
    "X_test_forces = np.array(X_test_forces)\n",
    "X_test_supports = np.array(X_test_supports)\n",
    "X_test_filled = np.array(X_test_filled)\n",
    "Y_test_x = np.array(Y_test_x)\n",
    "Y_test_finished = np.array(Y_test_finished)\n",
    "\n",
    "print(len(X_train_part))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "BatchSize = 32 # default tensorflow batchsize\n",
    "numEpochs = 10\n",
    "BatchesPerEpoch = len(X_train_part) // (BatchSize*numEpochs)\n",
    "BatchesPerEpoch = BatchesPerEpoch\n",
    "\n",
    "print(BatchesPerEpoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend.py:5674: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.0324 - x_out_loss: 0.0322 - finished_loss: 0.0251\n",
      "Epoch 1: saving model to c:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\MachineLerning\\ModelSave\\Model_m2\\Model_m2\n",
      "100/100 [==============================] - 573s 6s/step - loss: 0.0324 - x_out_loss: 0.0322 - finished_loss: 0.0251 - val_loss: 0.0171 - val_x_out_loss: 0.0171 - val_finished_loss: 2.1140e-07\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0162 - x_out_loss: 0.0162 - finished_loss: 3.6735e-07\n",
      "Epoch 2: saving model to c:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\MachineLerning\\ModelSave\\Model_m2\\Model_m2\n",
      "100/100 [==============================] - 539s 5s/step - loss: 0.0162 - x_out_loss: 0.0162 - finished_loss: 3.6735e-07 - val_loss: 0.0153 - val_x_out_loss: 0.0153 - val_finished_loss: 4.7353e-07\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0148 - x_out_loss: 0.0148 - finished_loss: 2.3343e-06\n",
      "Epoch 3: saving model to c:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\MachineLerning\\ModelSave\\Model_m2\\Model_m2\n",
      "100/100 [==============================] - 539s 5s/step - loss: 0.0148 - x_out_loss: 0.0148 - finished_loss: 2.3343e-06 - val_loss: 0.0146 - val_x_out_loss: 0.0146 - val_finished_loss: 3.4252e-06\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0139 - x_out_loss: 0.0139 - finished_loss: 2.4969e-06\n",
      "Epoch 4: saving model to c:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\MachineLerning\\ModelSave\\Model_m2\\Model_m2\n",
      "100/100 [==============================] - 537s 5s/step - loss: 0.0139 - x_out_loss: 0.0139 - finished_loss: 2.4969e-06 - val_loss: 0.0136 - val_x_out_loss: 0.0136 - val_finished_loss: 1.4633e-06\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0136 - x_out_loss: 0.0136 - finished_loss: 2.9408e-06\n",
      "Epoch 5: saving model to c:\\Users\\Nate\\Documents\\GitHub\\SOundstuff\\Top-Op\\MachineLerning\\ModelSave\\Model_m2\\Model_m2\n",
      "100/100 [==============================] - 531s 5s/step - loss: 0.0136 - x_out_loss: 0.0136 - finished_loss: 2.9408e-06 - val_loss: 0.0130 - val_x_out_loss: 0.0130 - val_finished_loss: 3.1307e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "        {'x':X_train_part,'forces':X_train_forces,'supports':X_train_supports,'filled':X_train_filled},\n",
    "        {'x_out':Y_train_x,'finished':Y_train_finished},\n",
    "        batch_size=None,#BatchSize,\n",
    "        epochs=numEpochs,\n",
    "        shuffle=True,\n",
    "        validation_data=(\n",
    "                        {'x':X_test_part,'forces':X_test_forces,'supports':X_test_supports,'filled':X_test_filled},\n",
    "                        {'x_out':Y_test_x,'finished':Y_test_finished}),\n",
    "        callbacks=[callBack],\n",
    "        steps_per_epoch = None)#BatchesPerEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 489ms/step\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#build some statistics on the data\n",
    "X_score_part, X_score_filled, X_score_forces, X_score_supports = splitX(X_score)\n",
    "Y_score_x, Y_score_finished = splitY(Y_score)\n",
    "\n",
    "X_score_part = np.array(X_score_part)\n",
    "X_score_forces = np.array(X_score_forces)\n",
    "X_score_supports = np.array(X_score_supports)\n",
    "X_score_filled = np.array(X_score_filled)\n",
    "Y_score_x = np.array(Y_score_x)\n",
    "Y_score_finished = np.array(Y_score_finished)\n",
    "\n",
    "output = model.predict({'x':X_score_part,'forces':X_score_forces,'supports':X_score_supports,'filled':X_score_filled})\n",
    "Y_pred_part = output[0]\n",
    "Y_pred_finished = output[1]\n",
    "print(len(Y_pred_part))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalBit(a):\n",
    "    if(a[0] > 0):\n",
    "        return 'fin'\n",
    "    else:\n",
    "        return 'it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the true and predicted Values\n",
    "ncol = 4\n",
    "nelx = 100\n",
    "nely = 50\n",
    "\n",
    "fig,ax = plt.subplots(3,ncol)\n",
    "\n",
    "rnd = np.arange(len(X_score_part),dtype='int32')\n",
    "np.random.shuffle(rnd)\n",
    "\n",
    "for i in range(ncol):\n",
    "    ax[0,i].set_title(\"original\")\n",
    "    ax[0,i].imshow(np.reshape(X_score_part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,i].get_xaxis().set_visible(False)\n",
    "    ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[1,i].set_title(\"True\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,i].imshow(np.reshape(Y_score_x[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,i].get_xaxis().set_visible(False)\n",
    "    ax[1,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[2,i].set_title(\"Predicted\")#:{}\".format(finalBit(Y_pred_finished[rnd[i]])))\n",
    "    ax[2,i].imshow(np.reshape(Y_pred_part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[2,i].get_xaxis().set_visible(False)\n",
    "    ax[2,i].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thoughts</h1>\n",
    "\n",
    "The model is not learning anything. It is applying a blur filter to what it is given and adding the circles around that. I think that a new aproach it needed to fully train the model.\n",
    "\n",
    "In addition to various different loss functions and optimizers that could be changed, and can easily be changed. I think that training the model on only the first itteration of each data point may be a good indicator of how things should end up.\n",
    "\n",
    "By looking only at the first itteration, the model learn how to form shapes between the given points instead of just adding a blur. The first iteration being the solid volume filled with the volfrac amount and the optimal part from that being the first signs of a shape forming\n",
    "\n",
    "Since the x data is a float between 0 and 1 I think that it may be nessesary to cosider a different loss function. logrithmic error is good for this type of loss but there may be a better loss function for the part data.\n",
    "\n",
    "Looking at the model outputs, we need to introduce the circles eariler as well as ensure taht the convolutions allow for a full grasp of what the part is. As much as I didn't want to a fully dense or perhaps a few fully dense layers are needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
