{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3123\n",
      "Agent1_485135\n"
     ]
    }
   ],
   "source": [
    "#overview of the data\n",
    "DATA_FILE_PATH = os.path.join(os.getcwd(),'data','100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "data_x_columns = ['forces','supports','filled','x']\n",
    "data_y_columns = ['x','finished']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data information:</h1>\n",
    "\n",
    "All the data will bes stored in a pandas data frame\n",
    "\n",
    "Three primary datasets can be retreived from the data in the folder\n",
    "<ul>\n",
    "    <li>Iterative method data</li>\n",
    "    <li>End to End data</li>\n",
    "    <li>Compliance clasification data</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackLoadCondtions(loadConditions):\n",
    "    forces = loadConditions['a']\n",
    "    free = loadConditions['b']\n",
    "    passive = loadConditions['c']\n",
    "    formating_array = loadConditions['d']\n",
    "\n",
    "    volfrac = formating_array[0]\n",
    "    nelx = int(formating_array[1])\n",
    "    nely = int(formating_array[2])\n",
    "    penal = formating_array[3]\n",
    "    rmin = formating_array[4]\n",
    "\n",
    "    #print(volfrac,nelx,nely)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin\n",
    "\n",
    "\n",
    "def unpackIteration(iteration):\n",
    "    x = iteration['a']\n",
    "    xPhys = iteration['b']\n",
    "    formating_array = iteration['c']\n",
    "\n",
    "    compliance = formating_array[0]\n",
    "    change = formating_array[1]\n",
    "    mass = formating_array[2]\n",
    "\n",
    "    #print(compliance,change,mass)\n",
    "    return x,xPhys,compliance,change,mass\n",
    "\n",
    "def getAgentData(agentPath):\n",
    "    \"\"\"\n",
    "    Given a agent file path as a input, return all the unpacked and sorted data from that agent\n",
    "    returns:\n",
    "        forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "    \"\"\"\n",
    "\n",
    "    FilesToGrab = os.listdir(agentPath)\n",
    "    numberOfIterations = len(FilesToGrab) - 1\n",
    "    iterations = []\n",
    "\n",
    "    loadConditionsExist = False\n",
    "\n",
    "\n",
    "    for fileName in FilesToGrab:\n",
    "        if('loadConditions' in fileName):\n",
    "            loadConditions = np.load(os.path.join(agentPath,fileName))\n",
    "            #print('loadCondtions Exist')\n",
    "            loadConditionsExist = True\n",
    "            \n",
    "        elif('iteration_' in fileName):\n",
    "            number_extension = fileName[len('iteration_'):]\n",
    "            extesionIndex = number_extension.find('.')\n",
    "            number = int(number_extension[:extesionIndex])\n",
    "            #print(number)\n",
    "            iterations.append([number,np.load(os.path.join(agentPath,fileName))])\n",
    "        #print(fileName)\n",
    "    \n",
    "    if(not loadConditionsExist):\n",
    "        raise Exception(\"File path {} does not hold propper data\".format(agentPath))\n",
    "\n",
    "    def sortKey(x):\n",
    "        return x[0]\n",
    "\n",
    "    iterations.sort(key=sortKey)\n",
    "    #print(iterations)\n",
    "\n",
    "    forces,free,passive,volfrac,nelx,nely,penal,rmin = unpackLoadCondtions(loadConditions)\n",
    "\n",
    "    x_array = []\n",
    "    xPhys_array = []\n",
    "    compliance_array = []\n",
    "    change_array = []\n",
    "    mass_array = []\n",
    "\n",
    "    for i in range(numberOfIterations):\n",
    "        x,xPhys,compliance,change,mass = unpackIteration(iterations[i][1])\n",
    "        x_array.append(x)\n",
    "        xPhys_array.append(xPhys)\n",
    "        compliance_array.append(compliance)\n",
    "        change_array.append(change)\n",
    "        mass_array.append(mass)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset will be the iterative model.\n",
    "\n",
    "This model will attempt to mimic the proccess of the TopOpt where a 'part' and load conditions will be inputed and then the optimal part will then be outputed. This new optimal part should in theory be able to be put back into the model untill it is fully optimized.\n",
    "\n",
    "The model data will be formated as follows:\n",
    "<h1>Inputs</h1>\n",
    "<ul>\n",
    "    <li>xphys:the part to be optimized</li>\n",
    "    <li>forces: as an image for xforces and y forces</li>\n",
    "    <li>Supports: as an image</li>\n",
    "</ul>\n",
    "\n",
    "<h1>Outputs</h1>\n",
    "<ul>\n",
    "    <li>x: the optimal part</li>\n",
    "    <li> A boolean representing if the part has been fully optimized, i.e. last iteration</li>\n",
    "</ul>\n",
    "\n",
    "The data will be built with the following factors in mind.\n",
    "<ol>\n",
    "    <li>The output x will be an image of values between 0 and 1</li>\n",
    "    <li>The boolean can be gotten using a cross entropy error and the wieght on the total accuracy will be low</li>\n",
    "    <li>Since mass will need to remain constant, we can sum the first xphys input layer and use that to normalize the output x</li>\n",
    "    <li>Forces will be an image of nelx+1 by nely+1 with two channels, supports will be the same size as forces but with one channel. xPhys will only be nelx by nely so some form of resizing may be needed</li>\n",
    "    <li>It will be important for the model to know when the part is fully optimized, thus extra data of a fully optimized part as input and itself as output will be used to enforce the idea that there is an optimal end point</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (41, 4)\n",
      "y: (41, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:85: FutureWarning: Could not cast to float32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n"
     ]
    }
   ],
   "source": [
    "def formatIterativeModelDataSet(agentFilePath):\n",
    "    \"\"\"\n",
    "    For the iterative model data.\n",
    "    Takes the extensive output of the getAgentData function and returns the formated data needed for the iterateive model\n",
    "\n",
    "\n",
    "    Forces, passive, and free must be rebuilt as propper images and not 1D arrays\n",
    "    \"\"\"\n",
    "    forces,free,passive,_,nelx,nely,_,_,_,xPhys_array,_,_,_ = getAgentData(agentFilePath)\n",
    "    # print(\"Forces shape\",forces.shape)\n",
    "    # print(\"free shape\",free.shape)\n",
    "    # print(\"passive shape\",passive.shape)\n",
    "    # print(\"xphys shape\",xPhys_array[0].shape)\n",
    "\n",
    "\n",
    "    finalShape = (int(nelx+1),int(nely+1))\n",
    "    forces2 = forces.sum(1)\n",
    "    forces2 = np.reshape(forces2,(finalShape[0],finalShape[1],2))\n",
    "\n",
    "    d2 = np.ones(2*finalShape[0]*finalShape[1])\n",
    "    for index in free:\n",
    "        d2[index] = 0\n",
    "    d3 = np.reshape(d2,(finalShape[0],finalShape[1],2))\n",
    "    degreesOfFreedom2 = d3.sum(2)\n",
    "\n",
    "    passive2 = np.zeros((nelx*nely))\n",
    "    passive2 = np.where(passive > 0,1,0)\n",
    "    passive2 = np.reshape(passive2,(nelx,nely))\n",
    "\n",
    "\n",
    "    #reshape x_arrays as an np array\n",
    "    numberOfIterations = len(xPhys_array)\n",
    "    xPhys_np_array = np.zeros((nelx,nely,numberOfIterations))\n",
    "    for i in range(numberOfIterations):\n",
    "        xPhys_np_array[:,:,i] = np.reshape(xPhys_array[i],(nelx,nely))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return forces2,degreesOfFreedom2,passive2,xPhys_np_array,numberOfIterations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def buildIterativeModelDataSet(dataPointsToGrab:int):\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the dataGrabed\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "\n",
    "        forces,dof,passive,x,numIterations = formatIterativeModelDataSet(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]]))\n",
    "        # print(\"index:\",indexList[i])\n",
    "        # print(\"Forces shape:\",forces.shape)\n",
    "        # print(\"free shape:\",dof.shape)\n",
    "        # print(\"passive shape:\",passive.shape)\n",
    "        # print(\"xphys shape:\",x.shape)\n",
    "        \n",
    "        for j in range(numIterations-1):\n",
    "            dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,j]])\n",
    "            dataY.append([x[:,:,j+1],np.array([0.])])\n",
    "\n",
    "        # add the last iterations(dataY has True)\n",
    "        dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,numIterations-2]])\n",
    "        dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "\n",
    "        # add the optimal Stoping point data, input = output\n",
    "        dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,numIterations-1]])\n",
    "        dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "    data_x = pd.DataFrame(dataX,columns=data_x_columns)\n",
    "    data_y = pd.DataFrame(dataY,columns=data_y_columns)\n",
    "\n",
    "    return data_x,data_y\n",
    "        \n",
    "\n",
    "data_x,data_y = buildIterativeModelDataSet(1)\n",
    "print(\"x:\",data_x.shape)\n",
    "print(\"y:\",data_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forces      object\n",
      "supports    object\n",
      "filled      object\n",
      "x           object\n",
      "dtype: object\n",
      "x            object\n",
      "finished    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_x.dtypes)\n",
    "print(data_y.dtypes)\n",
    "#data_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 16\n",
      "Y_train: 16\n",
      "\n",
      "X_test: 3\n",
      "Y_test: 3\n",
      "\n",
      "X_score: 1\n",
      "Y_score: 1\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "\"\"\"\n",
    "By performing the test train split we can get a training data set and a testing dataset to get the metrics for out model\n",
    "By performing the split a second time we can get a scoring dataset that the model will never see that we can use to get out own accuracy score out of\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test  = train_test_split(data_x,data_y, test_size=0.2)\n",
    "X_test, X_score, Y_test, Y_score = train_test_split(X_test,Y_test, test_size=0.1)\n",
    "print(\"X_train: {}\\nY_train: {}\".format(len(X_train), len(Y_train)))\n",
    "print(\"\\nX_test: {}\\nY_test: {}\".format(len(X_test), len(Y_test)))\n",
    "print(\"\\nX_score: {}\\nY_score: {}\".format(len(X_score), len(Y_score)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal parameters\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m1(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    A generic image creation model\n",
    "    ['forces','supports','filled','x']\n",
    "\n",
    "    Inputs:\n",
    "        x: (100,50)\n",
    "        forces: (101,51,2)\n",
    "        supports: (101,51)\n",
    "        filled: (100,50)\n",
    "\n",
    "    Outputs:\n",
    "        x: (100,50)\n",
    "        done: bool\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(forcesInput)\n",
    "    supportConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(supportsInput)\n",
    "\n",
    "    #resize the partConv to be the same as the rest of the data\n",
    "    partConv = layers.ZeroPadding2D(padding=((1,0),(1,0)))(partConv)\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape = [x2.shape[1],x2.shape[2]]\n",
    "    x3 = layers.Flatten()(x2)\n",
    "    #x_flat = layers.Dense(newShape[0]*newShape[1],activation=activation)(x3)\n",
    "    #x4 = layers.Reshape(newShape)(x_flat)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride < kernalsize\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x2)\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x4)\n",
    "\n",
    "    paddingNeeded = ((filledInput.shape[1]-x4.shape[1],0),(filledInput.shape[2]-x4.shape[2],0))\n",
    "\n",
    "    x4 = layers.ZeroPadding2D(padding=paddingNeeded)(x4)\n",
    "\n",
    "\n",
    "    filledAreaAddition = layers.Concatenate()([x4,filledInput])\n",
    "\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(5,5),padding='same',activation=activation)(filledAreaAddition)\n",
    "\n",
    "    #output for finished part\n",
    "\n",
    "    x5 = layers.Dense(newShape[1],activation=activation)(x3)\n",
    "    x5 = layers.Dense(20,activation=activation)(x5)\n",
    "    output_finished =layers.Dense(1,activation=activation)(x5)\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part,output_finished])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUpOptimizer(variant):\n",
    "    \"\"\"\n",
    "    Builds a keras optmizer based of default parameters\n",
    "    \n",
    "    Accepts:\n",
    "        1:adam\n",
    "        2:adadelta\n",
    "        3:adafactor\n",
    "        4:adagrad\n",
    "        5:adamax\n",
    "        6:ftrl\n",
    "        7:nadam\n",
    "        8:rmsprop\n",
    "    \"\"\"\n",
    "    if(variant == 1 or variant == 'adam'):\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') \n",
    "    elif(variant == 2 or variant == 'adadelta'):\n",
    "        return keras.optimizers.experimental.Adadelta(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.95,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adadelta'\n",
    "                                                    )\n",
    "    elif(variant == 3 or variant == 'adafactor'):\n",
    "        return keras.optimizers.experimental.Adafactor(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_2_decay=-0.8,\n",
    "                                                        epsilon_1=1e-30,\n",
    "                                                        epsilon_2=0.001,\n",
    "                                                        clip_threshold=1.0,\n",
    "                                                        relative_step=True,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adafactor'\n",
    "                                                    )\n",
    "    elif(variant == 4 or variant == 'adagrad'):\n",
    "        return keras.optimizers.experimental.Adagrad(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        initial_accumulator_value=0.1,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adagrad'\n",
    "                                                    )\n",
    "    elif(variant == 5 or variant == 'adamax'):\n",
    "        return keras.optimizers.experimental.Adamax(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_1=0.9,\n",
    "                                                        beta_2=0.999,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adamax'\n",
    "                                                    )\n",
    "    elif(variant == 6 or variant == 'ftrl'):\n",
    "        return keras.optimizers.experimental.Ftrl(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    learning_rate_power=-0.5,\n",
    "                                                    initial_accumulator_value=0.1,\n",
    "                                                    l1_regularization_strength=0.0,\n",
    "                                                    l2_regularization_strength=0.0,\n",
    "                                                    l2_shrinkage_regularization_strength=0.0,\n",
    "                                                    beta=0.0,\n",
    "                                                    weight_decay=None,\n",
    "                                                    clipnorm=None,\n",
    "                                                    clipvalue=None,\n",
    "                                                    global_clipnorm=None,\n",
    "                                                    use_ema=False,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    ema_overwrite_frequency=None,\n",
    "                                                    jit_compile=True,\n",
    "                                                    name='Ftrl'\n",
    "                                                )\n",
    "    elif(variant == 7 or variant == 'nadam'):\n",
    "        return keras.optimizers.experimental.Nadam(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    beta_1=0.9,\n",
    "                                                    beta_2=0.999,\n",
    "                                                    epsilon=1e-07,\n",
    "                                                    weight_decay=None,\n",
    "                                                    clipnorm=None,\n",
    "                                                    clipvalue=None,\n",
    "                                                    global_clipnorm=None,\n",
    "                                                    use_ema=False,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    ema_overwrite_frequency=None,\n",
    "                                                    jit_compile=True,\n",
    "                                                    name='Nadam'\n",
    "                                                )\n",
    "    elif(variant == 8 or variant == 'rmsprop'):\n",
    "        return keras.optimizers.experimental.RMSprop(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.9,\n",
    "                                                        momentum=0.0,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        centered=False,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=100,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='RMSprop'\n",
    "                                                    )\n",
    "    else:\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel(modelNumber):\n",
    "    if(modelNumber == 1):\n",
    "        model = model_m1()\n",
    "        fileSaveName = \"Model_m1\"\n",
    "    else:\n",
    "        raise Exception(\"No model identified, model {} DNE.\".format(modelNumber))\n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=str(modelPath),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        model.load_weights(modelPath)\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "\n",
    "    if(modelNumber == 1):\n",
    "        model.compile(optimizer=SetUpOptimizer(1),\n",
    "                        loss=[\n",
    "                            keras.losses.MeanSquaredLogarithmicError(), #logrithmic error for the 0-1 output of the image\n",
    "                            keras.losses.BinaryCrossentropy(from_logits=True) #binary entropy error for the bool output\n",
    "                        ],\n",
    "                        loss_weights=[1.0, 0.2])\n",
    "    \n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x (InputLayer)                 [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 100, 50, 5)   50          ['x[0][0]']                      \n",
      "                                                                                                  \n",
      " forces (InputLayer)            [(None, 101, 51, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " supports (InputLayer)          [(None, 101, 51, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPadding  (None, 101, 51, 5)  0           ['conv2d_83[0][0]']              \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 101, 51, 5)   95          ['forces[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 101, 51, 5)   50          ['supports[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 101, 51, 15)  0           ['zero_padding2d_17[0][0]',      \n",
      "                                                                  'conv2d_84[0][0]',              \n",
      "                                                                  'conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 101, 51, 32)  4352        ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 101, 51, 32)  9248        ['conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooling2D  (None, 50, 25, 32)  0           ['conv2d_87[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 50, 25, 32)   9248        ['max_pooling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 50, 25, 32)   9248        ['conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 50, 25, 16)   4624        ['conv2d_89[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooling2D  (None, 25, 12, 16)  0           ['conv2d_90[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_15 (Conv2DTra  (None, 50, 24, 16)  2320        ['max_pooling2d_17[0][0]']       \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2DTra  (None, 100, 48, 16)  2320       ['conv2d_transpose_15[0][0]']    \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 4800)         0           ['max_pooling2d_17[0][0]']       \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 100, 50, 16)  0          ['conv2d_transpose_16[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " filled (InputLayer)            [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 12)           57612       ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 100, 50, 17)  0           ['zero_padding2d_18[0][0]',      \n",
      "                                                                  'filled[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 20)           260         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 100, 50, 1)   426         ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1)            21          ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 99,874\n",
      "Trainable params: 99,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,callBack = getModel(1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.]), array([0.]), array([0.])], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data spliting\n",
    "#data_x_columns = ['forces','supports','filled','x']\n",
    "#data_y_columns = ['x','finished']\n",
    "\n",
    "np.array(Y_test['finished'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14656/1053850741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[1;34m'forces'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forces'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'supports'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'supports'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'filled'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filled'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 {'x':Y_test['x'],'finished':Y_test['finished']}),\n\u001b[1;32m----> 9\u001b[1;33m         callbacks=[callBack])\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Nate\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "        {'forces':X_train['forces'],'supports':X_train['supports'],'filled':X_train['filled'],'x':X_train['x']},\n",
    "        {'x':Y_train['x'],'finished':Y_train['finished']},\n",
    "        epochs=1,\n",
    "        shuffle=True,\n",
    "        validation_data=(\n",
    "                {'forces':X_test['forces'],'supports':X_test['supports'],'filled':X_test['filled'],'x':X_test['x']},\n",
    "                {'x':Y_test['x'],'finished':Y_test['finished']}),\n",
    "        callbacks=[callBack])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
