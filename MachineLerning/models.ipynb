{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview of the data\n",
    "DATA_FILE_PATH = os.path.join(os.getcwd(),'data','100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "data_x_columns = ['forces','supports','filled','x']\n",
    "data_y_columns = ['x','finished']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data information:</h1>\n",
    "\n",
    "All the data will bes stored in a pandas data frame\n",
    "\n",
    "Three primary datasets can be retreived from the data in the folder\n",
    "<ul>\n",
    "    <li>Iterative method data</li>\n",
    "    <li>End to End data</li>\n",
    "    <li>Compliance clasification data</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackLoadCondtions(loadConditions):\n",
    "    forces = loadConditions['a']\n",
    "    free = loadConditions['b']\n",
    "    passive = loadConditions['c']\n",
    "    formating_array = loadConditions['d']\n",
    "\n",
    "    volfrac = formating_array[0]\n",
    "    nelx = int(formating_array[1])\n",
    "    nely = int(formating_array[2])\n",
    "    penal = formating_array[3]\n",
    "    rmin = formating_array[4]\n",
    "\n",
    "    #print(volfrac,nelx,nely)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin\n",
    "\n",
    "\n",
    "def unpackIteration(iteration):\n",
    "    x = iteration['a']\n",
    "    xPhys = iteration['b']\n",
    "    formating_array = iteration['c']\n",
    "\n",
    "    compliance = formating_array[0]\n",
    "    change = formating_array[1]\n",
    "    mass = formating_array[2]\n",
    "\n",
    "    #print(compliance,change,mass)\n",
    "    return x,xPhys,compliance,change,mass\n",
    "\n",
    "def getAgentData(agentPath):\n",
    "    \"\"\"\n",
    "    Given a agent file path as a input, return all the unpacked and sorted data from that agent\n",
    "    returns:\n",
    "        forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "    \"\"\"\n",
    "\n",
    "    FilesToGrab = os.listdir(agentPath)\n",
    "    numberOfIterations = len(FilesToGrab) - 1\n",
    "    iterations = []\n",
    "\n",
    "    loadConditionsExist = False\n",
    "\n",
    "\n",
    "    for fileName in FilesToGrab:\n",
    "        if('loadConditions' in fileName):\n",
    "            loadConditions = np.load(os.path.join(agentPath,fileName))\n",
    "            #print('loadCondtions Exist')\n",
    "            loadConditionsExist = True\n",
    "            \n",
    "        elif('iteration_' in fileName):\n",
    "            number_extension = fileName[len('iteration_'):]\n",
    "            extesionIndex = number_extension.find('.')\n",
    "            number = int(number_extension[:extesionIndex])\n",
    "            #print(number)\n",
    "            iterations.append([number,np.load(os.path.join(agentPath,fileName))])\n",
    "        #print(fileName)\n",
    "    \n",
    "    if(not loadConditionsExist):\n",
    "        raise Exception(\"File path {} does not hold propper data\".format(agentPath))\n",
    "\n",
    "    def sortKey(x):\n",
    "        return x[0]\n",
    "\n",
    "    iterations.sort(key=sortKey)\n",
    "    #print(iterations)\n",
    "\n",
    "    forces,free,passive,volfrac,nelx,nely,penal,rmin = unpackLoadCondtions(loadConditions)\n",
    "\n",
    "    x_array = []\n",
    "    xPhys_array = []\n",
    "    compliance_array = []\n",
    "    change_array = []\n",
    "    mass_array = []\n",
    "\n",
    "    for i in range(numberOfIterations):\n",
    "        x,xPhys,compliance,change,mass = unpackIteration(iterations[i][1])\n",
    "        x_array.append(x)\n",
    "        xPhys_array.append(xPhys)\n",
    "        compliance_array.append(compliance)\n",
    "        change_array.append(change)\n",
    "        mass_array.append(mass)\n",
    "\n",
    "    return forces,free,passive,volfrac,nelx,nely,penal,rmin,x_array,xPhys_array,compliance_array,change_array,mass_array\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset will be the iterative model.\n",
    "\n",
    "This model will attempt to mimic the proccess of the TopOpt where a 'part' and load conditions will be inputed and then the optimal part will then be outputed. This new optimal part should in theory be able to be put back into the model untill it is fully optimized.\n",
    "\n",
    "The model data will be formated as follows:\n",
    "<h1>Inputs</h1>\n",
    "<ul>\n",
    "    <li>xphys:the part to be optimized</li>\n",
    "    <li>forces: as an image for xforces and y forces</li>\n",
    "    <li>Supports: as an image</li>\n",
    "</ul>\n",
    "\n",
    "<h1>Outputs</h1>\n",
    "<ul>\n",
    "    <li>x: the optimal part</li>\n",
    "    <li> A boolean representing if the part has been fully optimized, i.e. last iteration</li>\n",
    "</ul>\n",
    "\n",
    "The data will be built with the following factors in mind.\n",
    "<ol>\n",
    "    <li>The output x will be an image of values between 0 and 1</li>\n",
    "    <li>The boolean can be gotten using a cross entropy error and the wieght on the total accuracy will be low</li>\n",
    "    <li>Since mass will need to remain constant, we can sum the first xphys input layer and use that to normalize the output x</li>\n",
    "    <li>Forces will be an image of nelx+1 by nely+1 with two channels, supports will be the same size as forces but with one channel. xPhys will only be nelx by nely so some form of resizing may be needed</li>\n",
    "    <li>It will be important for the model to know when the part is fully optimized, thus extra data of a fully optimized part as input and itself as output will be used to enforce the idea that there is an optimal end point</li>\n",
    "    <li>A step/jump in iterations may be needed, this will make it so that instead of model predicting an iteration, it will predict 2 iterations in one go.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatIterativeModelDataSet(agentFilePath):\n",
    "    \"\"\"\n",
    "    For the iterative model data.\n",
    "    Takes the extensive output of the getAgentData function and returns the formated data needed for the iterateive model\n",
    "\n",
    "\n",
    "    Forces, passive, and free must be rebuilt as propper images and not 1D arrays\n",
    "    \"\"\"\n",
    "    forces,free,passive,_,nelx,nely,_,_,_,xPhys_array,_,_,_ = getAgentData(agentFilePath)\n",
    "    # print(\"Forces shape\",forces.shape)\n",
    "    # print(\"free shape\",free.shape)\n",
    "    # print(\"passive shape\",passive.shape)\n",
    "    # print(\"xphys shape\",xPhys_array[0].shape)\n",
    "\n",
    "\n",
    "    finalShape = (int(nelx+1),int(nely+1))\n",
    "    forces2 = forces.sum(1)\n",
    "    forces2 = np.reshape(forces2,(finalShape[0],finalShape[1],2))\n",
    "\n",
    "    d2 = np.ones(2*finalShape[0]*finalShape[1])\n",
    "    for index in free:\n",
    "        d2[index] = 0\n",
    "    d3 = np.reshape(d2,(finalShape[0],finalShape[1],2))\n",
    "    degreesOfFreedom2 = d3.sum(2)\n",
    "\n",
    "    passive2 = np.zeros((nelx*nely))\n",
    "    passive2 = np.where(passive > 0,1,0)\n",
    "    passive2 = np.reshape(passive2,(nelx,nely))\n",
    "\n",
    "\n",
    "    #reshape x_arrays as an np array\n",
    "    numberOfIterations = len(xPhys_array)\n",
    "    xPhys_np_array = np.zeros((nelx,nely,numberOfIterations))\n",
    "    for i in range(numberOfIterations):\n",
    "        xPhys_np_array[:,:,i] = np.reshape(xPhys_array[i],(nelx,nely))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return forces2,degreesOfFreedom2,passive2,xPhys_np_array,numberOfIterations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def buildIterativeModelDataSet(dataPointsToGrab:int,iterationJump:int=1):\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the dataGrabed\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{}%\\t\\t\".format(int(100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            forces,dof,passive,x,numIterations = formatIterativeModelDataSet(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]]))\n",
    "        except:\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "            continue\n",
    "        else:\n",
    "            # print(\"index:\",indexList[i])\n",
    "            # print(\"Forces shape:\",forces.shape)\n",
    "            # print(\"free shape:\",dof.shape)\n",
    "            # print(\"passive shape:\",passive.shape)\n",
    "            # print(\"xphys shape:\",x.shape)\n",
    "            #print(\"Out of {} iterations.\".format(numIterations))\n",
    "            for j in range(numIterations-iterationJump):\n",
    "                dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,j]])\n",
    "                v = 0.0\n",
    "                f= 'unfinished'\n",
    "                if(j+iterationJump >= numIterations - 1):\n",
    "                    v = 1.0\n",
    "                    f = 'finished'\n",
    "                dataY.append([x[:,:,j+iterationJump],np.array([v])])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:{}\".format(j,j+iterationJump,f))\n",
    "\n",
    "            for j in range(1,min(iterationJump,numIterations)):\n",
    "                # add the last iterations(dataY has True)\n",
    "                dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,-j -1]])\n",
    "                dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:finished\".format(numIterations-j-1,numIterations-1))\n",
    "\n",
    "            # add the optimal Stoping point data, input = output\n",
    "            dataX.append([forces.copy(),dof.copy(),passive.copy(),x[:,:,numIterations-1]])\n",
    "            dataY.append([x[:,:,numIterations-1],np.array([1.])])\n",
    "\n",
    "        #print(\"Adding itter: {} -> {}:finished\".format(numIterations-1,numIterations-1))\n",
    "    print(\"100%\\t\\t\")\n",
    "    return dataX,dataY\n",
    "        \n",
    "\n",
    "data_x,data_y = buildIterativeModelDataSet(500,10)\n",
    "print(\"x:\",len(data_x))\n",
    "print(\"y:\",len(data_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Train Split\n",
    "\"\"\"\n",
    "By performing the test train split we can get a training data set and a testing dataset to get the metrics for out model\n",
    "By performing the split a second time we can get a scoring dataset that the model will never see that we can use to get out own accuracy score out of\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test  = train_test_split(data_x,data_y, test_size=0.2)\n",
    "X_test, X_score, Y_test, Y_score = train_test_split(X_test,Y_test, test_size=0.05)\n",
    "print(\"X_train: {}\\nY_train: {}\".format(len(X_train), len(Y_train)))\n",
    "print(\"\\nX_test: {}\\nY_test: {}\".format(len(X_test), len(Y_test)))\n",
    "print(\"\\nX_score: {}\\nY_score: {}\".format(len(X_score), len(Y_score)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal parameters\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m1(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    A generic image creation model\n",
    "    ['forces','supports','filled','x']\n",
    "\n",
    "    Inputs:\n",
    "        x: (100,50)\n",
    "        forces: (101,51,2)\n",
    "        supports: (101,51)\n",
    "        filled: (100,50)\n",
    "\n",
    "    Outputs:\n",
    "        x: (100,50)\n",
    "        done: bool\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(forcesInput)\n",
    "    supportConv = layers.Conv2D(filters= 5, kernel_size=(3,3),padding='same',activation=activation)(supportsInput)\n",
    "\n",
    "    #resize the partConv to be the same as the rest of the data\n",
    "    partConv = layers.ZeroPadding2D(padding=((1,0),(1,0)))(partConv)\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape = [x2.shape[1],x2.shape[2]]\n",
    "    x3 = layers.Flatten()(x2)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride < kernalsize\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x2)\n",
    "    x4 = layers.Conv2DTranspose(filters= 16, kernel_size=(3,3),strides=2,padding='same',activation=activation)(x4)\n",
    "    paddingNeeded = ((filledInput.shape[1]-x4.shape[1],0),(filledInput.shape[2]-x4.shape[2],0))\n",
    "\n",
    "    x4 = layers.ZeroPadding2D(padding=paddingNeeded)(x4)\n",
    "    filledAreaAddition = layers.Concatenate()([x4,filledInput])\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(5,5),padding='same',activation=activation, name=\"x_out\")(filledAreaAddition)\n",
    "\n",
    "    #output for finished part\n",
    "\n",
    "    x5 = layers.Dense(newShape[1],activation=activation)(x3)\n",
    "    x5 = layers.Dense(20,activation=activation)(x5)\n",
    "    output_finished =layers.Dense(1,activation='sigmoid', name=\"finished\")(x5)\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part,output_finished])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUpOptimizer(variant):\n",
    "    \"\"\"\n",
    "    Builds a keras optmizer based of default parameters\n",
    "    \n",
    "    Accepts:\n",
    "        1:adam\n",
    "        2:adadelta\n",
    "        3:adafactor\n",
    "        4:adagrad\n",
    "        5:adamax\n",
    "        6:ftrl\n",
    "        7:nadam\n",
    "        8:rmsprop\n",
    "    \"\"\"\n",
    "    if(variant == 1 or variant == 'adam'):\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') \n",
    "    elif(variant == 2 or variant == 'adadelta'):\n",
    "        return keras.optimizers.experimental.Adadelta(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.95,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adadelta'\n",
    "                                                    )\n",
    "    elif(variant == 3 or variant == 'adafactor'):\n",
    "        return keras.optimizers.experimental.Adafactor(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_2_decay=-0.8,\n",
    "                                                        epsilon_1=1e-30,\n",
    "                                                        epsilon_2=0.001,\n",
    "                                                        clip_threshold=1.0,\n",
    "                                                        relative_step=True,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adafactor'\n",
    "                                                    )\n",
    "    elif(variant == 4 or variant == 'adagrad'):\n",
    "        return keras.optimizers.experimental.Adagrad(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        initial_accumulator_value=0.1,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adagrad'\n",
    "                                                    )\n",
    "    elif(variant == 5 or variant == 'adamax'):\n",
    "        return keras.optimizers.experimental.Adamax(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_1=0.9,\n",
    "                                                        beta_2=0.999,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=None,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='Adamax'\n",
    "                                                    )\n",
    "    elif(variant == 6 or variant == 'ftrl'):\n",
    "        return keras.optimizers.experimental.Ftrl(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    learning_rate_power=-0.5,\n",
    "                                                    initial_accumulator_value=0.1,\n",
    "                                                    l1_regularization_strength=0.0,\n",
    "                                                    l2_regularization_strength=0.0,\n",
    "                                                    l2_shrinkage_regularization_strength=0.0,\n",
    "                                                    beta=0.0,\n",
    "                                                    weight_decay=None,\n",
    "                                                    clipnorm=None,\n",
    "                                                    clipvalue=None,\n",
    "                                                    global_clipnorm=None,\n",
    "                                                    use_ema=False,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    ema_overwrite_frequency=None,\n",
    "                                                    jit_compile=True,\n",
    "                                                    name='Ftrl'\n",
    "                                                )\n",
    "    elif(variant == 7 or variant == 'nadam'):\n",
    "        return keras.optimizers.experimental.Nadam(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    beta_1=0.9,\n",
    "                                                    beta_2=0.999,\n",
    "                                                    epsilon=1e-07,\n",
    "                                                    weight_decay=None,\n",
    "                                                    clipnorm=None,\n",
    "                                                    clipvalue=None,\n",
    "                                                    global_clipnorm=None,\n",
    "                                                    use_ema=False,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    ema_overwrite_frequency=None,\n",
    "                                                    jit_compile=True,\n",
    "                                                    name='Nadam'\n",
    "                                                )\n",
    "    elif(variant == 8 or variant == 'rmsprop'):\n",
    "        return keras.optimizers.experimental.RMSprop(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.9,\n",
    "                                                        momentum=0.0,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        centered=False,\n",
    "                                                        weight_decay=None,\n",
    "                                                        clipnorm=None,\n",
    "                                                        clipvalue=None,\n",
    "                                                        global_clipnorm=None,\n",
    "                                                        use_ema=False,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=100,\n",
    "                                                        jit_compile=True,\n",
    "                                                        name='RMSprop'\n",
    "                                                    )\n",
    "    else:\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel(modelNumber):\n",
    "    if(modelNumber == 1):\n",
    "        model = model_m1()\n",
    "        fileSaveName = \"Model_m1\"\n",
    "    else:\n",
    "        raise Exception(\"No model identified, model {} DNE.\".format(modelNumber))\n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelPath,fileSaveName),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        model.load_weights(os.path.join(modelPath,fileSaveName))\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "\n",
    "    if(modelNumber == 1):\n",
    "        model.compile(optimizer=SetUpOptimizer(1),\n",
    "                        loss={\n",
    "                            'x_out':keras.losses.MeanSquaredLogarithmicError(), #logrithmic error for the 0-1 output of the image\n",
    "                            'finished':keras.losses.BinaryCrossentropy(from_logits=True) #binary entropy error for the bool output\n",
    "                        },\n",
    "                        loss_weights={'x_out':1.0,'finished':0.2})\n",
    "    \n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,callBack = getModel(1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data spliting\n",
    "def splitX(data):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    for forces,support,filled,x in data:\n",
    "        forces_array.append(forces)\n",
    "        support_array.append(support)\n",
    "        filled_array.append(filled)\n",
    "        x_array.append(x)\n",
    "    return x_array,filled_array,forces_array, support_array,  \n",
    "\n",
    "def splitY(data):\n",
    "    x_array = []\n",
    "    finished_array = []\n",
    "    for x,finished in data:\n",
    "        x_array.append(x)\n",
    "        finished_array.append(finished)\n",
    "    return x_array,finished_array\n",
    "\n",
    "X_train_part, X_train_filled, X_train_forces, X_train_supports = splitX(X_train)\n",
    "Y_train_x, Y_train_finished = splitY(Y_train)\n",
    "X_test_part, X_test_filled, X_test_forces, X_test_supports = splitX(X_test)\n",
    "Y_test_x, Y_test_finished = splitY(Y_test)\n",
    "\n",
    "\n",
    "X_train_part = np.array(X_train_part)\n",
    "X_train_forces = np.array(X_train_forces)\n",
    "X_train_supports = np.array(X_train_supports)\n",
    "X_train_filled = np.array(X_train_filled)\n",
    "Y_train_x = np.array(Y_train_x)\n",
    "Y_train_finished = np.array(Y_train_finished)\n",
    "\n",
    "X_test_part = np.array(X_test_part)\n",
    "X_test_forces = np.array(X_test_forces)\n",
    "X_test_supports = np.array(X_test_supports)\n",
    "X_test_filled = np.array(X_test_filled)\n",
    "Y_test_x = np.array(Y_test_x)\n",
    "Y_test_finished = np.array(Y_test_finished)\n",
    "\n",
    "print(len(X_train_part))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 32 # default tensorflow batchsize\n",
    "numEpochs = 10\n",
    "BatchesPerEpoch = len(X_train_part) // (BatchSize*numEpochs)\n",
    "BatchesPerEpoch = max(10,BatchesPerEpoch)\n",
    "\n",
    "print(BatchesPerEpoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "        {'x':X_train_part,'forces':X_train_forces,'supports':X_train_supports,'filled':X_train_filled},\n",
    "        {'x_out':Y_train_x,'finished':Y_train_finished},\n",
    "        batch_size=BatchSize,\n",
    "        epochs=numEpochs,\n",
    "        shuffle=True,\n",
    "        validation_data=(\n",
    "                        {'x':X_test_part,'forces':X_test_forces,'supports':X_test_supports,'filled':X_test_filled},\n",
    "                        {'x_out':Y_test_x,'finished':Y_test_finished}),\n",
    "        callbacks=[callBack],\n",
    "        steps_per_epoch = BatchesPerEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build some statistics on the data\n",
    "X_score_part, X_score_filled, X_score_forces, X_score_supports = splitX(X_score)\n",
    "Y_score_x, Y_score_finished = splitY(Y_score)\n",
    "\n",
    "X_score_part = np.array(X_score_part)\n",
    "X_score_forces = np.array(X_score_forces)\n",
    "X_score_supports = np.array(X_score_supports)\n",
    "X_score_filled = np.array(X_score_filled)\n",
    "Y_score_x = np.array(Y_score_x)\n",
    "Y_score_finished = np.array(Y_score_finished)\n",
    "\n",
    "output = model.predict({'x':X_score_part,'forces':X_score_forces,'supports':X_score_supports,'filled':X_score_filled})\n",
    "Y_pred_part = output[0]\n",
    "Y_pred_finished = output[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalBit(a):\n",
    "    if(a[0] > 0):\n",
    "        return 'fin'\n",
    "    else:\n",
    "        return 'it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the true and predicted Values\n",
    "ncol = 5\n",
    "nelx = 100\n",
    "nely = 50\n",
    "\n",
    "fig,ax = plt.subplots(3,ncol)\n",
    "\n",
    "rnd = np.arange(len(X_score_part),dtype='int32')\n",
    "np.random.shuffle(rnd)\n",
    "\n",
    "for i in range(ncol):\n",
    "    ax[0,i].set_title(\"original\")\n",
    "    ax[0,i].imshow(np.reshape(X_score_part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,i].get_xaxis().set_visible(False)\n",
    "    ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[1,i].set_title(\"True\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,i].imshow(np.reshape(Y_score_x[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,i].get_xaxis().set_visible(False)\n",
    "    ax[1,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[2,i].set_title(\"Predicted\")#:{}\".format(finalBit(Y_pred_finished[rnd[i]])))\n",
    "    ax[2,i].imshow(np.reshape(Y_pred_part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[2,i].get_xaxis().set_visible(False)\n",
    "    ax[2,i].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thoughts</h1>\n",
    "\n",
    "The model is not learning anything. It is applying a blur filter to what it is given and adding the circles around that. I think that a new aproach it needed to fully train the model.\n",
    "\n",
    "In addition to various different loss functions and optimizers that could be changed, and can easily be changed. I think that training the model on only the first itteration of each data point may be a good indicator of how things should end up.\n",
    "\n",
    "By looking only at the first itteration, the model learn how to form shapes between the given points instead of just adding a blur. The first iteration being the solid volume filled with the volfrac amount and the optimal part from that being the first signs of a shape forming\n",
    "\n",
    "Since the x data is a float between 0 and 1 I think that it may be nessesary to cosider a different loss function. logrithmic error is good for this type of loss but there may be a better loss function for the part data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
