{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetAgentData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3129\n",
      "Agent1_485135\n"
     ]
    }
   ],
   "source": [
    "#overview of the data\n",
    "#dataDirectory = os.path.join(os.getcwd(),'data')\n",
    "dataDirectory = r\"E:\\TopoptGAfileSaves\\ComplianceMinimization\\Agents\"\n",
    "DATA_FILE_PATH = os.path.join(dataDirectory,'100_50')\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "data_x_columns = ['forces','supports','filled','x']\n",
    "data_y_columns = ['x','finished']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence class will hold each problem statement as a sequence of all the iterations.\n",
    "It will hold the load conditions as well as each iteration.\n",
    "<ol>\n",
    "<li>When training the model, some fraction of the sequences will be called and the model will train on them.</li>\n",
    "<li>The model will then be given some other fraction of seqences to predict.</li>\n",
    "<li>These predictions will be maped to their original inputs and will be re-outputed as new problem statment iterations.</li>\n",
    "<li>The new(Model predicted) datapoints can then be inputed back into the model for training.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopOptSequence:\n",
    "    def __init__(self,ID,forces,dof,passive,x,numIterations):\n",
    "        self.ID = ID\n",
    "        self.forceImage = forces\n",
    "        self.anchorImage = dof\n",
    "        self.filledAreaImage = passive\n",
    "        self.xPhys_array = x\n",
    "        self.numIterations = numIterations\n",
    "        self.iterationJumpTracker = []\n",
    "    \n",
    "    def dispenceData(self,iterationJump:int=5):\n",
    "        \"\"\"\n",
    "        When called creates list of numpy arrays filled with the data needed to train the model\n",
    "\n",
    "        returns:\n",
    "            forces_array\n",
    "            support_array\n",
    "            filled_array\n",
    "            x_array\n",
    "            x_optimized_array\n",
    "            finished_array\n",
    "        \"\"\"\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        self.iterationJumpTracker = []\n",
    "        for j in range(self.numIterations-iterationJump):\n",
    "                dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,j]])\n",
    "                v = 0.0\n",
    "                f= 'unfinished'\n",
    "                if(j+iterationJump >= self.numIterations - 1):\n",
    "                    v = 1.0\n",
    "                    f = 'finished'\n",
    "                dataY.append([self.xPhys_array[:,:,j+iterationJump],np.array([v])])\n",
    "                self.iterationJumpTracker.append([j,j+iterationJump])\n",
    "\n",
    "                #print(\"Adding itter: {} -> {}:{}\".format(j,j+iterationJump,f))\n",
    "\n",
    "        for j in range(1,min(iterationJump,self.numIterations)):\n",
    "            # add the last iterations(dataY has True)\n",
    "            dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,-j -1]])\n",
    "            dataY.append([self.xPhys_array[:,:,self.numIterations-1],np.array([1.])])\n",
    "            self.iterationJumpTracker.append([-j,self.numIterations-1])\n",
    "\n",
    "            #print(\"Adding itter: {} -> {}:finished\".format(numIterations-j-1,numIterations-1))\n",
    "\n",
    "        # add the optimal Stoping point data, input = output\n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,self.numIterations-1]])\n",
    "        dataY.append([self.xPhys_array[:,:,self.numIterations-1],np.array([1.])])\n",
    "        self.iterationJumpTracker.append([self.numIterations-1,self.numIterations-1])\n",
    "\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for x,finished in dataY:\n",
    "            x_optimized_array.append(x)\n",
    "            finished_array.append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "\n",
    "    def findNextIterations(self,i):\n",
    "        \"\"\"\n",
    "        Given and index for a predicted image, find it's next optimized output.\n",
    "        each output image will have a order that matches the order of it's input.\n",
    "        By knowing the input image we can find what image the prediction was supposed to be.\n",
    "        By knowing what the image was supposed to be, we can find next step in the iteration.\n",
    "\n",
    "\n",
    "        Process works like this:\n",
    "            - iterationTracker stores the input and output image,\n",
    "            - We know the input image so we use this to find the correct output image\n",
    "            - We then search the tracker for where the output image was used as input to get the correct next iteration.\n",
    "        \"\"\"\n",
    "        def searchTracker(index):\n",
    "            \"\"\"given an input index find the matching output index\"\"\"\n",
    "            for inputIndex,outputIndex in self.iterationJumpTracker:\n",
    "                if(inputIndex == index):\n",
    "                    return outputIndex\n",
    "            return -1\n",
    "        \n",
    "        correctOutput = searchTracker(i)\n",
    "        nextIteration = searchTracker(correctOutput)\n",
    "        return nextIteration\n",
    "\n",
    "    def formatPredictedData(self,predicted_x_array):\n",
    "        \"\"\"\n",
    "        Given an array of images and the finished array, reformate the images with their respective inputs to create a new dataset that has as input the predicted x and as output the correct next iteration.\n",
    "\n",
    "        The iteration Jump tracker has stored what iterations were jumped so by following the tracker list we can find the correct next output\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(predicted_x_array)\n",
    "        if(n ==  self.numIterations):#check if correct number of iterations has been recieved\n",
    "            forces_array = []\n",
    "            support_array = []\n",
    "            filled_array = []\n",
    "            x_array = []\n",
    "            x_optimized_array = []\n",
    "            finished_array = []\n",
    "            for i in range(n):\n",
    "                correctOutput = self.findNextIterations(i)\n",
    "                if(correctOutput <= 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    forces_array.append(self.forceImage.copy())\n",
    "                    support_array.append(self.anchorImage.copy())\n",
    "                    filled_array.append(self.filledAreaImage.copy())\n",
    "\n",
    "                    x_array.append(predicted_x_array[i].copy())\n",
    "                    v = 0.0\n",
    "                    if(correctOutput >= n):\n",
    "                        correctOutput = n-1\n",
    "                        v = 1.0\n",
    "                    x_optimized_array.append(self.xPhys_array[:,:,correctOutput])\n",
    "                    finished_array.append([v])\n",
    "                    \n",
    "            return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Data given is not of the correct format. required iterations: {}. iterations recieved: {}\".format(self.numIterations,n))\n",
    "\n",
    "    def dispenceFirstIterationData(self):\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        \n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,0]])\n",
    "        dataY.append([self.xPhys_array[:,:,1],np.array([0])])\n",
    "\n",
    "        dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,0]])\n",
    "        dataY.append([self.xPhys_array[:,:,2],np.array([0])])\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for x,finished in dataY:\n",
    "            x_optimized_array.append(x)\n",
    "            finished_array.append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n",
    "        \n",
    "    def dispenceM7modelData(self,iterationJump:int=5,predictionDepth:int=5):\n",
    "        \"\"\"\n",
    "        When called creates list of numpy arrays filled with the data needed to train the model\n",
    "        Designed to return the inital input but with an array of output representing the folowing iterations.\n",
    "\n",
    "        This will allow the model to train on its own predictions\n",
    "        \"\"\"\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        for j in range(self.numIterations-(iterationJump//2)):\n",
    "            dataX.append([self.forceImage.copy(),self.anchorImage.copy(),self.filledAreaImage.copy(),self.xPhys_array[:,:,j]])\n",
    "            \n",
    "            dataY.append([])\n",
    "            for i in range(predictionDepth):\n",
    "                currentIteration = min(j + i*iterationJump,self.numIterations-1)\n",
    "                v = 0.0\n",
    "                if(currentIteration >= self.numIterations - 1):\n",
    "                    v = 1.0\n",
    "                dataY[j].append([self.xPhys_array[:,:,currentIteration],np.array([v])])\n",
    "\n",
    "\n",
    "        forces_array = []\n",
    "        support_array = []\n",
    "        filled_array = []\n",
    "        x_array = []\n",
    "        for forces,support,filled,x in dataX:\n",
    "\n",
    "            forces_array.append(forces)\n",
    "            support_array.append(support)\n",
    "            filled_array.append(filled)\n",
    "            x_array.append(x)\n",
    "\n",
    "        x_optimized_array = []\n",
    "        finished_array = []\n",
    "        for i in range(len(dataY)):\n",
    "            x_optimized_array.append([])\n",
    "            finished_array.append([])\n",
    "            for x,finished in dataY[i]:\n",
    "                x_optimized_array[i].append(x)\n",
    "                finished_array[i].append(finished)\n",
    "\n",
    "\n",
    "        return forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(dataPointsToGrab:int):\n",
    "\n",
    "    # Constants of interest\n",
    "    # DATA_FILE_PATH = path to agent files\n",
    "    # dir_List = all agent files\n",
    "    # max_data_points = total number of datapoints\n",
    "\n",
    "    dataPointsToGrab = min(dataPointsToGrab,max_data_points)\n",
    "\n",
    "    #randomize the data grabed so that the first thee datapoints aren't always in the data.\n",
    "    indexList = np.arange(max_data_points,dtype='int32')\n",
    "    np.random.shuffle(indexList)\n",
    "\n",
    "    sequenceData = []\n",
    "    print(\"Retreiving {} Datapoints.\".format(dataPointsToGrab))\n",
    "\n",
    "    for i in range(dataPointsToGrab):\n",
    "        print(\"{:.2f}%\\t\\t\".format((100*(i/dataPointsToGrab))),end='\\r')\n",
    "        try:\n",
    "            #join the data file path to a random sorted member within the data directory\n",
    "            pathToAgent = os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])\n",
    "            forces,dof,passive,x,numIterations = formatIterativeModelDataSet(pathToAgent)\n",
    "        except:\n",
    "            #if an exception occurs list it and move forward\n",
    "            print(\"Exception Occured at file '{}'.\".format(os.path.join(DATA_FILE_PATH,dir_list[indexList[i]])))\n",
    "            continue\n",
    "        else:\n",
    "            #if no error occured append that data to the data list\n",
    "            sequenceData.append(TopOptSequence(i,forces,dof,passive,x,numIterations))\n",
    "\n",
    "    print(\"100%\\t\\t\")\n",
    "    return sequenceData\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving 50 Datapoints.\n",
      "100%\t\t\t\t\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "Data = buildDataSet(50)\n",
    "print(len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the data output is correct\n",
    "def checkArrays(arraysOfValues):\n",
    "    correct = True\n",
    "    for i in range(1,len(arraysOfValues)):\n",
    "        a = np.equal(arraysOfValues[i-1],arraysOfValues[i]).sum()\n",
    "        numberofValues = np.prod(arraysOfValues[i-1].shape)\n",
    "        #print(a,numberofValues)\n",
    "        if(a != numberofValues):\n",
    "            print(\"iteration {} is not the same as iteration {}, {} != {}.\".format(i-1,i,a,numberofValues))\n",
    "            correct = False\n",
    "        #print(a,forceValues)\n",
    "\n",
    "    return correct\n",
    "            \n",
    "def plotIteration(input_array,output_array,finished_array):\n",
    "    numIterations = len(input_array)\n",
    "    for i in range(numIterations):\n",
    "        fig,ax = plt.subplots(1,2)\n",
    "        ax[0].imshow(input_array[i].T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[0].get_xaxis().set_visible(False)\n",
    "        ax[0].get_yaxis().set_visible(False)\n",
    "        ax[0].set_title(\"Input\")\n",
    "\n",
    "        ax[1].imshow(output_array[i].T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[1].get_xaxis().set_visible(False)\n",
    "        ax[1].get_yaxis().set_visible(False)\n",
    "        ax[1].set_title(\"Output, Finished:{}\".format(finished_array[i]))\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def checkData(indexToUse):\n",
    "    currentSum = 0\n",
    "    for sequence in Data:\n",
    "        currentSum += sequence.numIterations\n",
    "    \n",
    "    print(\"With {} problem statements there are {} sample datapoints.\".format(len(Data),currentSum))\n",
    "\n",
    "    forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array = Data[indexToUse].dispenceFirstIterationData()\n",
    "    #check forces\n",
    "    print(\"check Forces:\")\n",
    "    if(checkArrays(forces_array)):\n",
    "        print(\"\\tOk.\")\n",
    "\n",
    "    print(\"check Supports:\")\n",
    "    if(checkArrays(support_array)):\n",
    "        print(\"\\tOk.\")\n",
    "    \n",
    "    print(\"check Filled area:\")\n",
    "    if(checkArrays(filled_array)):\n",
    "        print(\"\\tOk.\")\n",
    "    \n",
    "    numIterations = Data[indexToUse].numIterations\n",
    "    print(\"Iterations:\",numIterations )\n",
    "    plotIteration(x_array,x_optimized_array,finished_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 50 problem statements there are 923 sample datapoints.\n",
      "check Forces:\n",
      "\tOk.\n",
      "check Supports:\n",
      "\tOk.\n",
      "check Filled area:\n",
      "\tOk.\n",
      "Iterations: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#forces_array,support_array,filled_array,x_array,x_optimized_array,finished_array = Data[0].dispenceData()\n",
    "\n",
    "#print(Data[0].numIterations)\n",
    "#print(len(x_array))\n",
    "checkData(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7\n",
      "\n",
      "Test: 12\n",
      "\n",
      "Score: 31\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split\n",
    "\"\"\"\n",
    "By performing the test train split we can get a training data set and a testing dataset to get the metrics for out model\n",
    "By performing the split a second time we can get a validataion dataset that the model will never see that we can use to get out own accuracy score out of\n",
    "\"\"\"\n",
    "Data_train, Data_test = train_test_split(Data, test_size=0.85)\n",
    "Data_test, Data_score= train_test_split(Data_test, test_size=0.7)\n",
    "print(\"Train: {}\".format(len(Data_train)))\n",
    "print(\"\\nTest: {}\".format(len(Data_test)))\n",
    "print(\"\\nScore: {}\".format(len(Data_score)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Information</h1>\n",
    "\n",
    "Below are the models that will be used to attempt to learn the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal parameters\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model_m4(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    A U-net architecture model to be used to predict the first iteration of the part.\n",
    "    all input images are upscalled to the nearest power of two\n",
    "    \"\"\"\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    \n",
    "    concatenatedConvolution = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    convolution1 = layers.Conv2D(filters= 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(concatenatedConvolution)\n",
    "    convolution1 = layers.Conv2D(filters= 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution1)\n",
    "\n",
    "    convolution2 = layers.MaxPool2D(pool_size=(2,2))(convolution1)\n",
    "    convolution2 = layers.Conv2D(filters= 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution2)\n",
    "    convolution2 = layers.Conv2D(filters= 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution2)\n",
    "\n",
    "    convolution3 = layers.MaxPool2D(pool_size=(2,2))(convolution2)\n",
    "    convolution3 = layers.Conv2D(filters= 128, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution3)\n",
    "    convolution3 = layers.Conv2D(filters= 128, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution3)\n",
    "    \n",
    "    convolution4 = layers.Conv2DTranspose(filters=64, kernel_size=(3,3),strides=2,padding='same',activation=activation)(convolution3)\n",
    "    convolution4 = layers.Concatenate()([convolution4,convolution2])\n",
    "    convolution4 = layers.Conv2D(filters= 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution4)\n",
    "    convolution4 = layers.Conv2D(filters= 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution4)\n",
    "\n",
    "    convolution5 = layers.Conv2DTranspose(filters=32, kernel_size=(3,3),strides=2,padding='same',activation=activation)(convolution4)\n",
    "    convolution5 = layers.Concatenate()([convolution5,convolution1])\n",
    "    convolution5 = layers.Conv2D(filters= 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution5)\n",
    "    convolution5 = layers.Conv2D(filters= 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convolution5)\n",
    "\n",
    "    outputConvolution = layers.Resizing(height=100,width=50)(convolution5)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),strides=1,padding='same',activation=activation, name=\"x_out\")(outputConvolution)\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m5(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    Modle based off the m3 but with noise reduction embedded into it.\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.Dropout(rate=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.Dropout(rate=0.2)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.Dropout(rate=0.3)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape=conv_16_8.shape[1:]\n",
    "    shapeFlat = np.prod(newShape)\n",
    "    print(\"x2.Shape:{}={}\".format(newShape,shapeFlat))\n",
    "    denseLayer = layers.Flatten()(conv_16_8)\n",
    "    denseLayer = layers.Dense(shapeFlat,activation=activation)(denseLayer)\n",
    "    denseLayer = layers.Reshape(newShape)(denseLayer)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(denseLayer)\n",
    "    print(\"32_16:\",convUpscale_32_16.shape)\n",
    "    convUpscale_32_16 = layers.Dropout(rate=0.3)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    print(\"64_32:\",convUpscale_32_16.shape)\n",
    "    convUpscale_64_32 = layers.Dropout(rate=0.2)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    print(\"128_64:\",convUpscale_32_16.shape)\n",
    "    convUpscale_128_64 = layers.Dropout(rate=0.1)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='sigmoid', name=\"x_out\")(output_resize)\n",
    "\n",
    "\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])\n",
    "\n",
    "# m = model_m5()\n",
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_m6(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    \"\"\"\n",
    "    Modle based off the m3 but with noise reduction embedded into it.\n",
    "    \"\"\"\n",
    "\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.GaussianNoise(stddev=0.1)(conv_64_32)\n",
    "    conv_64_32 = layers.Dropout(rate=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.GaussianNoise(stddev=0.1)(conv_32_16)\n",
    "    conv_32_16 = layers.Dropout(rate=0.2)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.Dropout(rate=0.3)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape=conv_16_8.shape[1:]\n",
    "    shapeFlat = np.prod(newShape)\n",
    "    #print(\"x2.Shape:{}={}\".format(newShape,shapeFlat))\n",
    "    denseLayer = layers.Flatten()(conv_16_8)\n",
    "    denseLayer = layers.Dense(shapeFlat,activation=activation)(denseLayer)\n",
    "    denseLayer_16_8 = layers.Reshape(newShape)(denseLayer)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(denseLayer_16_8)\n",
    "    #print(\"32_16:\",convUpscale_32_16.shape)\n",
    "    convUpscale_32_16 = layers.Dropout(rate=0.3)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.GaussianNoise(stddev=0.1)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    #print(\"64_32:\",convUpscale_32_16.shape)\n",
    "    convUpscale_64_32 = layers.Dropout(rate=0.2)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    #print(\"128_64:\",convUpscale_32_16.shape)\n",
    "    convUpscale_128_64 = layers.Dropout(rate=0.1)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='hard_sigmoid', name=\"x_out\")(output_resize)\n",
    "    \"\"\"\n",
    "    The hard sigmoid activation, defined as:\n",
    "        if x < -2.5: return 0\n",
    "        if x > 2.5: return 1\n",
    "        if -2.5 <= x <= 2.5: return 0.2 * x + 0.5\n",
    "    \"\"\"\n",
    "    finishedCheckLayer = layers.Dense(10)(denseLayer)\n",
    "    finishedCheckLayer = layers.Dense(10)(finishedCheckLayer)\n",
    "    finishedOutput = layers.Dense(1,name='finished')(finishedCheckLayer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part,finishedOutput])\n",
    "\n",
    "# m = model_m5()\n",
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_m7(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.GaussianNoise(stddev=0.1)(conv_64_32)\n",
    "    conv_64_32 = layers.Dropout(rate=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.GaussianNoise(stddev=0.1)(conv_32_16)\n",
    "    conv_32_16 = layers.Dropout(rate=0.2)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.Dropout(rate=0.3)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #Dense 2D layer\n",
    "    newShape=conv_16_8.shape[1:]\n",
    "    shapeFlat = np.prod(newShape)\n",
    "    denseLayer = layers.Flatten()(conv_16_8)\n",
    "    denseLayer = layers.Dense(shapeFlat,activation=activation)(denseLayer)\n",
    "    denseLayer_16_8 = layers.Reshape(newShape)(denseLayer)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(denseLayer_16_8)\n",
    "    convUpscale_32_16 = layers.Dropout(rate=0.3)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.GaussianNoise(stddev=0.1)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_64_32 = layers.Dropout(rate=0.2)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_128_64 = layers.Dropout(rate=0.1)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='hard_sigmoid', name=\"x_out\")(output_resize)\n",
    "    \"\"\"\n",
    "    The hard sigmoid activation, defined as:\n",
    "        if x < -2.5: return 0\n",
    "        if x > 2.5: return 1\n",
    "        if -2.5 <= x <= 2.5: return 0.2 * x + 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])#,finishedOutput])\n",
    "\n",
    "class Model_m7(keras.Model):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model_m7, self).__init__()\n",
    "        self.model = buildModel_m7()\n",
    "        \n",
    "\n",
    "    def call(self,data,training = False):\n",
    "        #part = data['x']\n",
    "        #forces = data['forces']\n",
    "        #supports = data['supports']\n",
    "        #filled = data['filled']\n",
    "        #print(1)\n",
    "        if(training):\n",
    "            \n",
    "            out1 = self.model(data)\n",
    "            data['x'] = out1\n",
    "            \n",
    "            #print(2)\n",
    "            out2 = self.model(data)\n",
    "            data['x'] = out2\n",
    "\n",
    "            out3 = self.model(data)\n",
    "            data['x'] = out3\n",
    "        \n",
    "            out4 = self.model(data)\n",
    "            data['x'] = out4\n",
    "\n",
    "            out5 = self.model(data)\n",
    "            #print(6)\n",
    "            return out1,out2,out3,out4,out5\n",
    "        else:\n",
    "            return self.model(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_m8(x_inputShape = (100,50,1),forces_inputShape = (101,51,2),supports_inputShape = (101,51,1),filled_inputShape = (100,50,1)):\n",
    "    partInput = keras.Input(shape=x_inputShape,name=\"x\")\n",
    "    forcesInput = keras.Input(shape=forces_inputShape,name=\"forces\")\n",
    "    supportsInput = keras.Input(shape=supports_inputShape,name=\"supports\")\n",
    "    #since filled input is solely the solid area it will be passed into the model at the very end\n",
    "    filledInput = keras.Input(shape=filled_inputShape,name=\"filled\")\n",
    "\n",
    "    partInput_resize = layers.Resizing(height=128,width=64)(partInput)\n",
    "    forcesInput_resize = layers.Resizing(height=128,width=64)(forcesInput)\n",
    "    forcesInput_resize = layers.Activation(activation='tanh')(forcesInput_resize)# normaize the force input\n",
    "    supportsInput_resize = layers.Resizing(height=128,width=64)(supportsInput)\n",
    "    filledInput_resize = layers.Resizing(height=128,width=64)(filledInput)\n",
    "\n",
    "    concatenatedStartLayer = layers.Concatenate()([partInput_resize,forcesInput_resize,supportsInput_resize,filledInput_resize])\n",
    "\n",
    "    #First Convolution Layer\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(concatenatedStartLayer)\n",
    "    conv_128_64 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(conv_128_64)\n",
    "    conv_64_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_64)\n",
    "    conv_64_32 = layers.GaussianNoise(stddev=0.1)(conv_64_32)\n",
    "\n",
    "    #Second convolution Layer\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_64_32 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(conv_64_32)\n",
    "    conv_32_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_32)\n",
    "    conv_32_16 = layers.GaussianNoise(stddev=0.1)(conv_32_16)\n",
    "\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_32_16 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(conv_32_16)\n",
    "    conv_16_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_16)\n",
    "    conv_16_8 = layers.GaussianNoise(stddev=0.1)(conv_16_8)\n",
    "\n",
    "    conv_16_8 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "    conv_16_8 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(conv_16_8)\n",
    "\n",
    "    #upscaleLayer\n",
    "    #upscaling is performed by convolution transpose where stride=2 < kernalsize\n",
    "    convUpscale_32_16 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(conv_16_8)\n",
    "    convUpscale_32_16 = layers.GaussianNoise(stddev=0.1)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Concatenate()([convUpscale_32_16,conv_32_16])\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_32_16 = layers.Conv2D(filters = 64, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_32_16)\n",
    "\n",
    "    convUpscale_64_32 = layers.Conv2DTranspose(filters= 32, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_32_16)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Concatenate()([convUpscale_64_32,conv_64_32])\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.Conv2D(filters = 32, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_64_32)\n",
    "\n",
    "    convUpscale_128_64 = layers.Conv2DTranspose(filters= 64, kernel_size=(5,5),strides=2,padding='same',activation=activation)(convUpscale_64_32)\n",
    "    convUpscale_64_32 = layers.GaussianNoise(stddev=0.1)(convUpscale_64_32)\n",
    "    convUpscale_128_64 = layers.Concatenate()([convUpscale_128_64,conv_128_64])\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 16, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "    convUpscale_128_64 = layers.Conv2D(filters = 16, kernel_size=(3,3),strides=1,padding='same',activation=activation)(convUpscale_128_64)\n",
    "\n",
    "    output_resize =layers.Resizing(height=100,width=50)(convUpscale_128_64)\n",
    "    output_part = layers.Conv2D(filters= 1, kernel_size=(1,1),padding='same',activation='hard_sigmoid', name=\"x_out\")(output_resize)\n",
    "    \"\"\"\n",
    "    The hard sigmoid activation, defined as:\n",
    "        if x < -2.5: return 0\n",
    "        if x > 2.5: return 1\n",
    "        if -2.5 <= x <= 2.5: return 0.2 * x + 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    return keras.Model(inputs= [partInput,forcesInput,supportsInput,filledInput],outputs=[output_part])#,finishedOutput])\n",
    "\n",
    "class Model_m8(keras.Model):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model_m8, self).__init__()\n",
    "        self.model = buildModel_m8()\n",
    "        \n",
    "\n",
    "    def call(self,data,training = False):\n",
    "        #part = data['x']\n",
    "        #forces = data['forces']\n",
    "        #supports = data['supports']\n",
    "        #filled = data['filled']\n",
    "        #print(1)\n",
    "        if(training):\n",
    "            \n",
    "            out1 = self.model(data)\n",
    "            data['x'] = out1\n",
    "            \n",
    "            #print(2)\n",
    "            out2 = self.model(data)\n",
    "            data['x'] = out2\n",
    "\n",
    "            out3 = self.model(data)\n",
    "            data['x'] = out3\n",
    "        \n",
    "            out4 = self.model(data)\n",
    "            data['x'] = out4\n",
    "\n",
    "            out5 = self.model(data)\n",
    "            #print(6)\n",
    "            return out1,out2,out3,out4,out5\n",
    "        else:\n",
    "            return self.model(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUpOptimizer(variant):\n",
    "    \"\"\"\n",
    "    Builds a keras optmizer based of default parameters\n",
    "    \n",
    "    Accepts:\n",
    "        1:adam\n",
    "        2:adadelta\n",
    "        3:adafactor\n",
    "        4:adagrad\n",
    "        5:adamax\n",
    "        6:ftrl\n",
    "        7:nadam\n",
    "        8:rmsprop\n",
    "    \"\"\"\n",
    "    if(variant == 1 or variant == 'adam'):\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') \n",
    "    elif(variant == 2 or variant == 'adadelta'):\n",
    "        print(\"Optimizer: AdaDelta\")\n",
    "        return keras.optimizers.experimental.Adadelta(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.95,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adadelta'\n",
    "                                                    )\n",
    "    elif(variant == 3 or variant == 'adafactor'):\n",
    "        print(\"Optimizer: AdaFactor\")\n",
    "        return keras.optimizers.experimental.Adafactor(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_2_decay=-0.8,\n",
    "                                                        epsilon_1=1e-30,\n",
    "                                                        epsilon_2=0.001,\n",
    "                                                        clip_threshold=1.0,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adafactor'\n",
    "                                                    )\n",
    "    elif(variant == 4 or variant == 'adagrad'):\n",
    "        print(\"Optimizer: AdaGrad\")\n",
    "        return keras.optimizers.experimental.Adagrad(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        initial_accumulator_value=0.1,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adagrad'\n",
    "                                                    )\n",
    "    elif(variant == 5 or variant == 'adamax'):\n",
    "        print(\"Optimizer: AdaMax\")\n",
    "        return keras.optimizers.experimental.Adamax(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        beta_1=0.9,\n",
    "                                                        beta_2=0.999,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        name='Adamax'\n",
    "                                                    )\n",
    "    elif(variant == 6 or variant == 'ftrl'):\n",
    "        print(\"Optimizer: FTRL\")\n",
    "        return keras.optimizers.experimental.Ftrl(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    learning_rate_power=-0.5,\n",
    "                                                    initial_accumulator_value=0.1,\n",
    "                                                    l1_regularization_strength=0.0,\n",
    "                                                    l2_regularization_strength=0.0,\n",
    "                                                    l2_shrinkage_regularization_strength=0.0,\n",
    "                                                    beta=0.0,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Ftrl'\n",
    "                                                )\n",
    "    elif(variant == 7 or variant == 'nadam'):\n",
    "        print(\"Optimizer: Nadam\")\n",
    "        return keras.optimizers.experimental.Nadam(\n",
    "                                                    learning_rate=0.001,\n",
    "                                                    beta_1=0.9,\n",
    "                                                    beta_2=0.999,\n",
    "                                                    epsilon=1e-07,\n",
    "                                                    ema_momentum=0.99,\n",
    "                                                    name='Nadam'\n",
    "                                                )\n",
    "    elif(variant == 8 or variant == 'rmsprop'):\n",
    "        print(\"Optimizer: RMSprop\")\n",
    "        return keras.optimizers.experimental.RMSprop(\n",
    "                                                        learning_rate=0.001,\n",
    "                                                        rho=0.9,\n",
    "                                                        momentum=0.0,\n",
    "                                                        epsilon=1e-07,\n",
    "                                                        ema_momentum=0.99,\n",
    "                                                        ema_overwrite_frequency=100,\n",
    "                                                        name='RMSprop'\n",
    "                                                    )\n",
    "    else:\n",
    "        print(\"Optimizer: Adam\")\n",
    "        return keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setUp modelSaving\n",
    "\n",
    "def getModel(modelNumber,optimizerVarient:int = 1):\n",
    "    if(modelNumber == 4):\n",
    "        model = unet_model_m4()\n",
    "        fileSaveName = \"Model_m4\"\n",
    "    \n",
    "    elif(modelNumber == 5):\n",
    "        model = model_m5()\n",
    "        fileSaveName = \"Model_m5\"\n",
    "    elif(modelNumber == 6):\n",
    "        model = model_m6()\n",
    "        fileSaveName = \"Model_m6\"\n",
    "    elif(modelNumber == 7):\n",
    "        model = Model_m7()\n",
    "        fileSaveName = \"Model_m7\"\n",
    "    elif(modelNumber == 8):\n",
    "        model = Model_m8()\n",
    "        fileSaveName = \"Model_m8\"\n",
    "    else:\n",
    "        raise Exception(\"No model identified, model {} DNE.\".format(modelNumber))\n",
    "    \n",
    "\n",
    "    modelPath = os.path.join(os.getcwd(),'ModelSave',fileSaveName)\n",
    "    \n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelPath,fileSaveName),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    if(os.path.isdir(modelPath)):\n",
    "        try:\n",
    "            \n",
    "            model.load_weights(os.path.join(modelPath,fileSaveName))\n",
    "        except:\n",
    "            print(\"Model weights could not be loaded.\")\n",
    "        else:\n",
    "            print(\"Model weights Loaded\")\n",
    "    else:\n",
    "        os.mkdir(modelPath)\n",
    "        print(\"Model path created\")\n",
    "\n",
    "    if(modelNumber == 1 or modelNumber == 6 ):\n",
    "        model.compile(optimizer=SetUpOptimizer(1),\n",
    "                        loss={\n",
    "                            'x_out':keras.losses.BinaryCrossentropy(), #logrithmic error for the 0-1 output of the image\n",
    "                            'finished':keras.losses.BinaryCrossentropy(from_logits=True) #binary entropy error for the bool output\n",
    "                        },\n",
    "                        loss_weights={'x_out':1.0,'finished':0.01})\n",
    "    elif(modelNumber == 4 or modelNumber == 5 or modelNumber == 7 or modelNumber == 8):\n",
    "        model.compile(  optimizer=SetUpOptimizer(optimizerVarient),\n",
    "                        loss= keras.losses.BinaryCrossentropy()\n",
    "                        )\n",
    "    return model,cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights Loaded\n",
      "Optimizer: Adam\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " forces (InputLayer)            [(None, 101, 51, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " x (InputLayer)                 [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " resizing_1 (Resizing)          (None, 128, 64, 2)   0           ['forces[0][0]']                 \n",
      "                                                                                                  \n",
      " supports (InputLayer)          [(None, 101, 51, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " filled (InputLayer)            [(None, 100, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " resizing (Resizing)            (None, 128, 64, 1)   0           ['x[0][0]']                      \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 128, 64, 2)   0           ['resizing_1[0][0]']             \n",
      "                                                                                                  \n",
      " resizing_2 (Resizing)          (None, 128, 64, 1)   0           ['supports[0][0]']               \n",
      "                                                                                                  \n",
      " resizing_3 (Resizing)          (None, 128, 64, 1)   0           ['filled[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 64, 5)   0           ['resizing[0][0]',               \n",
      "                                                                  'activation[0][0]',             \n",
      "                                                                  'resizing_2[0][0]',             \n",
      "                                                                  'resizing_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 64, 16)  736         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 64, 16)  2320        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 32, 16)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 64, 32, 16)  0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 32, 32)   4640        ['gaussian_noise[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 32, 32)   9248        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 16, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (GaussianNois  (None, 32, 16, 32)  0           ['max_pooling2d_1[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 16, 64)   18496       ['gaussian_noise_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 16, 64)   36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 8, 64)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " gaussian_noise_2 (GaussianNois  (None, 16, 8, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 8, 128)   73856       ['gaussian_noise_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 8, 128)   147584      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 16, 64)  204864      ['conv2d_7[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " gaussian_noise_3 (GaussianNois  (None, 32, 16, 64)  0           ['conv2d_transpose[0][0]']       \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 16, 128)  0           ['gaussian_noise_3[0][0]',       \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 16, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 16, 64)   36928       ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 32, 32)  51232       ['conv2d_9[0][0]']               \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " gaussian_noise_4 (GaussianNois  (None, 64, 32, 32)  0           ['conv2d_transpose_1[0][0]']     \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 32, 64)   0           ['gaussian_noise_4[0][0]',       \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 32, 32)   18464       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 32, 32)   9248        ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 64, 64)  51264      ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 64, 80)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 64, 16)  11536       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 64, 16)  2320        ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " resizing_4 (Resizing)          (None, 100, 50, 16)  0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " x_out (Conv2D)                 (None, 100, 50, 1)   17          ['resizing_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 753,473\n",
      "Trainable params: 753,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "currentModelNumber = 8 #change this one\n",
    "model,callBack = getModel(currentModelNumber)\n",
    "print()\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFirstIterationDataSet(sequenceData):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    x_optimized_array =[]\n",
    "    finished_array = []\n",
    "    for i in range(len(sequenceData)):\n",
    "        force,support,filled,x_start,x_optimized,finished = sequenceData[i].dispenceFirstIterationData()\n",
    "        for f in force:\n",
    "            forces_array.append(f)\n",
    "        for s in support:\n",
    "            support_array.append(s)\n",
    "        for f in filled:\n",
    "            filled_array.append(f)\n",
    "        for x in x_start:\n",
    "            x_array.append(x)\n",
    "        for x in x_optimized:\n",
    "            x_optimized_array.append(x)\n",
    "        for f in finished:\n",
    "            finished_array.append(f)\n",
    "    \n",
    "    x_array = np.array(x_array)\n",
    "    forces_array = np.array(forces_array)\n",
    "    support_array = np.array(support_array)\n",
    "    filled_array = np.array(filled_array)\n",
    "    x_optimized_array = np.array(x_optimized_array)\n",
    "    finished_array = np.array(finished_array)\n",
    "\n",
    "    return x_array, forces_array, support_array, filled_array, x_optimized_array, finished_array\n",
    "\n",
    "\n",
    "def createFullIterationDataSet(sequenceData,indexesToUse,iterationJump:int=5):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    x_optimized_array =[]\n",
    "    finished_array = []\n",
    "    for i in indexesToUse:\n",
    "        force,support,filled,x_start,x_optimized,finished = sequenceData[i].dispenceData(iterationJump)\n",
    "        for f in force:\n",
    "            forces_array.append(f)\n",
    "        for s in support:\n",
    "            support_array.append(s)\n",
    "        for f in filled:\n",
    "            filled_array.append(f)\n",
    "        for x in x_start:\n",
    "            x_array.append(x)\n",
    "        for x in x_optimized:\n",
    "            x_optimized_array.append(x)\n",
    "        for f in finished:\n",
    "            finished_array.append(f)\n",
    "    \n",
    "    x_array = np.array(x_array)\n",
    "    forces_array = np.array(forces_array)\n",
    "    support_array = np.array(support_array)\n",
    "    filled_array = np.array(filled_array)\n",
    "    x_optimized_array = np.array(x_optimized_array)\n",
    "    finished_array = np.array(finished_array)\n",
    "\n",
    "    return x_array, forces_array, support_array, filled_array, x_optimized_array, finished_array\n",
    "\n",
    "\n",
    "def CreateAugmentedFullIterationDataSet(sequenceData,indexesToUse_train,indexToUse_predict,iterationJump:int=5):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    x_optimized_array =[]\n",
    "    finished_array = []\n",
    "\n",
    "\n",
    "    for index in indexToUse_predict:\n",
    "        part_pred,forces_pred,supports_pred,filled_pred,_,_ = createFullIterationDataSet(sequenceData,[index],iterationJump)\n",
    "\n",
    "        output = model.predict({'x':part_pred,'forces':forces_pred,'supports':supports_pred,'filled':filled_pred})\n",
    "        Y_pred_part = output[0]\n",
    "\n",
    "        force,support,filled,x_start,x_optimized,finished = sequenceData[index].formatPredictedData(Y_pred_part)\n",
    "\n",
    "        for f in force:\n",
    "            forces_array.append(f)\n",
    "        for s in support:\n",
    "            support_array.append(s)\n",
    "        for f in filled:\n",
    "            filled_array.append(f)\n",
    "        for x in x_start:\n",
    "            x_array.append(np.reshape(x,(100,50)))\n",
    "        for x in x_optimized:\n",
    "            x_optimized_array.append(x)\n",
    "        for f in finished:\n",
    "            finished_array.append(f)\n",
    "\n",
    "    for index in indexesToUse_train:\n",
    "        force,support,filled,x_start,x_optimized,finished = sequenceData[index].dispenceData(iterationJump)\n",
    "        for f in force:\n",
    "            forces_array.append(f)\n",
    "        for s in support:\n",
    "            support_array.append(s)\n",
    "        for f in filled:\n",
    "            filled_array.append(f)\n",
    "        for x in x_start:\n",
    "            x_array.append(x)\n",
    "        for x in x_optimized:\n",
    "            x_optimized_array.append(x)\n",
    "        for f in finished:\n",
    "            finished_array.append(f)\n",
    "\n",
    "    #print(x_array)\n",
    "    \n",
    "    x_array = np.array(x_array)\n",
    "    forces_array = np.array(forces_array)\n",
    "    support_array = np.array(support_array)\n",
    "    filled_array = np.array(filled_array)\n",
    "    x_optimized_array = np.array(x_optimized_array)\n",
    "    finished_array = np.array(finished_array)\n",
    "\n",
    "    return x_array, forces_array, support_array, filled_array, x_optimized_array, finished_array\n",
    "\n",
    "\n",
    "def TrainFirstIteration_2OutputModel(numEpochs,data_train,data_test,saveModelCallback):\n",
    "    \"\"\"\n",
    "    Train the model according the the predefined method\n",
    "\n",
    "        1. Model will be trained on all input data for 1 epoch with the first iterations only\n",
    "    \"\"\"\n",
    "\n",
    "    #build data for first Iteration\n",
    "    part,forces,supports,filled,x_true,finished = createFirstIterationDataSet(data_train)\n",
    "    X_test_part,X_test_forces,X_test_supports,X_test_filled,Y_test_x,Y_test_finished = createFirstIterationDataSet(data_test)\n",
    "\n",
    "    # print(f'part:{part.shape}')\n",
    "    # print(f'forces:{forces.shape}')\n",
    "    # print(f'supports:{supports.shape}')\n",
    "    # print(f'filled:{filled.shape}')\n",
    "    # print(f'x_true:{x_true.shape}')\n",
    "    # print(f'finished:{finished.shape}')\n",
    "\n",
    "    history = model.fit(\n",
    "                            {'x':part,'forces':forces,'supports':supports,'filled':filled},\n",
    "                            {'x_out':x_true,'finished':finished},\n",
    "                            epochs=numEpochs,\n",
    "                            shuffle=True,\n",
    "                            validation_data=(\n",
    "                                            {'x':X_test_part,'forces':X_test_forces,'supports':X_test_supports,'filled':X_test_filled},\n",
    "                                            {'x_out':Y_test_x,'finished':Y_test_finished}),\n",
    "                            callbacks=[saveModelCallback])\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def TrainFullIteration_2OutputModel(numEpochs,data_train,data_test,saveModelCallback,iterationJump:int=5):\n",
    "    \"\"\"\n",
    "    Train the model according the the predefined method\n",
    "        The first iteration will train on 1/(numEpochs)% of the full data\n",
    "        The following iterations will predict data and add that into the training data.\n",
    "        As the epochs continue more predicted data will be added to the mix but the same real data fraction will remain\n",
    "        At the final epoch all predicted data will be trained on.\n",
    "        \n",
    "    \"\"\"\n",
    "    #setup global parameters\n",
    "    DataTrainingIndexes = np.arange(len(data_train),dtype='int32')\n",
    "    np.random.shuffle(DataTrainingIndexes)\n",
    "\n",
    "    DataPredictionIndexes = np.arange(len(data_train),dtype='int32')\n",
    "    np.random.shuffle(DataPredictionIndexes)\n",
    "    \n",
    "    DataTestingIndexes = np.arange(len(data_test),dtype='int32')\n",
    "    np.random.shuffle(DataTrainingIndexes)\n",
    "\n",
    "    indexsPerEpoch = (len(DataTrainingIndexes)-1)//numEpochs\n",
    "    #print('indexsPerEpoch:',indexsPerEpoch)\n",
    "\n",
    "    historyArray = []\n",
    "\n",
    "\n",
    "    #first training NO predictions\n",
    "    \n",
    "    #print('DataTrainingIndexes:',DataTrainingIndexes[:indexsPerEpoch])\n",
    "    part,forces,supports,filled,x_true,finished = createFullIterationDataSet(data_train,DataTrainingIndexes[:indexsPerEpoch],iterationJump)\n",
    "    #print('DataTestingIndexes:',DataTestingIndexes)\n",
    "    X_test_part,X_test_forces,X_test_supports,X_test_filled,Y_test_x,Y_test_finished = createFullIterationDataSet(data_test,DataTestingIndexes,iterationJump)\n",
    "\n",
    "    #set up epoch data\n",
    "    BatchSize = 32 # default tensorflow batchsize\n",
    "    BatchesPerEpoch = (len(part)-1) // (BatchSize*numEpochs)\n",
    "    print(\"Training model on first non-augmented data:\")\n",
    "    history = model.fit(\n",
    "                            {'x':part,'forces':forces,'supports':supports,'filled':filled},\n",
    "                            {'x_out':x_true,'finished':finished},\n",
    "                            #batch_size=BatchSize,\n",
    "                            epochs=1,\n",
    "                            shuffle=True,\n",
    "                            validation_data=(\n",
    "                                            {'x':X_test_part,'forces':X_test_forces,'supports':X_test_supports,'filled':X_test_filled},\n",
    "                                            {'x_out':Y_test_x,'finished':Y_test_finished}),\n",
    "                            callbacks=[saveModelCallback])#,\n",
    "                            #steps_per_epoch = BatchesPerEpoch)\n",
    "    historyArray.append(history)\n",
    "\n",
    "    for i in range(1,numEpochs):\n",
    "\n",
    "        #build data for first Iteration\n",
    "        indexesToUse_train = DataTrainingIndexes[indexsPerEpoch*i:indexsPerEpoch*(i+1)]\n",
    "        \n",
    "        np.random.shuffle(DataPredictionIndexes)\n",
    "        indexesToUse_predict = DataPredictionIndexes[:indexsPerEpoch*(i+1)]\n",
    "\n",
    "        part,forces,supports,filled,x_true,finished = CreateAugmentedFullIterationDataSet(data_train,indexesToUse_train,indexesToUse_predict,iterationJump)\n",
    "        X_test_part,X_test_forces,X_test_supports,X_test_filled,Y_test_x,Y_test_finished = createFullIterationDataSet(data_test,DataTestingIndexes,iterationJump)\n",
    "\n",
    "        # print(f'part:{part.shape}')\n",
    "        # print(f'forces:{forces.shape}')\n",
    "        # print(f'supports:{supports.shape}')\n",
    "        # print(f'filled:{filled.shape}')\n",
    "        # print(f'x_true:{x_true.shape}')\n",
    "        # print(f'finished:{finished.shape}')\n",
    "\n",
    "        #set up epoch data\n",
    "        BatchSize = 32 # default tensorflow batchsize\n",
    "        BatchesPerEpoch = (len(part)-1) // (BatchSize*i)\n",
    "        percentAugmented = len(indexesToUse_predict)/(len(indexesToUse_train) + len(indexesToUse_predict))\n",
    "        print(\"\\nTraining model on augmented data {} of {} with {} data points({}% augmented):\".format(i,numEpochs,len(part),percentAugmented))\n",
    "\n",
    "        history = model.fit(\n",
    "                                {'x':part,'forces':forces,'supports':supports,'filled':filled},\n",
    "                                {'x_out':x_true,'finished':finished},\n",
    "                                batch_size=BatchSize,\n",
    "                                epochs=i,\n",
    "                                shuffle=True,\n",
    "                                validation_data=(\n",
    "                                                {'x':X_test_part,'forces':X_test_forces,'supports':X_test_supports,'filled':X_test_filled},\n",
    "                                                {'x_out':Y_test_x,'finished':Y_test_finished}),\n",
    "                                callbacks=[saveModelCallback],\n",
    "                                steps_per_epoch = BatchesPerEpoch)\n",
    "        historyArray.append(history)\n",
    "    \n",
    "    return historyArray\n",
    "\n",
    "\n",
    "def Train2OutputModel(numEpochs,data_train,data_test,saveModelCallback):\n",
    "    \"\"\"\n",
    "    Train the model according the the predefined method\n",
    "\n",
    "        1. Model will be trained on all input data for 1 epoch with the first iterations only\n",
    "        2. Model will then begin 10 batch trainings where at the end of each batch predicted data is added into the training set.\n",
    "    \"\"\"\n",
    "    iterationJump = 1\n",
    "    print(\"Training model on first Iteration dataset\")\n",
    "    firstIterationHistory = TrainFirstIteration_2OutputModel(numEpochs//2,data_train,data_test,saveModelCallback)\n",
    "    print(\"Training model on full dataset\")\n",
    "    fullIterationHistory = TrainFullIteration_2OutputModel(numEpochs,data_train,data_test,saveModelCallback,iterationJump)\n",
    "\n",
    "    #firstIterationHistory = TrainFirstIteration_2OutputModel(1,data_train,data_test,saveModelCallback)\n",
    "    #firstIterationHistory = None\n",
    "    #fullIterationHistory = TrainFullIteration_2OutputModel(2,data_train,data_test,saveModelCallback,iterationJump)\n",
    "\n",
    "    return firstIterationHistory,fullIterationHistory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h1,h2 = Train2OutputModel(10,Data_train,Data_test,callBack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Pretrain_SubcalssModelTrainingSet(data,predictionDepth:int=5):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    x_pred= []\n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    f3 = []\n",
    "    f4 = []\n",
    "    f5 = []\n",
    "    for j in range(predictionDepth):\n",
    "        x_pred.append([])\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        force,support,filled,x_start,x_optimized,finished = Data_train[i].dispenceM7modelData(predictionDepth)\n",
    "        forces_array.append(force[0])\n",
    "        support_array.append(support[0])\n",
    "        filled_array.append(filled[0])\n",
    "        x_array.append(x_start[0])\n",
    "\n",
    "        for j in range(predictionDepth):\n",
    "            x_pred[j].append(x_optimized[0][j])\n",
    "\n",
    "    \n",
    "    x_array = np.array(x_array)\n",
    "    forces_array = np.array(forces_array)\n",
    "    support_array = np.array(support_array)\n",
    "    filled_array = np.array(filled_array)\n",
    "    x_pred_return = []\n",
    "    for j in range(predictionDepth):\n",
    "        x_pred_return.append(np.array(x_pred[j]))\n",
    "\n",
    "    return x_array,forces_array,support_array,filled_array,x_pred_return\n",
    "\n",
    "\n",
    "\n",
    "def Pretrain_modelm7(run=False):\n",
    "\n",
    "    x_array,forces_array,support_array,filled_array,x_pred = create_Pretrain_SubcalssModelTrainingSet(Data_train,5)\n",
    "    x1=x_pred[0]\n",
    "    x2=x_pred[1]\n",
    "    x3=x_pred[2]\n",
    "    x4=x_pred[3]\n",
    "    x5=x_pred[4]\n",
    "\n",
    "    x_array_test,forces_array_test,support_array_test,filled_array_test,x_pred_test = create_Pretrain_SubcalssModelTrainingSet(Data_test,5)\n",
    "    x1_test=x_pred_test[0]\n",
    "    x2_test=x_pred_test[1]\n",
    "    x3_test=x_pred_test[2]\n",
    "    x4_test=x_pred_test[3]\n",
    "    x5_test=x_pred_test[4]\n",
    "\n",
    "    numEpochs = 5\n",
    "    BatchSize = 32 # default tensorflow batchsize\n",
    "    numBatches = len(x_array) // BatchSize\n",
    "    BatchesPerEpoch = numBatches// numEpochs\n",
    "    print(\"Pretraining model over {} epochs.\\n\\tnumSamples: {}\\n\\tnumBatches: {}\\n\\tBatches per Epoch:{}\\n\".format(numEpochs,len(x_array),numBatches,BatchesPerEpoch))\n",
    "    if(run):\n",
    "        history1 = model.fit(\n",
    "            x={'x':x_array,'forces':forces_array,'supports':support_array,'filled':filled_array},\n",
    "            y=(x1,x2,x3,x4,x5),\n",
    "            #validation_split = 0.1,\n",
    "            batch_size=BatchSize,\n",
    "            validation_data=(\n",
    "                    {'x':x_array_test,'forces':forces_array_test,'supports':support_array_test,'filled':filled_array_test},\n",
    "                    x1_test),\n",
    "            epochs=numEpochs,\n",
    "            shuffle=True,\n",
    "            steps_per_epoch = BatchesPerEpoch,\n",
    "            callbacks = [callBack])\n",
    "        return history1\n",
    "    else:\n",
    "        return len(x_array)\n",
    "    \n",
    "h2 = Pretrain_modelm7(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(hist):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.set_title(\"\")\n",
    "    keys = hist.history.keys()\n",
    "    y = np.arange(1,hist.params['epochs']+1)\n",
    "    for key in keys:\n",
    "        if('output' in key):\n",
    "            minVal = min(hist.history[key])\n",
    "            meanVal = np.mean(hist.history[key])\n",
    "            maxVal = max(hist.history[key])\n",
    "            if(minVal != maxVal):\n",
    "                print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "                #ax.plot(y,hist.history[key],linewidth=0.5,label=key)\n",
    "        else:\n",
    "            ax.plot(y,hist.history[key],label=key)\n",
    "            minVal = min(hist.history[key])\n",
    "            meanVal = np.mean(hist.history[key])\n",
    "            maxVal = max(hist.history[key])\n",
    "            print(\"{}:\\n\\tmin:{}\\n\\tmean:{}\\n\\tmax:{}\".format(key,minVal,meanVal,maxVal))\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubcalssModelTrainingSet(data,predictionDepth:int=5):\n",
    "    forces_array = []\n",
    "    support_array = []\n",
    "    filled_array = []\n",
    "    x_array = []\n",
    "    x_pred= []\n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    f3 = []\n",
    "    f4 = []\n",
    "    f5 = []\n",
    "    for j in range(predictionDepth):\n",
    "        x_pred.append([])\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        force,support,filled,x_start,x_optimized,finished = Data_train[i].dispenceM7modelData(predictionDepth)\n",
    "        for f in force:\n",
    "            forces_array.append(f)\n",
    "        for s in support:\n",
    "            support_array.append(s)\n",
    "        for f in filled:\n",
    "            filled_array.append(f)\n",
    "        for x in x_start:\n",
    "            x_array.append(x)\n",
    "\n",
    "        for x_optimized_array in x_optimized:\n",
    "            for j in range(predictionDepth):\n",
    "                x_pred[j].append(x_optimized_array[j])\n",
    "\n",
    "    \n",
    "    x_array = np.array(x_array)\n",
    "    forces_array = np.array(forces_array)\n",
    "    support_array = np.array(support_array)\n",
    "    filled_array = np.array(filled_array)\n",
    "    x_pred_return = []\n",
    "    for j in range(predictionDepth):\n",
    "        x_pred_return.append(np.array(x_pred[j]))\n",
    "\n",
    "    return x_array,forces_array,support_array,filled_array,x_pred_return\n",
    "\n",
    "def train_Test_modelm7(run=False):\n",
    "\n",
    "    x_array,forces_array,support_array,filled_array,x_pred = createSubcalssModelTrainingSet(Data_train,5)\n",
    "    x1=x_pred[0]\n",
    "    x2=x_pred[1]\n",
    "    x3=x_pred[2]\n",
    "    x4=x_pred[3]\n",
    "    x5=x_pred[4]\n",
    "\n",
    "    x_array_test,forces_array_test,support_array_test,filled_array_test,x_pred_test = createSubcalssModelTrainingSet(Data_test,5)\n",
    "    x1_test=x_pred_test[0]\n",
    "    x2_test=x_pred_test[1]\n",
    "    x3_test=x_pred_test[2]\n",
    "    x4_test=x_pred_test[3]\n",
    "    x5_test=x_pred_test[4]\n",
    "\n",
    "    numEpochs = 50\n",
    "    BatchSize = 32 # 32 is default tensorflow batchsize\n",
    "    numBatches = len(x_array) // BatchSize\n",
    "    BatchesPerEpoch = numBatches// numEpochs\n",
    "    print(\"Training model over {} epochs.\\n\\tnumSamples: {}\\n\\tnumBatches: {}\\n\\tBatches per Epoch:{}\\n\".format(numEpochs,len(x_array),numBatches,BatchesPerEpoch))\n",
    "    if(run):\n",
    "        history1 = model.fit(\n",
    "            x={'x':x_array,'forces':forces_array,'supports':support_array,'filled':filled_array},\n",
    "            y=(x1,x2,x3,x4,x5),\n",
    "            #validation_split = 0.1,\n",
    "            batch_size=BatchSize,\n",
    "            validation_data=(\n",
    "                    {'x':x_array_test,'forces':forces_array_test,'supports':support_array_test,'filled':filled_array_test},\n",
    "                    x1_test),\n",
    "            epochs=numEpochs,\n",
    "            shuffle=True,\n",
    "            steps_per_epoch = BatchesPerEpoch,\n",
    "            callbacks = [callBack])\n",
    "        \n",
    "        return history1\n",
    "    \n",
    "\n",
    "#train_Test_modelm7()\n",
    "h3 = train_Test_modelm7(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the true and predicted Values\n",
    "ncol = 5\n",
    "nelx = 100\n",
    "nely = 50\n",
    "\n",
    "fig,ax = plt.subplots(3,ncol)\n",
    "\n",
    "rnd = np.arange(len(part),dtype='int32')\n",
    "np.random.shuffle(rnd)\n",
    "\n",
    "for i in range(ncol):\n",
    "    print(rnd[i],end='\\t')\n",
    "    ax[0,i].set_title(\"Input\")\n",
    "    ax[0,i].imshow(np.reshape(part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,i].get_xaxis().set_visible(False)\n",
    "    ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[1,i].set_title(\"True\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,i].imshow(np.reshape(x_true[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,i].get_xaxis().set_visible(False)\n",
    "    ax[1,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[2,i].set_title(\"Predicted\")#:{}\".format(finalBit(Y_pred_finished[rnd[i]])))\n",
    "    ax[2,i].imshow(np.reshape(Y_pred_part[rnd[i]],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[2,i].get_xaxis().set_visible(False)\n",
    "    ax[2,i].get_yaxis().set_visible(False)\n",
    "\n",
    "print()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EditImage(image):\n",
    "\n",
    "    #noise = np.random.normal(loc=0,scale=.05,size=image.shape)\n",
    "    #return image + noise\n",
    "\n",
    "    return np.flip(image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawModelIteratins(num):\n",
    "    sequenceToStart:TopOptSequence = Data_score[num]\n",
    "    numImages = sequenceToStart.numIterations\n",
    "    imagesToShow = 5\n",
    "    #print(numImages)\n",
    "    fig,ax = plt.subplots(2,imagesToShow)\n",
    "\n",
    "    sequenceToStart.dispenceData()\n",
    "\n",
    "    nelx = 100\n",
    "    nely = 50\n",
    "    force,support,filled,x_start,x_optimized,finished = sequenceToStart.dispenceData(1)\n",
    "\n",
    "    force = np.array([force[0]])\n",
    "    force = EditImage(force)\n",
    "    support = EditImage(np.array([support[0]]))\n",
    "    filled = EditImage(np.array([filled[0]]))\n",
    "    ImageToPredict = np.array([sequenceToStart.xPhys_array[:,:,0]])\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages):\n",
    "        \n",
    "        output = model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages,end-start,(end-start)/numImages))\n",
    "    imagesToJump = numImages // imagesToShow\n",
    "\n",
    "    for i in range(0,imagesToShow-1):\n",
    "        ax[0,i].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[0,i].get_xaxis().set_visible(False)\n",
    "        ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "        #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "        ax[1,i].imshow(np.reshape(PredictedImages[i*imagesToJump],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax[1,i].get_xaxis().set_visible(False)\n",
    "        ax[1,i].get_yaxis().set_visible(False)\n",
    "    ax[0,-1].imshow(np.reshape(sequenceToStart.xPhys_array[:,:,-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[0,-1].get_xaxis().set_visible(False)\n",
    "    ax[0,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    #ax[1,i].set_title(\"Pred\")#:{}\".format(finalBit(Y_score_finished[rnd[i]])))\n",
    "    ax[1,-1].imshow(np.reshape(PredictedImages[-1],(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "    ax[1,-1].get_xaxis().set_visible(False)\n",
    "    ax[1,-1].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[0,0].set_title(\"True\")\n",
    "    ax[1,0].set_title(\"Pred\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "19 iterations took 1.62 seconds or about 0.08524 seconds per iteration.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 28#np.random.randint(0,len(Data_score)-1)\n",
    "print(n)\n",
    "DrawModelIteratins(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14952/3699023041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#n = np.arange(len(Data_score),dtype='int32')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "#n = np.random.randint(0,len(Data_score)-1)\n",
    "n = np.arange(len(Data_score),dtype='int32')\n",
    "np.random.shuffle(n)\n",
    "print(len(n))\n",
    "for i in range(10):\n",
    "    DrawModelIteratins(n[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model because I'm paranoid\n",
    "checkpoint_path = r\"E:\\TopoptGAfileSaves\\Models\\Model_m6\"\n",
    "model.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOverIterations(index,data):\n",
    "    sequenceToStart = data[index]\n",
    "    numImages = sequenceToStart.numIterations\n",
    "    imagesToShow = numImages\n",
    "    #print(numImages)\n",
    "\n",
    "    sequenceToStart.dispenceData()\n",
    "\n",
    "    nelx = 100\n",
    "    nely = 50\n",
    "    force,support,filled,x_start,x_optimized,finished = sequenceToStart.dispenceData(1)\n",
    "\n",
    "    force = np.array([force[0]])\n",
    "    support = np.array([support[0]])\n",
    "    filled = np.array([filled[0]])\n",
    "    ImageToPredict = np.array([sequenceToStart.xPhys_array[:,:,0]])\n",
    "    PredictedImages = [ImageToPredict]\n",
    "\n",
    "\n",
    "    start = time()\n",
    "    for i in range(numImages * 3):\n",
    "        \n",
    "        output = model.predict({'x':ImageToPredict,'forces':force,'supports':support,'filled':filled},verbose = 0)\n",
    "        ImageToPredict = output#[0]\n",
    "        PredictedImages.append(ImageToPredict)\n",
    "    end = time()\n",
    "    print(\"{} iterations took {:.2f} seconds or about {:.5f} seconds per iteration.\".format(numImages,end-start,(end-start)/numImages))\n",
    "    imagesToJump = 1\n",
    "    imageArray = []\n",
    "\n",
    "    for i,image in enumerate(PredictedImages):\n",
    "        fig,ax = plt.subplots(1,1)\n",
    "        \n",
    "        if(i == 0):\n",
    "            ax.set_title(\"Iteration: {}\".format(i))\n",
    "        else:\n",
    "            im1 = np.reshape(PredictedImages[i],(nelx*nely))\n",
    "            im2 = np.reshape(PredictedImages[i-1],(nelx*nely))\n",
    "            ax.set_title(\"Iteration: {}, Change: {:.5f}\".format(i,np.linalg.norm(im1-im2,ord=np.inf)))\n",
    "        ax.imshow(np.reshape(image,(nelx,nely)).T,cmap='gray_r',norm=colors.Normalize(vmin=0,vmax=1))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        img_buf = io.BytesIO()\n",
    "        plt.savefig(img_buf, format='png')\n",
    "\n",
    "        im = Image.open(img_buf)\n",
    "        imageArray.append(im)\n",
    "\n",
    "        #plt.show()\n",
    "    return imageArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesToSave = 10\n",
    "rnd = np.arange(imagesToSave,dtype='int32')\n",
    "np.random.shuffle(rnd)\n",
    "for i in range(10):\n",
    "    im_array = plotOverIterations(rnd[i],Data)\n",
    "    im = im_array[0]\n",
    "    im_array.pop(0)\n",
    "    im.save(\"out{}.gif\".format(i),save_all=True,append_images = im_array,optimize=False,loop=0)\n",
    "    im.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thoughts</h1>\n",
    "\n",
    "M6: Looking at the model at work shows progress when loads are grouped up. Failures seem to occur with spaced load conditions and low volfrac."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
