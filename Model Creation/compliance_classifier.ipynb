{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH= os.path.join(os.path.dirname(os.getcwd()),r\"DataGathering\\Data\\30_30\")\n",
    "#print(DATA_FILE_PATH)\n",
    "\n",
    "dir_list = os.listdir(DATA_FILE_PATH)\n",
    "max_data_points = len(dir_list)\n",
    "print(\"Number of data points: {}\".format(len(dir_list)))\n",
    "print(dir_list[0])\n",
    "\n",
    "#print(os.listdir(os.path.join(DATA_FILE_PATH,dir_list[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgent(path):\n",
    "\n",
    "    filesToPull = os.listdir(path)\n",
    "\n",
    "    dataPoints = []\n",
    "\n",
    "    for fileName in filesToPull:\n",
    "        try:\n",
    "\n",
    "            data = np.load(os.path.join(path,fileName),allow_pickle=True)\n",
    "\n",
    "            xPhys = data['a']\n",
    "            forces = data['b']\n",
    "            degreesOfFreedom = data['c']\n",
    "            formating_array = data['d']\n",
    "\n",
    "            maxDof = forces.shape[0]\n",
    "            toPad = maxDof - len(degreesOfFreedom)\n",
    "            degreesOfFreedom = np.pad(degreesOfFreedom,[0,toPad])\n",
    "\n",
    "            compliance = formating_array[0]\n",
    "            compliance_max = formating_array[1]\n",
    "            shape = formating_array[2:]\n",
    "\n",
    "            #forces = np.reshape(forces,(shape[0],shape[1],4))\n",
    "\n",
    "            dataPoints.append([xPhys,forces,degreesOfFreedom,compliance_max,shape,compliance])\n",
    "\n",
    "        except:\n",
    "            print(\"Error in reading file couldn't get file: {}\".format(fileName))\n",
    "    \n",
    "    return dataPoints\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some basig information about the shapes of the data\n",
    "d1 = getAgent(os.path.join(DATA_FILE_PATH,dir_list[0]))\n",
    "\n",
    "print(\"xPhys.shape:\",d1[0][0].shape)\n",
    "print(\"forces.shape:\",d1[0][1].shape)\n",
    "print(\"dofs.shape:\",d1[0][2].shape)\n",
    "print(\"c-Max:\",d1[0][3])\n",
    "print(\"compliance:\",d1[0][5])\n",
    "print(\"shape:\",d1[0][4])\n",
    "\n",
    "shape_of_Inputs = d1[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d1[0][2]\n",
    "print(d.shape)\n",
    "\n",
    "d2 = np.ones(2*31*31)\n",
    "for index in d:\n",
    "    d2[index] = 0\n",
    "\n",
    "d3 = np.reshape(d2,(31,31,2))\n",
    "print(d3.shape)\n",
    "\n",
    "d4 = d3.sum(2)\n",
    "print(d4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(xPhys,forces,degreesOfFreedom,compliance_max,shape):\n",
    "    finalShape = (int(shape[0]+1),int(shape[1]+1))\n",
    "    xPhysShape = xPhys.shape\n",
    "    difference = (int(finalShape[0]-xPhysShape[0]),int(finalShape[1]-xPhysShape[1]))\n",
    "    xPhys2 = np.pad(xPhys,[[0,difference[0]],[0,difference[1]]])\n",
    "\n",
    "    forces2 = forces.sum(1)\n",
    "    forces2 = np.reshape(forces2,(finalShape[0],finalShape[1],2))\n",
    "\n",
    "    d2 = np.ones(2*finalShape[0]*finalShape[1])\n",
    "    for index in degreesOfFreedom:\n",
    "        d2[index] = 0\n",
    "    d3 = np.reshape(d2,(finalShape[0],finalShape[1],2))\n",
    "    degreesOfFreedom2 = d3.sum(2)\n",
    "\n",
    "    c_max = compliance_max * np.ones((finalShape[0],finalShape[1]))\n",
    "\n",
    "    arraysToStack = [xPhys2,forces2[:,:,0],forces2[:,:,1],degreesOfFreedom2]\n",
    "    #for ar in arraysToStack:\n",
    "    #    print(ar.shape)\n",
    "\n",
    "    fullPart = np.stack(arraysToStack,axis=-1).astype('float32')\n",
    "\n",
    "    return [xPhys2,forces2,degreesOfFreedom2,compliance_max]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xPhys,forces,degreesOfFreedom,compliance_max,shape,compliance in getAgent(os.path.join(DATA_FILE_PATH,dir_list[0])):\n",
    "    data = formatData(xPhys,forces,degreesOfFreedom,compliance_max,shape)\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data\n",
    "points_to_Use = 100000\n",
    "\"\"\"\n",
    "1000    = 11 seconds\n",
    "10000   = 4 minutes\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "points_to_Use = min(points_to_Use,max_data_points)\n",
    "\n",
    "# can use an np.arrange and np.random.shuffle to get random data points every time\n",
    "pointsShuffeled = np.arange(max_data_points).astype(\"int32\")\n",
    "np.random.shuffle(pointsShuffeled)\n",
    "\n",
    "\n",
    "compliancesToMutateFrom = 0 # number of extra compliance_max value to add to add variety to the data\n",
    "ComplianceRange = 10\n",
    "\n",
    "bad\n",
    "\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(points_to_Use):\n",
    "    data1 = getAgent(os.path.join(DATA_FILE_PATH,dir_list[pointsShuffeled[i]]))\n",
    "    for xPhys,forces,degreesOfFreedom,compliance_max,shape,compliance in data1: \n",
    "        x = formatData(xPhys,forces,degreesOfFreedom,compliance_max,shape)\n",
    "        data_x.append(x)\n",
    "        y_val = np.log(compliance).astype('float32')\n",
    "        data_y.append(y_val)\n",
    "        if(y_val <= 0):\n",
    "            #print(i,compliance)\n",
    "            data_x.pop()\n",
    "            data_y.pop()\n",
    "        for j in range(compliancesToMutateFrom):\n",
    "            newC_max = compliance + (np.random.random()-0.5) * ComplianceRange\n",
    "            x = formatData(xPhys,forces,degreesOfFreedom,compliance_max,shape)\n",
    "            data_x.append(x)\n",
    "            data_y.append(np.array([1*(newC_max >= compliance)]).astype('float32')) \n",
    "\n",
    "#data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "print(len(data_x))\n",
    "print(len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some statistics on the data\n",
    "numTrue = 0\n",
    "numFalse = 0\n",
    "\n",
    "numTrue = int(data_y.sum())\n",
    "numFalse = len(data_y) - numTrue\n",
    "\n",
    "print(numTrue)\n",
    "print(numFalse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some statistics on the data\n",
    "\n",
    "yMax = np.max(data_y)\n",
    "yMin = np.min(data_y)\n",
    "\n",
    "print(yMax)\n",
    "print(yMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test  = train_test_split(data_x,data_y, test_size=0.25, random_state=42)\n",
    "print(\"X_train: {}\\nY_train: {}\".format(len(X_train), len(Y_train)))\n",
    "print(\"X_test: {}\\nY_test: {}\".format(len(X_test), len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part = []\n",
    "X_train_compliance = []\n",
    "X_train_forces=[]\n",
    "X_train_supports = []\n",
    "\n",
    "X_test_part = []\n",
    "X_test_compliance = []\n",
    "X_test_forces=[]\n",
    "X_test_supports = []\n",
    "\n",
    "for x,f,dof,compliance_max in X_train:\n",
    "    X_train_part.append(x)\n",
    "    X_train_forces.append(f)\n",
    "    X_train_supports.append(dof)\n",
    "    X_train_compliance.append(compliance)\n",
    "\n",
    "for x,f,dof,compliance_max in X_test:\n",
    "    X_test_part.append(x)\n",
    "    X_test_forces.append(f)\n",
    "    X_test_supports.append(dof)\n",
    "    X_test_compliance.append(compliance)\n",
    "\n",
    "X_train_part = np.array(X_train_part)\n",
    "X_train_forces = np.array(X_train_forces)\n",
    "X_train_supports = np.array(X_train_supports)\n",
    "X_train_compliance = np.array(X_train_compliance)\n",
    "\n",
    "X_test_part = np.array(X_test_part)\n",
    "X_test_forces = np.array(X_test_forces)\n",
    "X_test_supports = np.array(X_test_supports)\n",
    "X_test_compliance = np.array(X_test_compliance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToSavePath = os.path.join(os.path.dirname(os.getcwd()),r\"Model Creation\\models\\complianceRegressor2\")\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=str(ToSavePath),\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "\n",
    "InputShape = (31,31,4)\n",
    "activation = 'relu'\n",
    "uniformRandomInitalizer = tf.random_uniform_initializer(minval=-0.1, maxval=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model will have a generic input of a 31 by 31 image with 4 channels representing the density grid, the forces in both the x and y direction, and the supports. A 5th channel, holding a matrix of compliance max values, will be stacked on the layers as they pass through each convolution. The same value will be concatenated in each dense layer once we flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1():\n",
    "    partInput = keras.Input(shape=InputShape,name=\"partImage\")\n",
    "    complianceMaxInput = keras.Input(shape=(1),name=\"complianceMax\")\n",
    "\n",
    "\n",
    "    x1 = layers.Conv2D(filters= 16,kernel_size=(3,3))(partInput)\n",
    "    cScaling = layers.Reshape((31,31,1))(layers.RepeatVector(31*31)(complianceMaxInput))\n",
    "\n",
    "    x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    x2 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x3 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    x_flat = layers.Flatten()(x3)\n",
    "    x4 = layers.concatenate([x_flat,complianceMaxInput])\n",
    "    x4 = layers.Dense(31,activation=activation)(x4)\n",
    "\n",
    "    x4 = layers.concatenate([x4,complianceMaxInput])\n",
    "    outputs = layers.Dense(2)(x4)\n",
    "    return keras.Model(inputs= [partInput,complianceMaxInput],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2():\n",
    "    partInput = keras.Input(shape=InputShape,name=\"partImage\")\n",
    "    complianceMaxInput = keras.Input(shape=(1),name=\"complianceMax\")\n",
    "\n",
    "\n",
    "    x1 = layers.Conv2D(filters= 16,kernel_size=(3,3))(partInput)\n",
    "    cScaling = layers.Reshape((31,31,1))(layers.RepeatVector(31*31)(complianceMaxInput))\n",
    "\n",
    "    x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "\n",
    "    newShape = (x1.shape[1],x1.shape[2])\n",
    "    #print(x1.shape)\n",
    "    #cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    x2 = layers.Concatenate()([x1,cScaling])\n",
    "    x2 = layers.Conv2D(filters= 25, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    x_flat = layers.Flatten()(x2)\n",
    "    x3 = layers.concatenate([x_flat,complianceMaxInput])\n",
    "    x3 = layers.Dense(31,activation=activation)(x3)\n",
    "\n",
    "    x4 = layers.concatenate([x3,complianceMaxInput])\n",
    "    outputs = layers.Dense(2)(x4)\n",
    "    return keras.Model(inputs= [partInput,complianceMaxInput],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m3():\n",
    "    partInput = keras.Input(shape=(31,31,1),name=\"partImage\")\n",
    "    forceInput = keras.Input(shape=(31,31,2),name=\"Forces\")\n",
    "    supportInput = keras.Input(shape=(31,31,1),name=\"Supports\")\n",
    "    complianceMaxInput = keras.Input(shape=(1),name=\"complianceMax\")\n",
    "\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 10,kernel_size=(3,3),padding='same',activation='tanh')(forceInput)\n",
    "    supportConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(supportInput)\n",
    "    cScaling = layers.Reshape((supportConv.shape[1],supportConv.shape[2],1))(layers.RepeatVector(supportConv.shape[1]*supportConv.shape[2])(complianceMaxInput))\n",
    "\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Dropout(0.1)(x1)\n",
    "    x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.Dropout(0.2)(x1)\n",
    "    x1 = layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same')(x1)\n",
    "\n",
    "    newShape = (x1.shape[1],x1.shape[2])\n",
    "    #print(x1.shape)\n",
    "    cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    #partScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(concatenatedConvolution)\n",
    "    x2 = layers.Concatenate()([x1,cScaling])\n",
    "    x2 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x2)\n",
    "\n",
    "    newShape = (x2.shape[1],x2.shape[2])\n",
    "    #print(x1.shape)\n",
    "    cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    x3 = layers.Concatenate()([x2,cScaling])\n",
    "    x3 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x3)\n",
    "    x3 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x3)\n",
    "    x3 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x3)\n",
    "\n",
    "    x_flat = layers.Flatten()(x3)\n",
    "    #x3 = layers.concatenate([x_flat,complianceMaxInput])\n",
    "    x4 = layers.Dense(32,activation=activation)(x_flat)\n",
    "    #x3 = layers.Dropout(0.2)(x3)\n",
    "\n",
    "    #x4 = layers.concatenate([x3,complianceMaxInput])\n",
    "    #outputs = layers.GlobalAveragePooling1D()(x4)\n",
    "    outputs = layers.Dense(1)(x4)\n",
    "    return keras.Model(inputs= [partInput,forceInput,supportInput,complianceMaxInput],outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m4_regression():\n",
    "    partInput = keras.Input(shape=(31,31,1),name=\"partImage\")\n",
    "    forceInput = keras.Input(shape=(31,31,2),name=\"Forces\")\n",
    "    supportInput = keras.Input(shape=(31,31,1),name=\"Supports\")\n",
    "    #complianceMaxInput = keras.Input(shape=(1),name=\"complianceMax\")\n",
    "\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 10,kernel_size=(3,3),padding='same',activation='tanh')(forceInput)\n",
    "    supportConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(supportInput)\n",
    "    #cScaling = layers.Reshape((supportConv.shape[1],supportConv.shape[2],1))(layers.RepeatVector(supportConv.shape[1]*supportConv.shape[2])(complianceMaxInput))\n",
    "\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "    x1 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Dropout(0.1)(x1)\n",
    "    #x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.Dropout(0.2)(x1)\n",
    "    x1 = layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same')(x1)\n",
    "\n",
    "    newShape = (x1.shape[1],x1.shape[2])\n",
    "    #print(x1.shape)\n",
    "    #cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    partScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(concatenatedConvolution)\n",
    "    x2 = layers.Concatenate()([x1,partScaling])\n",
    "    x2 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Conv2D(filters= 128, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x2)\n",
    "\n",
    "    newShape = (x2.shape[1],x2.shape[2])\n",
    "    #print(x1.shape)\n",
    "    #cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    #x3 = layers.Concatenate()([x2,cScaling])\n",
    "    x3 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x3 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x3)\n",
    "    x3 = layers.Dropout(0.3)(x3)\n",
    "    x3 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x3)\n",
    "\n",
    "    x_flat = layers.Flatten()(x3)\n",
    "    #x3 = layers.concatenate([x_flat,complianceMaxInput])\n",
    "    x4 = layers.Dense(32,activation=activation)(x_flat)\n",
    "    #x3 = layers.Dropout(0.2)(x3)\n",
    "\n",
    "    #x4 = layers.concatenate([x3,complianceMaxInput])\n",
    "    #outputs = layers.GlobalAveragePooling1D()(x4)\n",
    "    outputs = layers.Dense(1)(x4)\n",
    "    return keras.Model(inputs= [partInput,forceInput,supportInput],outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m5_regression():\n",
    "    partInput = keras.Input(shape=(31,31,1),name=\"partImage\")\n",
    "    forceInput = keras.Input(shape=(31,31,2),name=\"Forces\")\n",
    "    supportInput = keras.Input(shape=(31,31,1),name=\"Supports\")\n",
    "    #complianceMaxInput = keras.Input(shape=(1),name=\"complianceMax\")\n",
    "\n",
    "\n",
    "    partConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(partInput)\n",
    "    forceConv = layers.Conv2D(filters= 10,kernel_size=(3,3),padding='same',activation='tanh')(forceInput)\n",
    "    supportConv = layers.Conv2D(filters= 5,kernel_size=(3,3),padding='same')(supportInput)\n",
    "    #cScaling = layers.Reshape((supportConv.shape[1],supportConv.shape[2],1))(layers.RepeatVector(supportConv.shape[1]*supportConv.shape[2])(complianceMaxInput))\n",
    "\n",
    "\n",
    "    concatenatedConvolution = layers.Concatenate()([partConv,forceConv,supportConv])\n",
    "    x1 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(concatenatedConvolution)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "    #x1 = layers.Concatenate()([x1,cScaling])\n",
    "    x1 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x1)\n",
    "    x1 = layers.GaussianNoise(stddev=0.5)(x1)\n",
    "    x1 = layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same')(x1)\n",
    "\n",
    "    newShape = (x1.shape[1],x1.shape[2])\n",
    "    #print(x1.shape)\n",
    "    #cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    partScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(concatenatedConvolution)\n",
    "    x2 = layers.Concatenate()([x1,partScaling])\n",
    "    x2 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "    x2 = layers.Conv2D(filters= 64, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x2 = layers.GaussianNoise(stddev=0.5)(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x2)\n",
    "\n",
    "    newShape = (x2.shape[1],x2.shape[2])\n",
    "    #print(x1.shape)\n",
    "    #cScaling = layers.Resizing(height=newShape[0],width=newShape[1],interpolation='nearest')(cScaling)\n",
    "    #x3 = layers.Concatenate()([x2,cScaling])\n",
    "    x3 = layers.Conv2D(filters= 32, kernel_size=(3,3),padding='same',activation=activation)(x2)\n",
    "    x3 = layers.Dropout(0.3)(x3)\n",
    "    x3 = layers.Conv2D(filters= 16, kernel_size=(3,3),padding='same',activation=activation)(x3)\n",
    "    x3 = layers.GaussianNoise(stddev=0.5)(x3)\n",
    "    x3 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(x3)\n",
    "\n",
    "    x_flat = layers.Flatten()(x3)\n",
    "    #x3 = layers.concatenate([x_flat,complianceMaxInput])\n",
    "    x4 = layers.Dense(32,activation=activation)(x_flat)\n",
    "    #x3 = layers.Dropout(0.2)(x3)\n",
    "\n",
    "    #x4 = layers.concatenate([x3,complianceMaxInput])\n",
    "    #outputs = layers.GlobalAveragePooling1D()(x4)\n",
    "    outputs = layers.Dense(1)(x4)\n",
    "    return keras.Model(inputs= [partInput,forceInput,supportInput],outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tester = m5_regression()\n",
    "comp_tester.summary()\n",
    "#keras.utils.plot_model(comp_tester, os.path.join(os.getcwd(),\"model1.png\"), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfMadOptomizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "comp_tester.compile(optimizer=selfMadOptomizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "comp_tester.load_weights(str(ToSavePath))\n",
    "# comp_tester.compile(optimizer=selfMadOptomizer,\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tester.fit(\n",
    "                {\"partImage\":X_train_part, \"Forces\":X_train_forces, \"Supports\":X_train_supports},#, \"complianceMax\":X_train_compliance},\n",
    "                Y_train,\n",
    "                epochs=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(\n",
    "                    {\"partImage\":X_test_part, \"Forces\":X_test_forces, \"Supports\":X_test_supports},#,\"complianceMax\":X_test_compliance}, \n",
    "                        Y_test),\n",
    "                callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsToTest = 10\n",
    "dataSample_part = X_test_part[pointsToTest:]\n",
    "dataSample_forces = X_test_forces[pointsToTest:]\n",
    "dataSample_supports = X_test_supports[pointsToTest:]\n",
    "\n",
    "dataSample_Y_True = Y_test[pointsToTest:]\n",
    "\n",
    "dataSample_Y_pred = comp_tester.predict({\"partImage\":dataSample_part, \"Forces\":dataSample_forces, \"Supports\":dataSample_supports})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanError = 0\n",
    "errorList = []\n",
    "\n",
    "for i in range(pointsToTest):\n",
    "    #print(dataSample_Y_True[i],dataSample_Y_pred[i][0])\n",
    "    a = np.exp(dataSample_Y_True[i])\n",
    "    b = np.exp(dataSample_Y_pred[i][0])\n",
    "    if(a != 0):\n",
    "        errorList.append(abs(a-b)/a)\n",
    "\n",
    "error = np.array(errorList)\n",
    "\n",
    "print(\"mean:\", np.mean(error))\n",
    "print(\"standard deviation:\", np.std(error))\n",
    "print(\"min: {}\\tmax: {}\".format(np.min(error),np.max(error)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d91d6363c0adb958ed116842d9c2fc7faebb1fa3beaff0888078e0808098095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
